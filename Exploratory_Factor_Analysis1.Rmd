---
title: "Exploratory Factor Analysis"
author: "Milla Pihlajamaki and Caitlin Dawson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_notebook
---

```{r Load Packages}

# library(ISLR) 
# library(dplyr) 
# library(tidyr)
library(tidyverse)
library(corrplot)
# library(caret)
library(glmnet)
library(semPlot)
# library(tidyselect)
library(psych)
library(lavaan)
# library(ggplot2)
library(psychTools)
# library(GPArotation)
# library(devtools)
# library(apaTables)
# library(sjPlot)
# library(glasso)

# Load data
data_efa <- read.csv("data_efa.csv")

# Create task- and survey-only sets
t_var_log <- c("GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum")
q_var <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "HEscore", "HRscore", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount")
survey_data <- data_efa[, q_var]
task_data <- data_efa[, t_var_log]

```


# Cross-method prediction

10-fold cross validated ridge regression to predict survey and task variables *within* and *between* measure types following Eisenberg et al, 2018. Intended to help decide whether to factor tasks and surveys together or separately, and also to see if some variables should be left out. 

Taking each DV one by one and trying to predict it using its own measurement category (leaving it out) and by the other measurement category. Each DV is the target; the predictors are the other variables in the category. 

4 distributions of predictions: tasks-by-tasks, tasks-by-surveys, surveys-by-tasks, and surveys-by-surveys -> extract the R^2 values and create four distributions

"Note that R2 values below 0 are possible when employing  cross-validation and indicate no discoverable linear relationship. The entire distribution of R2  values for each of these predictions is shown is Figure S2b."

Ridge regression works better than regular linear regression when you have many variables in a model and also collinearity. It is a form of penalized regression that adds a constraint. The constraint constant is defined by *lambda*, which shrinks coefficients. A lambda of 0 is a regular linear regression, and a too large lambda will shrink the coefficients too much to make a usable model. We can identify the best value of lambda by using cross-validation. 

Instead of splitting data into a training and test set, cross-validation trains and tests the model on subsets of the full dataset, creating a distribution. Here we just use it to compare various values of lambda in order to choose the best one for each prediction model. 

The aim of this section is to create a model for predicting each DV in the 4 distributions described above. Ridge regression is used because of the type of dataset and because we want to retain all variables when checking the cross- and between-measure type predictions. 

The question here is, can X variable be predicted equally well by surveys vs. tasks? After we get these R2 for each model (there will be 4 models per variable), we can take the mean R2 for each of the 4 distributions and make a plot as in Eisenberg to examine whether the distributions are similar. This helps us decide whether task and survey variables should be clustered or factored together.  

```{r Ridge Regression (Cross-Method Prediction)}

# Survey x survey 
# NOTE: omitting the binary variables H-E and H-R
q_var_sub <- q_var[-c(which(q_var == "HEscore"), which(q_var == "HRscore"))]
survey_data_sub <- data_efa[, q_var_sub]

predicted_SS <- c()
predicted_type_SS <- rep("survey", length(q_var_sub))
predictors_SS <- rep("surveys", length(q_var_sub))
R2_SS <- c()

for (i in 1:length(q_var_sub)) {
  
  # Save x and y
  x_var <- as.matrix(survey_data_sub[, -which(colnames(survey_data_sub) == q_var_sub[i])])
  y_var <- survey_data_sub[, q_var_sub[i]]
  predicted_SS <- c(predicted_SS, q_var_sub[i])
  
  # Fit the ridge regression model
  model <- glmnet(x = x_var, y = y_var, alpha = 0)
  
  # Perform k-fold cross-validation to find optimal lambda value
  cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
  
  # Find optimal lambda
  best_lambda <- cv_model$lambda.min
  
  # Find coefficients for the best model
  best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
  
  # Use fitted best model to make predictions (NOTE: not 100% sure about this)
  y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
  
  # Find SST and SSE
  sst <- sum((y_var - mean(y_var))^2)
  sse <- sum((y_predicted - y_var)^2)
  
  # Find R-squared of the model on the training data
  rsq <- 1 - sse/sst
  R2_SS <- c(R2_SS, rsq)
  
}

SxS <- data.frame(predicted = predicted_SS, predictors = predictors_SS, 
                  predicted_type = predicted_type_SS, R2 = R2_SS)

# Task x task
predicted_TT <- c()
predicted_type_TT <- rep("task", length(t_var_log))
predictors_TT <- rep("tasks", length(t_var_log))
R2_TT <- c()
for (i in 1:length(t_var_log)) {
  x_var <- as.matrix(task_data[, -which(colnames(task_data) == t_var_log[i])])
  y_var <- task_data[, t_var_log[i]]
  predicted_TT <- c(predicted_TT, t_var_log[i])
  model <- glmnet(x = x_var, y = y_var, alpha = 0)
  cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
  y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
  sst <- sum((y_var - mean(y_var))^2)
  sse <- sum((y_predicted - y_var)^2)
  rsq <- 1 - sse/sst
  R2_TT <- c(R2_TT, rsq)
}
TxT <- data.frame(predicted = predicted_TT, predictors = predictors_TT, 
                  predicted_type = predicted_type_TT, R2 = R2_TT)

# Survey x task (surveys predicted by tasks)
predicted_ST <- c()
predicted_type_ST <- rep("survey", length(q_var_sub))
predictors_ST <- rep("tasks", length(q_var_sub))
R2_ST <- c()
for (i in 1:length(q_var_sub)) {
  x_var <- as.matrix(task_data)
  y_var <- survey_data_sub[, q_var_sub[i]]
  predicted_ST <- c(predicted_ST, q_var_sub[i])
  model <- glmnet(x = x_var, y = y_var, alpha = 0)
  cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
  y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
  sst <- sum((y_var - mean(y_var))^2)
  sse <- sum((y_predicted - y_var)^2)
  rsq <- 1 - sse/sst
  R2_ST <- c(R2_ST, rsq)
}
SxT <- data.frame(predicted = predicted_ST, predictors = predictors_ST, 
                  predicted_type = predicted_type_ST, R2 = R2_ST)

# Tasks x surveys (tasks predicted by surveys)
predicted_TS <- c()
predicted_type_TS <- rep("task", length(t_var_log))
predictors_TS <- rep("surveys", length(t_var_log))
R2_TS <- c()
for (i in 1:length(t_var_log)) {
  x_var <- as.matrix(survey_data_sub)
  y_var <- task_data[, t_var_log[i]]
  predicted_TS <- c(predicted_TS, t_var_log[i])
  model <- glmnet(x = x_var, y = y_var, alpha = 0)
  cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
  best_lambda <- cv_model$lambda.min
  best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
  y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
  sst <- sum((y_var - mean(y_var))^2)
  sse <- sum((y_predicted - y_var)^2)
  rsq <- 1 - sse/sst
  R2_TS <- c(R2_TS, rsq)
}
TxS <- data.frame(predicted = predicted_TS, predictors = predictors_TS, 
                  predicted_type = predicted_type_TS, R2 = R2_TS)

# Bind the dataframes
R2_crossmethod <- rbind(SxS, TxT, SxT, TxS)

# Describe R^2 per group
R2_crossmethod <- R2_crossmethod %>% 
  mutate(format = case_when((predicted_type == "task" & predictors == "tasks")  ~ "TxT",
                            (predicted_type == "survey" & predictors == "surveys")  ~ "SxS",
                            (predicted_type == "task" & predictors == "surveys")  ~ "TxS",
                            (predicted_type == "survey" & predictors == "tasks")  ~ "SxT"))
R2_crossmethod$format <- as.factor(R2_crossmethod$format)
R2_crossmethod %>% 
  group_by(format) %>% 
  summarise(mean(R2), sd(R2))

# Visualize R^2 per group
# Same plot
ggplot(R2_crossmethod, aes(x = R2)) +
  geom_histogram(aes(color = format, fill = format),
                 position = "identity", bins = 50) +
  scale_color_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
  scale_fill_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
  theme_minimal()
# Separate plots
par(mfrow = c(2, 2))
formats <- c("SxS", "SxT", "TxT", "TxS")
for (i in 1:4) {
  hist(R2_crossmethod[which(R2_crossmethod$format == formats[i]), "R2"],
       main = paste0("R2 for ", formats[i]),
       col = sample(colors(), 1),
       breaks = 20,
       xlab = "")
}

```

# Exploratory Factor Analysis

Only using questionnaire variables.

## Create Correlation Matrices

```{r Create Correlation Matrices, include = FALSE}

# Descriptives
describe(data_efa)

# Create character strings with different classes of variables
con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount", "GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum")
q_con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount")
cat <- c("HEscore", "HRscore")

# Create a correlation matrix (polychoric/mixed correlations)
all_cor <- mixedCor(data = data_efa, d = cat, c = con, 
                    use = "pairwise.complete.obs",
                    method = "spearman")
Q_cor <- mixedCor(data = survey_data, d = cat, c = q_con,
                  use = "pairwise.complete.obs",
                  method = "spearman")
T_cor <- mixedCor(data = task_data, 
                  use = "pairwise.complete.obs",
                  method = "pearson")

# Store correlation matrix
all_rho <- all_cor$rho
Q_rho <- Q_cor$rho
T_rho <- T_cor$rho

# Mean correlation across items
mean(abs(all_rho[lower.tri(all_rho)]))
mean(abs(Q_rho[lower.tri(Q_rho)]))
mean(abs(T_rho[lower.tri(T_rho)]))

# Histogram of correlations
hist(abs(all_rho[lower.tri(all_rho)]), 
     breaks = 20, col = sample(colors(), 1))
hist(abs(Q_rho[lower.tri(Q_rho)]), 
     breaks = 20, col = sample(colors(), 1))
hist(abs(T_rho[lower.tri(T_rho)]), 
     breaks = 20, col = sample(colors(), 1))

# Corrplot without titles
corrplot(all_rho, tl.pos = "n")

```

## Factorability

```{r Factorability, include = FALSE}

# Bartlett test (p<.05 indicates data are suitable for structure detection)
cortest.bartlett(all_rho, n = nrow(data_efa))
cortest.bartlett(Q_rho, n = nrow(survey_data))
cortest.bartlett(T_rho, n = nrow(task_data))

# Kaiser-Meyer-Olkin measure (>.7 is good)
sort(round(KMO(r = all_rho)$MSAi, 2))
sort(round(KMO(r = Q_rho)$MSAi, 2))
sort(round(KMO(r = T_rho)$MSAi, 2))
# NOTE: KMO is not very good for a lot of items?

```

## Identify number of factors to extract

EBIC as the main criterion following Eisenberg et al., 2018, but final decision based on theoretical coherence of the factors. Zmigrod et al., 2021 used scree plots and PA.

```{r Number of factors, include = FALSE}

# Scree plots
# All variables
plot(eigen(all_rho)$values, type = "b", pch = 20, col = "red",
     main = "Scree Plot", ylab = "Eigenvalues",
     xlab = "No. Factors")
# Questionnaire variables
plot(eigen(Q_rho)$values, type = "b", pch = 20, col = "red",
     main = "Scree Plot", ylab = "Eigenvalues",
     xlab = "No. Factors")
# Task variables
plot(eigen(T_rho)$values, type = "b", pch = 20, col = "red",
     main = "Scree Plot", ylab = "Eigenvalues",
     xlab = "No. Factors")

# NFactors
# All variables
nfactors(all_rho, n = 6, n.obs  = nrow(data_efa), 
         rotate = "oblimin", diagonal = FALSE, 
         fm = "minrank") 
# Questionnaires
nfactors(Q_rho, n = 6, n.obs  = nrow(survey_data), 
         rotate = "oblimin", diagonal = FALSE,
         fm = "minrank") 
# Tasks
nfactors(T_rho, n = 6, n.obs  = nrow(task_data), 
         rotate = "oblimin", diagonal = FALSE,
         fm = "minrank") 

# Parallel Analysis
# All variables
fa.parallel(all_rho, n.obs = nrow(data_efa), fm = "minrank")
# cor.plot(all_rho)
# Questionnaires
fa.parallel(Q_rho, n.obs = nrow(survey_data), fm = "minrank")
# cor.plot(Q_rho)
# Tasks
fa.parallel(T_rho, n.obs = nrow(task_data), fm = "minrank")
# cor.plot(T_rho)

```

## Run the Factor Analysis with lavaan

Number of factors is determined with EBIC. Lavaan functions used in order to extract factor scores. 

```{r EFA for Questionnaires (4 factors according to EBIC)}

# 4-factor model
f4 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + EMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH1Sum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HEscore + HRscore + RPSum + sci_cur + sci_tru + sci_impo + sci_id + MatrixCorrectCount'

# Fit the model
efa_f4 <- cfa(model = f4,
              data = survey_data,
              rotation = "oblimin",
              estimator = "WLSMV",
              ordered = c("HEscore", "HRscore", "RPSum"))
summary(efa_f4, fit.measures = TRUE)
parameterEstimates(efa_f4)
fitmeasures(efa_f4)


#exploring removing some items
# Look at loadings
#loadings_4f <- inspect(efa_f4, what = "std")[["lambda"]]
#fa.diagram(inspect(efa_f4, what = "std")[["lambda"]])
#loadings_4f <- as.data.frame(loadings_4f)
#round(fa.sort(loadings_4f), 2)
# Remove EMean, HEscore (no loadings >= .3)

#survey_data_sub <- survey_data %>%
#  select(-c("HEscore"))  # removed EMean and HEscore first, and IH1sum second (here all at once)
#f4_sub <- '
#efa("efa")*f1 +
#efa("efa")*f2 +
#efa("efa")*f3 +
#efa("efa")*f4 =~ AMean + CMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH2Sum + IH3Sum + #IH4Sum + CloSum  +  CogSum + AOTSum + HRscore + RPSum + sci_cur + sci_impo + sci_id + sci_tru + #MatrixCorrectCount + IH1Sum + EMean'

# Fit the model
#efa_f4_sub <- cfa(model = f4_sub,
#                  data = survey_data_sub,
#                  rotation = "oblimin",
#                  estimator = "WLSMV",
#                  ordered = c("HRscore", "RPSum"))
#summary(efa_f4_sub, fit.measures = TRUE)
#parameterEstimates(efa_f4_sub)
#fitmeasures(efa_f4_sub)


#loadings_4f_sub <- inspect(efa_f4_sub, what = "std")[["lambda"]]
#fa.diagram(inspect(efa_f4_sub, what = "std")[["lambda"]])
#loadings_4f_sub <- as.data.frame(loadings_4f_sub)
#round(fa.sort(loadings_4f_sub), 2)


# Visualize
# 19 items, 4 factors
# Create layout matrix (23 nodes altogether)
# y <- c(rep(c(-0.9, -0.8), length.out = 19), # items
#        rep(0, 4)) # latents
# x <- c(seq(from = -0.98, to = 0.98, length.out = 19), # items
#        -0.75, -0.25, 0.25, 0.75)
# coord <- matrix(data = c(x, y), nrow = 23, ncol = 2, byrow = FALSE)
# semPaths(efa_f4_sub,
#          what = "est",
#          whatLabels = "no",
#          as.expression = c("nodes", "edges"),
#          theme = "colorblind", 
#          curvePivot = TRUE,
#          sizeMan = 3,
#          sizeLat = 7,
#          edge.label.cex = 1,
#          reorder = FALSE,
#          width = 8,
#          height = 5,
#          groups = "latents",
#          borders = FALSE,
#          residuals = FALSE,
#          intercepts = FALSE,
#          thresholds = FALSE,
#          label.prop = .96,
#          label.scale = TRUE,
#          color = c(rep("#bfbfbf", 4)),
#          layout = coord, 
#          exoCov = FALSE,
#          nodeLabels = c("AMean", "CMean", "ESMean", "OMean", "ICur", "DCur", "IH2", "IH3", "IH4", "Clo ", " Cog", "AOT", "HR", "RP", "sci_cur", "sci_tru", "sci_impo", "sci_id", "Mat_rea", "F1", "F2", "F3", "F4")
#          ,
#          filename = "4f_pathdiagram",
#          filetype = "pdf"
#          )

#This code can be used to attach row names to create a nice heatmap, but as they are manually ordered, double-check the actual order of variables and the order of the factors!

#loading_mat <- as.matrix(fa.sort(loadings_4f))
#loading_mat <- loading_mat[, -ncol(loading_mat)]
#rownames(loading_mat) <- c("Respect for others' viewpoints (IH)", 
#                           "Agreeableness (TIPI)", 
#                           "Openness (TIPI)",
#                           "Need for closure",
#                           "Extraversion (TIPI)",
#                            "Science identity (SA)",
#                           "Need for cognition",
#                           "Interest curiosity (EC)",
#                           "Science curiosity (SA)",
#                           "Deprivation curiosity (EC)",
#                           "Importance of science (SA)",
#                           "Independence of intellect and ego (IH)",
#                           "Trust in science (SA)",
#                           "Heuristic-equiprobability",
#                           "Openness to Revising One's Viewpoint (IH)",
#                           "Conscientiousness (TIPI)",
#                           "Actively Openminded Thinking",
#                           "Emotional Stability (TIPI)",
#                           "Lack of Intellectual Overconfidence (IH)")
#                           "Randomness-probability", 
#                           "Heuristic-representativeness", 
#                           "Matrix reasoning",


#colnames(loading_mat) <- c("Prosociality", "Curiosity", ""Openmindedness", Cognitive skills")

corrplot(loading_mat, method = "color",
         addCoef.col = NULL, 
         number.cex = .75,
         tl.cex = .75,
         tl.col = "black", 
         cl.pos = "b",
         cl.length = 4,
         cl.cex = .6
         )


```


```{r Extract Factor Scores}
#using the model with all items retained
scores_4f <- lavPredict(efa_f4, method = "EBM")
#scores_4f_sub <- lavPredict(efa_f4_sub, method = "EBM")

#attach factor scores to dataset
data_efa <- cbind(data_efa, scores_4f)
```

#Create Factor loading table in latex

```{r Factor loading table}

#this takes a df or matrix, do not put in the matrix using fa2latex
#argument 2 is cropping digits
df2latex(loading_mat, 2)

```

