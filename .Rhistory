data_nogoT <- data_nogoT %>%
group_by(Participant.Private.ID) %>%
mutate(Accuracy = sum(Correct, na.rm = TRUE) / (sum(Correct, na.rm = TRUE) + sum(Incorrect, na.rm = TRUE))) %>%
mutate(go.nogo_omit = case_when(Accuracy > .60 ~ 0,
Accuracy <= .60 ~ 1))
# Omit rows based on exclusion criteria
data_nogoT$Response[which(data_nogoT$go.nogo_omit == 1)] <- NA
# Create Signal Detection Theory categories for each row
data_nogoT <- data_nogoT %>%
filter(display == "Trials") %>%
mutate(SDT = case_when((Array %in% c("H.png",  "T.png") & Response == "Go") ~ "Hit",
(Array %in% c("H.png", "T.png") & Response == "No Go") ~ "Miss",
(Array == "N.png" & Response == "Go") ~ "False Alarm",
(Array == "N.png" & Response == "No Go") ~ "Correct Rejection")) %>%
mutate(Hit = case_when(SDT == "Hit" ~ 1,
SDT != "Hit" ~ 0),
Miss = case_when(SDT == "Miss" ~ 1,
SDT != "Miss" ~ 0),
FA = case_when(SDT == "False Alarm" ~ 1,
SDT != "False Alarm" ~ 0),
CR = case_when(SDT == "Correct Rejection" ~ 1,
SDT != "Correct Rejection" ~ 0))
# Calculate the mean and SD of hits and FA (trials with a go response)
data_go_RT <- data_nogoT %>%
filter(SDT %in% c("Hit", "FA")) %>%
group_by(Participant.Private.ID) %>%
summarise(MeanGoRT = mean(Reaction.Time, na.rm = TRUE),
SDGoRT = sd(Reaction.Time, na.rm = TRUE))
# Compute D-Prime and Bias for each participant
# https://www.rdocumentation.org/packages/psycho/versions/0.6.1/topics/dprime
# http://wise.cgu.edu/wise-tutorials/tutorial-signal-detection-theory/signal-detection-d-defined-2/
data_dprime <- data_nogoT %>%
group_by(Participant.Private.ID) %>%
summarise(dp = dprime(n_hit = sum(Hit, na.rm = TRUE),
n_fa = sum(FA, na.rm = TRUE),
n_miss = sum(Miss, na.rm = TRUE),
n_cr = sum(CR, na.rm = TRUE),
n_targets = 300,
n_distractors = 100))
# Add a row to specify what the five different values given mean
data_dprime$value <- rep_len(c("GNGdprime", "GNGbeta", "GNGaprime", "GNGbppd", "GNGc"),
length.out = nrow(data_dprime))
# Into wide format
data_dprime <- data_dprime %>%
pivot_wider(names_from = value, values_from = dp)
data_GNGdprime <- as.data.frame(data_dprime)
# Create a sum score of each response category for each participant
data_nogoT_final <- data_nogoT %>%
select(Participant.Private.ID, Hit, Miss, FA, CR) %>%
group_by(Participant.Private.ID) %>%
summarise(GNGHitSum = sum(Hit, na.rm = TRUE),
GNGMissSum = sum(Miss, na.rm = TRUE),
GNGFASum = sum(FA, na.rm = TRUE),
GNGCRSum = sum(CR, na.rm = TRUE))
# Combine the dataframes (keep all rows)
data_nogoT_final <- merge(data_nogoT_final, data_GNGdprime,
by = "Participant.Private.ID", all = TRUE)
data_nogoT_final <- merge(data_nogoT_final, data_go_RT,
by = "Participant.Private.ID", all = TRUE)
# Exclude participants with invalid responses
data_ConsentValidity <- data_Q_total %>%
select(Participant.Private.ID, Language, Validity.quantised)
# Final dataset
data_nogoT_final <- merge(data_nogoT_final, data_ConsentValidity,
by = "Participant.Private.ID")
# Exclude participants according to validity + language criteria; exclude the participants who stopped mid-task; exclude participants whose sum score for all hit/miss/cr/fa are 0s
data_nogoT_final <- data_nogoT_final %>%
filter(Validity.quantised %in% c(1, NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
filter(!Participant.Private.ID %in% c("5201242", "4886650", "5117494", "5282634", "5500754", "5552405", "5635997")) %>%
filter(!(GNGHitSum == 0 & GNGMissSum == 0 & GNGFASum == 0 & GNGCRSum == 0))
# Final set of columns
data_nogoT_final <- data_nogoT_final %>%
select(Participant.Private.ID, GNGHitSum, GNGMissSum, GNGFASum, GNGCRSum, MeanGoRT, SDGoRT, GNGdprime, GNGbeta, GNGaprime, GNGbppd, GNGc)
# Change columns into numeric
nogo <- c("GNGHitSum", "GNGMissSum", "GNGFASum", "GNGCRSum", "MeanGoRT", "SDGoRT", "GNGdprime", "GNGbeta", "GNGaprime", "GNGbppd", "GNGc")
for (i in 1:length(nogo)) {
data_nogoT_final[, nogo[i]] <- as.numeric(data_nogoT_final[, nogo[i]])
}
# Describe
describe(data_nogoT_final[, nogo])
par(mfrow = c(2, 3))
for (i in 1:length(nogo)) {
hist(data_nogoT_final[, nogo[i]],
main = colnames(data_nogoT_final[nogo[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Omit experiment-general columns & practice (etc.) rows
data_NavonT <- data_NavonT %>%
select(Participant.Private.ID, Spreadsheet:Image) %>%
filter(display %in% c("task1", "task2")) %>%
filter(Screen.Name == "Screen 3")
# Create a column for consistency
data_NavonT <- data_NavonT %>%
mutate(Consistency = case_when((Image == "bigHsmallH.png" | Image == "bigSsmallS.png") ~ "Consistent",
(Image == "bigHsmallS.png" | Image == "bigSsmallH.png") ~ "Inconsistent"))
data_NavonT$Consistency <- as.factor(data_NavonT$Consistency)
data_NavonT$display <- as.factor(data_NavonT$display)
# Accuracy for each task and consistency
Accuracy_Navon <- data_NavonT %>%
group_by(Consistency, display) %>%
summarise(Accuracy_cond = sum(Correct, na.rm = TRUE) / (sum(Correct, na.rm = TRUE) + sum(Incorrect, na.rm = TRUE)))
# Exclusion Criteria: Trial-Level
# RT <= 150ms
data_NavonT$Reaction.Time[which(data_NavonT$Reaction.Time <= 150)] <- NA
# Exclusion Criteria: Participant-Level
# <= 60% accuracy
data_NavonT <- data_NavonT %>%
group_by(Participant.Private.ID) %>%
mutate(Accuracy = sum(Correct, na.rm = TRUE) / (sum(Correct, na.rm = TRUE) + sum(Incorrect, na.rm = TRUE))) %>%
mutate(Navon_omit = case_when(Accuracy > .60 ~ 0,
Accuracy <= .60 ~ 1))
# Omit data based on Navon_omit
data_NavonT$Reaction.Time[which(data_NavonT$Navon_omit == 1)] <- NA
# Subset to only look at correct answers
data_NavonT <- data_NavonT %>%
filter(Correct == "1")
# Ungroup df
data_NavonT <- ungroup(data_NavonT)
# Global SD 1 (consistent trials only)
sd_Global_con <- data_NavonT %>%
filter((Consistency == "Consistent") & display == "task1") %>%
summarise(sd(Reaction.Time, na.rm = TRUE))
sd_Global_con <- sd_Global_con[[1]]
# Local SD 1 (consistent trials only)
sd_Local_con <- data_NavonT %>%
filter((Consistency == "Consistent") & display == "task2") %>%
summarise(sd(Reaction.Time, na.rm = TRUE))
sd_Local_con <- sd_Local_con[[1]]
# Local SD 2 (inconsistent trials only)
sd_Local_incon <- data_NavonT %>%
filter((Consistency == "Inconsistent") & display == "task2") %>%
summarise(sd(Reaction.Time, na.rm = TRUE))
sd_Local_incon <- sd_Local_incon[[1]]
# Calculate pooled SD
# https://www.statisticshowto.com/pooled-standard-deviation/
# Pooled SD consistent (local and global)
pooled_SD_con <- sqrt((sd_Global_con^2 + sd_Local_con^2)/2)
# Pooled SD local (consistent and inconsistent)
pooled_SD_local <- sqrt((sd_Local_incon^2 + sd_Local_con^2)/2)
# Final form of the Navon data
# Select relevant columns and transform the data so columns reflect mean reaction times in each of the four conditions (local/global x consistent/inconsistent)
data_NavonT_final <- data_NavonT %>%
select(Participant.Private.ID, Consistency, display, Reaction.Time) %>%
group_by(Participant.Private.ID, Consistency, display) %>%
summarise(NavonReactionTimeMean = mean(Reaction.Time, na.rm = TRUE),
.groups = "keep") %>%
pivot_wider(names_from = c(Consistency, display),
values_from = NavonReactionTimeMean)
# Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only
data_NavonT_final <- data_NavonT_final %>%
mutate(GlobalToLocalPrecedence = ((Consistent_task1 - Consistent_task2) / as.numeric(pooled_SD_con)))
# Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only
data_NavonT_final <- data_NavonT_final %>%
mutate(GlobalToLocalInterference = ((Inconsistent_task1 - Consistent_task2) / as.numeric(pooled_SD_local)))
# Exclude nonvalid participants
data_NavonT_final <- merge(data_NavonT_final, data_ConsentValidity,
by = "Participant.Private.ID")
# Validity/languege filter + get rid of participants who stopped mid-task + select relevant columns
data_NavonT_final <- data_NavonT_final %>%
filter(Validity.quantised %in% c(1, NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>%
filter(Participant.Private.ID != "4907987" & Participant.Private.ID != "4960307" & Participant.Private.ID != "5317567" & Participant.Private.ID != "5372338" & Participant.Private.ID != "5526450" & Participant.Private.ID != "5578226" & Participant.Private.ID != "5626669" & Participant.Private.ID != "5808176") %>%
select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)
# Two participants' reaction times were replaced with NAs due to their accuracy being below 60%; this produced NaNs in the calculations, so the NaNs are here replaced with NAs
data_NavonT_final <- data_NavonT_final %>%
filter(Participant.Private.ID != "5608075" & Participant.Private.ID != "5411218")
# Describe
Navon <- c("Consistent_task1", "Consistent_task2", "Inconsistent_task1", "Inconsistent_task2", "GlobalToLocalPrecedence", "GlobalToLocalInterference")
describe(data_NavonT_final[, Navon])
par(mfrow = c(2, 3))
for (i in 1:length(Navon)) {
hist(data_NavonT_final[, Navon[i]],
main = colnames(data_NavonT_final[Navon[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Omit irrelevant rows and columns
data_NeckerT <- data_NeckerT %>%
select(Participant.Private.ID, Spreadsheet:Image) %>%
filter(display %in% c("Trial 1", "Trial 2"))
# Calculate sum score for how many times space bar was hit in total
data_NeckerT_final <- data_NeckerT %>%
select(Participant.Private.ID, Response) %>%
group_by(Participant.Private.ID) %>%
summarise(NeckerCountTotal = sum(Response == "space", na.rm = TRUE))
# Calculate switches per second
data_NeckerT_final <- data_NeckerT_final %>%
mutate(NeckerTotalRate = NeckerCountTotal/60)
# Merge to exclude participants
data_NeckerT_final <- merge(data_NeckerT_final, data_ConsentValidity,
by = "Participant.Private.ID")
# Subset by validity and consent info + omit the irrelevant columns
data_NeckerT_final <- data_NeckerT_final %>%
filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
filter(Participant.Private.ID != "5385143") %>%
select(Participant.Private.ID, NeckerCountTotal, NeckerTotalRate)
# Describe
describe(data_NeckerT_final$NeckerTotalRate)
hist(data_NeckerT_final$NeckerTotalRate,
main = "Necker Total Rate",
col = sample(colors(), 1),
xlab = "")
# Load data
data_UUT <- read.csv("UUT_scoring_COMBINED_REVISED_Rcsv.csv", sep = ";")
# Rename participant ID column
names(data_UUT)[1] <- "Participant.Private.ID"
# Select relevant columns + calculate the fluency and flexibility sum score for each participant per rater
data_UUT <- data_UUT %>%
select(Participant.Private.ID, S.Fluency, S.Flex, K.Fluency, K.Flex) %>%
group_by(Participant.Private.ID) %>%
summarise(SFlexibilitySum = sum(S.Flex), SFluencySum = sum(S.Fluency),
KFlexibilitySum = sum(K.Flex), KFluencySum = sum(K.Fluency))
# Calculate participant scores as a mean of the two raters' scores (one for fluency, one for flexibility)
data_UUT$FlexSum <- rowMeans(cbind(data_UUT$SFlexibilitySum,
data_UUT$KFlexibilitySum),
na.rm = TRUE)
data_UUT$FluencySum <- rowMeans(cbind(data_UUT$SFluencySum,
data_UUT$KFluencySum),
na.rm = TRUE)
# Check validity + extract relevant columns
data_UUT <- merge(data_UUT, data_ConsentValidity,
by = "Participant.Private.ID")
data_UUT <- data_UUT %>%
filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
select(Participant.Private.ID, FlexSum, FluencySum)
# Describe
uut <- c("FlexSum", "FluencySum")
describe(data_UUT[, uut])
par(mfrow = c(2, 1))
for (i in 1:length(uut)) {
hist(data_UUT[, uut[i]],
main = colnames(data_UUT[uut[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Merge dataframes
data_T_total1 <- merge(data_nogoT_final, data_NavonT_final,
by = "Participant.Private.ID", all = TRUE)
data_T_total2 <- merge(data_UUT, data_NeckerT_final,
by = "Participant.Private.ID", all = TRUE)
data_T_total <- merge(data_T_total1, data_T_total2,
by = "Participant.Private.ID", all = TRUE)
rm(data_T_total1, data_T_total2)
# Extract the relevant columns
data_T_sub <- data_T_total %>%
select(Participant.Private.ID, GNGdprime, GNGbeta, MeanGoRT, SDGoRT, GlobalToLocalPrecedence, GlobalToLocalInterference, NeckerTotalRate, FlexSum, FluencySum)
# Participant ID into factor
data_T_sub$Participant.Private.ID <- as.factor(data_T_sub$Participant.Private.ID)
# Task variables
t_var <- c("GNGdprime", "GNGbeta", "MeanGoRT", "SDGoRT", "GlobalToLocalPrecedence", "GlobalToLocalInterference", "NeckerTotalRate", "FlexSum", "FluencySum")
# Add a column for count of missing data per ppt
data_T_sub$t_missingdata <- rowSums(is.na(data_T_sub[, t_var]))
table(data_T_sub$t_missingdata)
plot(sort(data_T_sub$t_missingdata))
# Merge demographic information to investigate missingness
# NOTE: what to do about the age correlation?
data_T_all <- data_Q_total %>%
select(Participant.Private.ID, gender, Age, Country, Language, Education)
data_T_sub <- merge(data_T_all, data_T_sub,
by = "Participant.Private.ID", all = TRUE)
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age, data_T_sub$t_missingdata,
method = "spearman", exact = FALSE)
# Remove participants with 4 or more missing task variables
data_T_sub <- data_T_sub %>%
group_by(Participant.Private.ID) %>%
filter(t_missingdata < 4) %>%
select(-t_missingdata)
# Normality of variables: visualize with histograms
data_T_sub <- as.data.frame(data_T_sub)
par(mfrow = c(2, 2))
for (i in 1:length(t_var)) {
hist(data_T_sub[, t_var[i]],
main = colnames(data_T_sub[t_var[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Describe: mean, skew, kurtosis
describe(data_T_sub[, t_var])
# Transforming all variables with absolute skew > 1
data_T_sub$GNGbetalog <- log10(data_T_sub$GNGbeta)
data_T_sub$SDGoRTlog <- log10(data_T_sub$SDGoRT)
data_T_sub$GlobalToLocalInterferencelog <- log10(data_T_sub$GlobalToLocalInterference + 3) # added 3 because log10 cannot handle 0s/negative numbers
data_T_sub$NeckerTotalRatelog <- log10(data_T_sub$NeckerTotalRate + 0.5) # added 1 because log10 cannot handle 0s
data_T_sub$GlobalToLocalPrecedencelog <- log10(max(data_T_sub$GlobalToLocalPrecedence + 1, na.rm = TRUE) - data_T_sub$GlobalToLocalPrecedence)
# Task variables: transformed
t_var_log <- c("GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum", "FluencySum")
# Describe
describe(data_T_sub[, t_var_log])
# Visualize
par(mfrow = c(2, 2))
for (i in 1:length(t_var_log)) {
hist(data_T_sub[, t_var_log[i]],
main = colnames(data_T_sub[t_var_log[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Correlation matrix
round(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"), 2)
abs(round(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"), 2)) > .85
corrplot(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"))
# Exclude FluencySum as it correlates highly with FlexSum; only include log-transformed variables where necessary
data_T_sub <- data_T_sub %>%
select(Participant.Private.ID, GNGdprime, GNGbetalog, MeanGoRT, SDGoRTlog, GlobalToLocalInterferencelog, GlobalToLocalPrecedencelog, NeckerTotalRatelog, FlexSum)
data_all_sub_cleaned <- merge(data_Q_sub, data_T_sub,
by = "Participant.Private.ID",
all = TRUE)
# Ungroup the dataframe
ungroup(data_all_sub_cleaned)
# Select relevant columns
data_all_sub_cleaned <- data_all_sub_cleaned %>%
select(-Participant.Private.ID)
# Check missing data
sort(colSums(is.na(data_all_sub_cleaned)))
sort(rowSums(is.na(data_all_sub_cleaned)))
# As more participants were excluded based on their task data than based on their questionnaire data, there are participants that have more missing variables than they should based on the thresholds set for tasks and questionnaires (7+3=10).
# NOTE: not sure what to do here, will remove them for now
data_all_sub_cleaned <- data_all_sub_cleaned[-which(rowSums(is.na(data_all_sub_cleaned)) > 10),]
# Rename
data_efa <- data_all_sub_cleaned
# Remove all rows with missing values
data_efa <- na.omit(data_efa)
# Describe
par(mfrow = c(2, 5))
for (i in 1:ncol(data_efa)) {
hist(data_efa[, i], col = sample(colors(), 1))
}
describe(data_efa)
# Check how much data is missing per row and column
# sort(table(colSums(is.na(data_efa))))
# sort(table(rowSums(is.na(data_efa))))
# % of missing data overall
# sum(is.na(data_efa))/(ncol(data_efa)*nrow(data_efa))*100 # 0.9% of data missing
# NOTE: do we want to impute? 127 participants with no missing data, 139 overall
# library(ISLR)
# library(glmnet)
# library(dplyr)
# library(tidyr)
# library(tidyverse)
# library(caret)
library(glmnet)
library(semPlot)
# library(tidyverse)
# library(tidyselect)
# library(psych)
# library(lavaan)
# library(dplyr)
# library(ggplot2)
# library(psychTools)
# library(GPArotation)
# library(devtools)
# library(apaTables)
# library(semPlot)
# library(sjPlot)
# library(glasso)
# Create task- and survey-only sets
t_var_log <- t_var_log[-9]
survey_data <- data_efa[, q_var]
task_data <- data_efa[, t_var_log]
# Survey x survey
# NOTE: not sure if the binary items are an issue? not sure if this is the case when they are predictors but I would assume when they are being predicted? I will omit them here just in case
q_var_sub <- q_var[-c(which(q_var == "HEscore"), which(q_var == "HRscore"))]
survey_data_sub <- data_efa[, q_var_sub]
predicted_SS <- c()
predicted_type_SS <- rep("survey", length(q_var_sub))
predictors_SS <- rep("surveys", length(q_var_sub))
R2_SS <- c()
for (i in 1:length(q_var_sub)) {
# Save x and y
x_var <- as.matrix(survey_data_sub[, -which(colnames(survey_data_sub) == q_var_sub[i])])
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_SS <- c(predicted_SS, q_var_sub[i])
# Fit the ridge regression model
model <- glmnet(x = x_var, y = y_var, alpha = 0)
# Perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
# Find optimal lambda
best_lambda <- cv_model$lambda.min
# Find coefficients for the best model
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
# Use fitted best model to make predictions (NOTE: not 100% sure about this)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
# Find SST and SSE
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
# Find R-squared of the model on the training data
rsq <- 1 - sse/sst
R2_SS <- c(R2_SS, rsq)
}
SxS <- data.frame(predicted = predicted_SS, predictors = predictors_SS,
predicted_type = predicted_type_SS, R2 = R2_SS)
# Task x task
predicted_TT <- c()
predicted_type_TT <- rep("task", length(t_var_log))
predictors_TT <- rep("tasks", length(t_var_log))
R2_TT <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(task_data[, -which(colnames(task_data) == t_var_log[i])])
y_var <- task_data[, t_var_log[i]]
predicted_TT <- c(predicted_TT, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TT <- c(R2_TT, rsq)
}
TxT <- data.frame(predicted = predicted_TT, predictors = predictors_TT,
predicted_type = predicted_type_TT, R2 = R2_TT)
# Survey x task (surveys predicted by tasks)
predicted_ST <- c()
predicted_type_ST <- rep("survey", length(q_var_sub))
predictors_ST <- rep("tasks", length(q_var_sub))
R2_ST <- c()
for (i in 1:length(q_var_sub)) {
x_var <- as.matrix(task_data)
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_ST <- c(predicted_ST, q_var_sub[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_ST <- c(R2_ST, rsq)
}
SxT <- data.frame(predicted = predicted_ST, predictors = predictors_ST,
predicted_type = predicted_type_ST, R2 = R2_ST)
# Tasks x surveys (tasks predicted by surveys)
predicted_TS <- c()
predicted_type_TS <- rep("task", length(t_var_log))
predictors_TS <- rep("surveys", length(t_var_log))
R2_TS <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(survey_data_sub)
y_var <- task_data[, t_var_log[i]]
predicted_TS <- c(predicted_TS, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TS <- c(R2_TS, rsq)
}
TxS <- data.frame(predicted = predicted_TS, predictors = predictors_TS,
predicted_type = predicted_type_TS, R2 = R2_TS)
# Bind the dataframes
R2_crossmethod <- rbind(SxS, TxT, SxT, TxS)
# Describe R^2 per group
R2_crossmethod <- R2_crossmethod %>%
mutate(format = case_when((predicted_type == "task" & predictors == "tasks")  ~ "TxT",
(predicted_type == "survey" & predictors == "surveys")  ~ "SxS",
(predicted_type == "task" & predictors == "surveys")  ~ "TxS",
(predicted_type == "survey" & predictors == "tasks")  ~ "SxT"))
R2_crossmethod$format <- as.factor(R2_crossmethod$format)
R2_crossmethod %>%
group_by(format) %>%
summarise(mean(R2), sd(R2))
# Visualize R^2 per group
# Same plot
ggplot(R2_crossmethod, aes(x = R2)) +
geom_histogram(aes(color = format, fill = format),
position = "identity", bins = 50) +
scale_color_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
scale_fill_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
theme_minimal()
# Separate plots
par(mfrow = c(2, 2))
formats <- c("SxS", "SxT", "TxT", "TxS")
for (i in 1:4) {
hist(R2_crossmethod[which(R2_crossmethod$format == formats[i]), "R2"],
main = paste0("R2 for ", formats[i]),
col = sample(colors(), 1),
breaks = 20,
xlab = "")
}
names(survey_data)
# 4-factor model
f4 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + EMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH1Sum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HEscore + HRscore + RPSum + sci_cur + sci_tru + sci_impo + sci_id + MatrixCorrectCount'
# Fit the model
efa_f4 <-
cfa(model = f4,
data = d,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HEscore", "HRscore", "RPSum"))
# Fit the model
efa_f4 <-
cfa(model = f4,
data = survey_data,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HEscore", "HRscore", "RPSum"))
summary(efa_f4, fit.measures = TRUE)
parameterEstimates(efa_f4)
summary(efa_f4, fit.measures = TRUE)
fitmeasures(efa_f4)
