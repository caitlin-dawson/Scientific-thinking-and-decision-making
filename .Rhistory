# Local SD 1 (consistent trials only)
sd_Local_con <- data_NavonT %>%
filter((Consistency == "Consistent") & display == "task2") %>%
summarise(sd(Reaction.Time, na.rm = TRUE))
sd_Local_con <- sd_Local_con[[1]]
# Local SD 2 (inconsistent trials only)
sd_Local_incon <- data_NavonT %>%
filter((Consistency == "Inconsistent") & display == "task2") %>%
summarise(sd(Reaction.Time, na.rm = TRUE))
sd_Local_incon <- sd_Local_incon[[1]]
# Calculate pooled SD
# https://www.statisticshowto.com/pooled-standard-deviation/
# Pooled SD consistent (local and global)
pooled_SD_con <- sqrt((sd_Global_con^2 + sd_Local_con^2)/2)
# Pooled SD local (consistent and inconsistent)
pooled_SD_local <- sqrt((sd_Local_incon^2 + sd_Local_con^2)/2)
# Final form of the Navon data
# Select relevant columns and transform the data so columns reflect mean reaction times in each of the four conditions (local/global x consistent/inconsistent)
data_NavonT_final <- data_NavonT %>%
select(Participant.Private.ID, Consistency, display, Reaction.Time) %>%
group_by(Participant.Private.ID, Consistency, display) %>%
summarise(NavonReactionTimeMean = mean(Reaction.Time, na.rm = TRUE),
.groups = "keep") %>%
pivot_wider(names_from = c(Consistency, display),
values_from = NavonReactionTimeMean)
# Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only
data_NavonT_final <- data_NavonT_final %>%
mutate(GlobalToLocalPrecedence = ((Consistent_task1 - Consistent_task2) / as.numeric(pooled_SD_con)))
# Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only
data_NavonT_final <- data_NavonT_final %>%
mutate(GlobalToLocalInterference = ((Inconsistent_task1 - Consistent_task2) / as.numeric(pooled_SD_local)))
# Exclude nonvalid participants
data_NavonT_final <- merge(data_NavonT_final, data_ConsentValidity,
by = "Participant.Private.ID")
# Validity/languege filter + get rid of participants who stopped mid-task + select relevant columns
data_NavonT_final <- data_NavonT_final %>%
filter(Validity.quantised %in% c(1, NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>%
filter(Participant.Private.ID != "4907987" & Participant.Private.ID != "4960307" & Participant.Private.ID != "5317567" & Participant.Private.ID != "5372338" & Participant.Private.ID != "5526450" & Participant.Private.ID != "5578226" & Participant.Private.ID != "5626669" & Participant.Private.ID != "5808176") %>%
select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)
# Two participants' reaction times were replaced with NAs due to their accuracy being below 60%; this produced NaNs in the calculations, so the NaNs are here replaced with NAs
data_NavonT_final <- data_NavonT_final %>%
filter(Participant.Private.ID != "5608075" & Participant.Private.ID != "5411218")
# Describe
Navon <- c("Consistent_task1", "Consistent_task2", "Inconsistent_task1", "Inconsistent_task2", "GlobalToLocalPrecedence", "GlobalToLocalInterference")
describe(data_NavonT_final[, Navon])
par(mfrow = c(2, 3))
for (i in 1:length(Navon)) {
hist(data_NavonT_final[, Navon[i]],
main = colnames(data_NavonT_final[Navon[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Omit irrelevant rows and columns
data_NeckerT <- data_NeckerT %>%
select(Participant.Private.ID, Spreadsheet:Image) %>%
filter(display %in% c("Trial 1", "Trial 2"))
# Calculate sum score for how many times space bar was hit in total
data_NeckerT_final <- data_NeckerT %>%
select(Participant.Private.ID, Response) %>%
group_by(Participant.Private.ID) %>%
summarise(NeckerCountTotal = sum(Response == "space", na.rm = TRUE))
# Calculate switches per second
data_NeckerT_final <- data_NeckerT_final %>%
mutate(NeckerTotalRate = NeckerCountTotal/60)
# Merge to exclude participants
data_NeckerT_final <- merge(data_NeckerT_final, data_ConsentValidity,
by = "Participant.Private.ID")
# Subset by validity and consent info + omit the irrelevant columns
data_NeckerT_final <- data_NeckerT_final %>%
filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
filter(Participant.Private.ID != "5385143") %>%
select(Participant.Private.ID, NeckerCountTotal, NeckerTotalRate)
# Describe
describe(data_NeckerT_final$NeckerTotalRate)
hist(data_NeckerT_final$NeckerTotalRate,
main = "Necker Total Rate",
col = sample(colors(), 1),
xlab = "")
# Load data
data_UUT <- read.csv("UUT_scoring_COMBINED_REVISED_Rcsv.csv", sep = ";")
# Rename participant ID column
names(data_UUT)[1] <- "Participant.Private.ID"
# Select relevant columns + calculate the fluency and flexibility sum score for each participant per rater
data_UUT <- data_UUT %>%
select(Participant.Private.ID, S.Fluency, S.Flex, K.Fluency, K.Flex) %>%
group_by(Participant.Private.ID) %>%
summarise(SFlexibilitySum = sum(S.Flex), SFluencySum = sum(S.Fluency),
KFlexibilitySum = sum(K.Flex), KFluencySum = sum(K.Fluency))
# Calculate participant scores as a mean of the two raters' scores (one for fluency, one for flexibility)
data_UUT$FlexSum <- rowMeans(cbind(data_UUT$SFlexibilitySum,
data_UUT$KFlexibilitySum),
na.rm = TRUE)
data_UUT$FluencySum <- rowMeans(cbind(data_UUT$SFluencySum,
data_UUT$KFluencySum),
na.rm = TRUE)
# Check validity + extract relevant columns
data_UUT <- merge(data_UUT, data_ConsentValidity,
by = "Participant.Private.ID")
data_UUT <- data_UUT %>%
filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
select(Participant.Private.ID, FlexSum, FluencySum)
# Describe
uut <- c("FlexSum", "FluencySum")
describe(data_UUT[, uut])
par(mfrow = c(2, 1))
for (i in 1:length(uut)) {
hist(data_UUT[, uut[i]],
main = colnames(data_UUT[uut[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Merge dataframes
data_T_total1 <- merge(data_nogoT_final, data_NavonT_final,
by = "Participant.Private.ID", all = TRUE)
data_T_total2 <- merge(data_UUT, data_NeckerT_final,
by = "Participant.Private.ID", all = TRUE)
data_T_total <- merge(data_T_total1, data_T_total2,
by = "Participant.Private.ID", all = TRUE)
rm(data_T_total1, data_T_total2)
# Extract the relevant columns
data_T_sub <- data_T_total %>%
select(Participant.Private.ID, GNGdprime, GNGbeta, MeanGoRT, SDGoRT, GlobalToLocalPrecedence, GlobalToLocalInterference, NeckerTotalRate, FlexSum, FluencySum)
# Participant ID into factor
data_T_sub$Participant.Private.ID <- as.factor(data_T_sub$Participant.Private.ID)
# Task variables
t_var <- c("GNGdprime", "GNGbeta", "MeanGoRT", "SDGoRT", "GlobalToLocalPrecedence", "GlobalToLocalInterference", "NeckerTotalRate", "FlexSum", "FluencySum")
# Add a column for count of missing data per ppt
data_T_sub$t_missingdata <- rowSums(is.na(data_T_sub[, t_var]))
table(data_T_sub$t_missingdata)
plot(sort(data_T_sub$t_missingdata))
# Merge demographic information to investigate missingness
# NOTE: what to do about the age correlation?
data_T_all <- data_Q_total %>%
select(Participant.Private.ID, gender, Age, Country, Language, Education)
data_T_sub <- merge(data_T_all, data_T_sub,
by = "Participant.Private.ID", all = TRUE)
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age, data_T_sub$t_missingdata,
method = "spearman", exact = FALSE)
# Remove participants with 4 or more missing task variables
data_T_sub <- data_T_sub %>%
group_by(Participant.Private.ID) %>%
filter(t_missingdata < 4) %>%
select(-t_missingdata)
# Normality of variables: visualize with histograms
data_T_sub <- as.data.frame(data_T_sub)
par(mfrow = c(2, 2))
for (i in 1:length(t_var)) {
hist(data_T_sub[, t_var[i]],
main = colnames(data_T_sub[t_var[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Describe: mean, skew, kurtosis
describe(data_T_sub[, t_var])[c("mean", "skew", "kurtosis")]
# Transforming all variables with absolute skew > 1
data_T_sub$GNGbetalog <- log10(data_T_sub$GNGbeta)
data_T_sub$SDGoRTlog <- log10(data_T_sub$SDGoRT)
data_T_sub$GlobalToLocalInterferencelog <- log10(data_T_sub$GlobalToLocalInterference + 3) # added 3 because log10 cannot handle 0s/negative numbers
data_T_sub$NeckerTotalRatelog <- log10(data_T_sub$NeckerTotalRate + 0.5) # added 1 because log10 cannot handle 0s
data_T_sub$GlobalToLocalPrecedencelog <- log10(max(data_T_sub$GlobalToLocalPrecedence + 1, na.rm = TRUE) - data_T_sub$GlobalToLocalPrecedence)
# Task variables: transformed
t_var_log <- c("GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum", "FluencySum")
# Describe
describe(data_T_sub[, t_var_log])[c("mean", "skew", "kurtosis")]
# Visualize
par(mfrow = c(2, 2))
for (i in 1:length(t_var_log)) {
hist(data_T_sub[, t_var_log[i]],
main = colnames(data_T_sub[t_var_log[i]]),
col = sample(colors(), 1),
xlab = "")
}
# Correlation matrix
round(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"), 2)
abs(round(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"), 2)) > .85
corrplot(cor(data_T_sub[, t_var_log], method = "pearson",
use = "pairwise.complete.obs"))
# Exclude FluencySum as it correlates highly with FlexSum; only include log-transformed variables where necessary
data_T_sub <- data_T_sub %>%
select(Participant.Private.ID, GNGdprime, GNGbetalog, MeanGoRT, SDGoRTlog, GlobalToLocalInterferencelog, GlobalToLocalPrecedencelog, NeckerTotalRatelog, FlexSum)
data_all_sub_cleaned <- merge(data_Q_sub, data_T_sub,
by = "Participant.Private.ID",
all = TRUE)
# Ungroup the dataframe
ungroup(data_all_sub_cleaned)
# Select relevant columns
data_all_sub_cleaned <- data_all_sub_cleaned %>%
select(-Participant.Private.ID)
# Check missing data
sort(colSums(is.na(data_all_sub_cleaned)))
sort(rowSums(is.na(data_all_sub_cleaned)))
# As more participants were excluded based on their task data than based on their questionnaire data, there are participants that have more missing variables than they should based on the thresholds set for tasks and questionnaires (7+3=10). These participants are missing all their task data.
t_var_log <- t_var_log[-9]
which(rowSums(is.na(data_all_sub_cleaned[, t_var_log])) == length(t_var_log))
# NOTE: not sure what to do here, I will exclude for now?
data_all_sub_cleaned <- data_all_sub_cleaned[-which(rowSums(is.na(data_all_sub_cleaned[, t_var_log])) == length(t_var_log)), ]
# Rename
data_efa <- data_all_sub_cleaned
# Remove all rows with missing values
data_efa <- na.omit(data_efa)
# Describe
par(mfrow = c(2, 5))
for (i in 1:ncol(data_efa)) {
hist(data_efa[, i], col = sample(colors(), 1))
}
describe(data_efa)[c("mean", "skew", "kurtosis")]
# Check how much data is missing per row and column
# sort(table(colSums(is.na(data_efa))))
# sort(table(rowSums(is.na(data_efa))))
# % of missing data overall
# sum(is.na(data_efa))/(ncol(data_efa)*nrow(data_efa))*100 # 0.9% of data missing
# NOTE: do we want to impute? 127 participants with no missing data, 139 overall
# library(ISLR)
# library(glmnet)
# library(dplyr)
# library(tidyr)
# library(tidyverse)
# library(caret)
library(glmnet)
# library(tidyverse)
# library(tidyselect)
# library(psych)
# library(lavaan)
# library(dplyr)
# library(ggplot2)
# library(psychTools)
# library(GPArotation)
# library(devtools)
# library(apaTables)
# library(semPlot)
# library(sjPlot)
# library(glasso)
# Create task- and survey-only sets
survey_data <- data_efa[, q_var]
task_data <- data_efa[, t_var_log]
# Survey x survey
# NOTE: not sure if the binary items are an issue? not sure if this is the case when they are predictors but I would assume when they are being predicted? I will omit them here just in case
q_var_sub <- q_var[-c(which(q_var == "HEscore"), which(q_var == "HRscore"))]
survey_data_sub <- data_efa[, q_var_sub]
predicted_SS <- c()
predicted_type_SS <- rep("survey", length(q_var_sub))
predictors_SS <- rep("surveys", length(q_var_sub))
R2_SS <- c()
for (i in 1:length(q_var_sub)) {
# Save x and y
x_var <- as.matrix(survey_data_sub[, -which(colnames(survey_data_sub) == q_var_sub[i])])
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_SS <- c(predicted_SS, q_var_sub[i])
# Fit the ridge regression model
model <- glmnet(x = x_var, y = y_var, alpha = 0)
# Perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
# Find optimal lambda
best_lambda <- cv_model$lambda.min
# Find coefficients for the best model
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
# Use fitted best model to make predictions (NOTE: not 100% sure about this)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
# Find SST and SSE
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
# Find R-squared of the model on the training data
rsq <- 1 - sse/sst
R2_SS <- c(R2_SS, rsq)
}
SxS <- data.frame(predicted = predicted_SS, predictors = predictors_SS,
predicted_type = predicted_type_SS, R2 = R2_SS)
# Task x task
predicted_TT <- c()
predicted_type_TT <- rep("task", length(t_var_log))
predictors_TT <- rep("tasks", length(t_var_log))
R2_TT <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(task_data[, -which(colnames(task_data) == t_var_log[i])])
y_var <- task_data[, t_var_log[i]]
predicted_TT <- c(predicted_TT, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TT <- c(R2_TT, rsq)
}
TxT <- data.frame(predicted = predicted_TT, predictors = predictors_TT,
predicted_type = predicted_type_TT, R2 = R2_TT)
# Survey x task (surveys predicted by tasks)
predicted_ST <- c()
predicted_type_ST <- rep("survey", length(q_var_sub))
predictors_ST <- rep("tasks", length(q_var_sub))
R2_ST <- c()
for (i in 1:length(q_var_sub)) {
x_var <- as.matrix(task_data)
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_ST <- c(predicted_ST, q_var_sub[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_ST <- c(R2_ST, rsq)
}
SxT <- data.frame(predicted = predicted_ST, predictors = predictors_ST,
predicted_type = predicted_type_ST, R2 = R2_ST)
# Tasks x surveys (tasks predicted by surveys)
predicted_TS <- c()
predicted_type_TS <- rep("task", length(t_var_log))
predictors_TS <- rep("surveys", length(t_var_log))
R2_TS <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(survey_data_sub)
y_var <- task_data[, t_var_log[i]]
predicted_TS <- c(predicted_TS, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TS <- c(R2_TS, rsq)
}
TxS <- data.frame(predicted = predicted_TS, predictors = predictors_TS,
predicted_type = predicted_type_TS, R2 = R2_TS)
# Bind the dataframes
R2_crossmethod <- rbind(SxS, TxT, SxT, TxS)
# Describe R^2 per group
R2_crossmethod <- R2_crossmethod %>%
mutate(format = case_when((predicted_type == "task" & predictors == "tasks")  ~ "TxT",
(predicted_type == "survey" & predictors == "surveys")  ~ "SxS",
(predicted_type == "task" & predictors == "surveys")  ~ "TxS",
(predicted_type == "survey" & predictors == "tasks")  ~ "SxT"))
R2_crossmethod$format <- as.factor(R2_crossmethod$format)
R2_crossmethod %>%
group_by(format) %>%
summarise(mean(R2), sd(R2))
# Visualize R^2 per group
# Same plot
ggplot(R2_crossmethod, aes(x = R2)) +
geom_histogram(aes(color = format, fill = format),
position = "identity", bins = 50) +
scale_color_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
scale_fill_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
theme_minimal()
# Separate plots
par(mfrow = c(2, 2))
formats <- c("SxS", "SxT", "TxT", "TxS")
for (i in 1:4) {
hist(R2_crossmethod[which(R2_crossmethod$format == formats[i]), "R2"],
main = paste0("R2 for ", formats[i]),
col = sample(colors(), 1),
breaks = 20,
xlab = "")
}
# A general note: we probably need to justify putting a bunch of task and self-report items in the same factor analysis / at least mention it !
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3268653/
# Descriptives
describe(data_efa)
# Create character strings with different classes of variables
# NOTE: do we actually want to treat ordinals as continuous? I think another option would be polytomous, but I am not sure; at least we should be consistent throughout the analyses
con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount", "GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum")
q_con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount")
cat <- c("HEscore", "HRscore")
# Create a correlation matrix (polychoric/mixed correlations)
all_cor <- mixedCor(data = data_efa, d = cat, c = con,
use = "pairwise.complete.obs",
method = "spearman")
Q_cor <- mixedCor(data = survey_data, d = cat, c = q_con,
use = "pairwise.complete.obs",
method = "spearman")
T_cor <- mixedCor(data = task_data,
use = "pairwise.complete.obs",
method = "pearson")
# NOTE: Caitlin had specified other arguments as well but I am not sure how necessary there are?
# Store correlation matrix
all_rho <- all_cor$rho
Q_rho <- Q_cor$rho
T_rho <- T_cor$rho
# Mean correlation across items
mean(abs(all_rho[lower.tri(all_rho)]))
mean(abs(Q_rho[lower.tri(Q_rho)]))
mean(abs(T_rho[lower.tri(T_rho)]))
# Histogram of correlations
hist(abs(all_rho[lower.tri(all_rho)]),
breaks = 20, col = sample(colors(), 1))
hist(abs(Q_rho[lower.tri(Q_rho)]),
breaks = 20, col = sample(colors(), 1))
hist(abs(T_rho[lower.tri(T_rho)]),
breaks = 20, col = sample(colors(), 1))
# Corrplot without titles
corrplot(all_rho, tl.pos = "n")
# Bartlett test (p<.05 indicates data are suitable for structure detection)
cortest.bartlett(all_rho, n = nrow(data_efa))
cortest.bartlett(Q_rho, n = nrow(survey_data))
cortest.bartlett(T_rho, n = nrow(task_data))
# Kaiser-Meyer-Olkin measure (>.7 is good)
sort(round(KMO(r = all_rho)$MSAi, 2))
sort(round(KMO(r = Q_rho)$MSAi, 2))
sort(round(KMO(r = T_rho)$MSAi, 2))
# NOTE: KMO is not very good for a lot of items?
# Scree plots
# All variables
plot(eigen(all_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# Questionnaire variables
plot(eigen(Q_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# Task variables
plot(eigen(T_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# NFactors
# All variables
nfactors(all_rho, n = 6, n.obs  = nrow(data_efa),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Questionnaires
nfactors(Q_rho, n = 6, n.obs  = nrow(survey_data),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Tasks
nfactors(T_rho, n = 6, n.obs  = nrow(task_data),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Parallel Analysis
# All variables
fa.parallel(all_rho, n.obs = nrow(data_efa), fm = "minrank")
# cor.plot(all_rho)
# Questionnaires
fa.parallel(Q_rho, n.obs = nrow(survey_data), fm = "minrank")
# cor.plot(Q_rho)
# Tasks
fa.parallel(T_rho, n.obs = nrow(task_data), fm = "minrank")
# cor.plot(T_rho)
# Questionnaires only
# EBIC: 4 factors
EFA_Q4 <- fa(Q_rho, nfactors = 4, rotate = "oblimin",
fm = "minrank", scores = "tenBerge")
fa.sort(EFA_Q4)
fa.sort(EFA_Q4)
survey_data_sub <- survey_data %>%
select(-c(c("HEscore")))
Q_rho_sub <- mixedCor(data = survey_data_sub,
d = c("HRscore"),
c = c("AMean", "CMean", "EMean", "ESMean", "OMean",  "ICuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_id", "MatrixCorrectCount", "sci_impo", "DCuriositySum"),
use = "pairwise.complete.obs",
method = "spearman")
Q_rho_sub <- Q_rho_sub$rho
EFA_Q4_sub <- fa(Q_rho_sub, nfactors = 4, rotate = "oblimin",
fm = "minrank", scores = "tenBerge")
fa.sort(EFA_Q4_sub)
fa.sort(EFA_Q4_sub)
survey_data_sub <- survey_data %>%
select(-c(c("HEscore")))
Q_rho_sub <- mixedCor(data = survey_data_sub,
d = c("HRscore"),
c = c("AMean", "CMean", "EMean", "ESMean", "OMean",  "ICuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_id", "MatrixCorrectCount", "sci_impo", "DCuriositySum", "clo_sum", "IH4sum"),
use = "pairwise.complete.obs",
method = "spearman")
Q_rho_sub <- mixedCor(data = survey_data_sub,
d = c("HRscore"),
c = c("AMean", "CMean", "EMean", "ESMean", "OMean",  "ICuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_id", "MatrixCorrectCount", "sci_impo", "DCuriositySum", "CloSum", "IH4Sum"),
use = "pairwise.complete.obs",
method = "spearman")
Q_rho_sub <- Q_rho_sub$rho
EFA_Q4_sub <- fa(Q_rho_sub, nfactors = 4, rotate = "oblimin",
fm = "minrank", scores = "tenBerge")
fa.sort(EFA_Q4_sub)
fa.sort(EFA_Q4_sub)
fa.sort(EFA_Q4)
survey_data_sub <- survey_data %>%
select(-c(c("HEscore")))
survey_data_sub <- survey_data %>%
select(-c(c("HEscore", "IH4Sum")))
Q_rho_sub <- mixedCor(data = survey_data_sub,
d = c("HRscore"),
c = c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount"),
use = "pairwise.complete.obs",
method = "spearman")
Q_rho_sub <- Q_rho_sub$rho
EFA_Q4_sub <- fa(Q_rho_sub, nfactors = 4, rotate = "oblimin",
fm = "minrank", scores = "tenBerge")
fa.sort(EFA_Q4_sub)
fa.sort(EFA_Q4_sub)
survey_data_sub <- survey_data %>%
select(-c(c("HEscore", "IH4Sum", "IH1Sum")))
Q_rho_sub <- mixedCor(data = survey_data_sub,
d = c("HRscore"),
c = c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH2Sum", "IH3Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount"),
use = "pairwise.complete.obs",
method = "spearman")
Q_rho_sub <- Q_rho_sub$rho
EFA_Q4_sub <- fa(Q_rho_sub, nfactors = 4, rotate = "oblimin",
fm = "minrank", scores = "tenBerge")
fa.sort(EFA_Q4_sub)
fa.sort(EFA_Q4_sub)
library(semPlot)
semPaths(EFA_Q4_sub)
install.packages("lavaanPlot")
install.packages("lavaanPlot")
fa.sort(EFA_Q4_sub)
