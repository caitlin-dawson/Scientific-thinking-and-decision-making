(predicted_type == "survey" & predictors == "surveys")  ~ "SxS",
(predicted_type == "task" & predictors == "surveys")  ~ "TxS",
(predicted_type == "survey" & predictors == "tasks")  ~ "SxT"))
R2_crossmethod$format <- as.factor(R2_crossmethod$format)
R2_crossmethod %>%
group_by(format) %>%
summarise(mean(R2), sd(R2))
# Visualize R^2 per group
# Same plot
ggplot(R2_crossmethod, aes(x = R2)) +
geom_histogram(aes(color = format, fill = format),
position = "identity", bins = 50) +
scale_color_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
scale_fill_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
theme_minimal()
# Separate plots
par(mfrow = c(2, 2))
formats <- c("SxS", "SxT", "TxT", "TxS")
for (i in 1:4) {
hist(R2_crossmethod[which(R2_crossmethod$format == formats[i]), "R2"],
main = paste0("R2 for ", formats[i]),
col = sample(colors(), 1),
breaks = 20,
xlab = "")
}
# Nicer visualizations?
# library(ISLR)
# library(glmnet)
# library(dplyr)
# library(tidyr)
# library(tidyverse)
# library(caret)
library(glmnet)
library(semPlot)
# library(tidyverse)
# library(tidyselect)
# library(psych)
# library(lavaan)
# library(dplyr)
# library(ggplot2)
# library(psychTools)
# library(GPArotation)
# library(devtools)
# library(apaTables)
# library(semPlot)
# library(sjPlot)
# library(glasso)
# Load data
data_efa <- read.csv("data_efa.csv")
# Create task- and survey-only sets
t_var_log <- c("GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum")
q_var <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "HEscore", "HRscore", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount")
survey_data <- data_efa[, q_var]
task_data <- data_efa[, t_var_log]
# Survey x survey
# NOTE: not sure if the binary items are an issue? not sure if this is the case when they are predictors but I would assume when they are being predicted? I will omit them here just in case
q_var_sub <- q_var[-c(which(q_var == "HEscore"), which(q_var == "HRscore"))]
survey_data_sub <- data_efa[, q_var_sub]
predicted_SS <- c()
predicted_type_SS <- rep("survey", length(q_var_sub))
predictors_SS <- rep("surveys", length(q_var_sub))
R2_SS <- c()
for (i in 1:length(q_var_sub)) {
# Save x and y
x_var <- as.matrix(survey_data_sub[, -which(colnames(survey_data_sub) == q_var_sub[i])])
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_SS <- c(predicted_SS, q_var_sub[i])
# Fit the ridge regression model
model <- glmnet(x = x_var, y = y_var, alpha = 0)
# Perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
# Find optimal lambda
best_lambda <- cv_model$lambda.min
# Find coefficients for the best model
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
# Use fitted best model to make predictions (NOTE: not 100% sure about this)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
# Find SST and SSE
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
# Find R-squared of the model on the training data
rsq <- 1 - sse/sst
R2_SS <- c(R2_SS, rsq)
}
SxS <- data.frame(predicted = predicted_SS, predictors = predictors_SS,
predicted_type = predicted_type_SS, R2 = R2_SS)
# Task x task
predicted_TT <- c()
predicted_type_TT <- rep("task", length(t_var_log))
predictors_TT <- rep("tasks", length(t_var_log))
R2_TT <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(task_data[, -which(colnames(task_data) == t_var_log[i])])
y_var <- task_data[, t_var_log[i]]
predicted_TT <- c(predicted_TT, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TT <- c(R2_TT, rsq)
}
TxT <- data.frame(predicted = predicted_TT, predictors = predictors_TT,
predicted_type = predicted_type_TT, R2 = R2_TT)
# Survey x task (surveys predicted by tasks)
predicted_ST <- c()
predicted_type_ST <- rep("survey", length(q_var_sub))
predictors_ST <- rep("tasks", length(q_var_sub))
R2_ST <- c()
for (i in 1:length(q_var_sub)) {
x_var <- as.matrix(task_data)
y_var <- survey_data_sub[, q_var_sub[i]]
predicted_ST <- c(predicted_ST, q_var_sub[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_ST <- c(R2_ST, rsq)
}
SxT <- data.frame(predicted = predicted_ST, predictors = predictors_ST,
predicted_type = predicted_type_ST, R2 = R2_ST)
# Tasks x surveys (tasks predicted by surveys)
predicted_TS <- c()
predicted_type_TS <- rep("task", length(t_var_log))
predictors_TS <- rep("surveys", length(t_var_log))
R2_TS <- c()
for (i in 1:length(t_var_log)) {
x_var <- as.matrix(survey_data_sub)
y_var <- task_data[, t_var_log[i]]
predicted_TS <- c(predicted_TS, t_var_log[i])
model <- glmnet(x = x_var, y = y_var, alpha = 0)
cv_model <- cv.glmnet(x = x_var, y = y_var, alpha = 0)
best_lambda <- cv_model$lambda.min
best_model <- glmnet(x = x_var, y = y_var, alpha = 0, lambda = best_lambda)
y_predicted <- predict(object = best_model, s = best_lambda, newx = x_var)
sst <- sum((y_var - mean(y_var))^2)
sse <- sum((y_predicted - y_var)^2)
rsq <- 1 - sse/sst
R2_TS <- c(R2_TS, rsq)
}
TxS <- data.frame(predicted = predicted_TS, predictors = predictors_TS,
predicted_type = predicted_type_TS, R2 = R2_TS)
# Bind the dataframes
R2_crossmethod <- rbind(SxS, TxT, SxT, TxS)
# Describe R^2 per group
R2_crossmethod <- R2_crossmethod %>%
mutate(format = case_when((predicted_type == "task" & predictors == "tasks")  ~ "TxT",
(predicted_type == "survey" & predictors == "surveys")  ~ "SxS",
(predicted_type == "task" & predictors == "surveys")  ~ "TxS",
(predicted_type == "survey" & predictors == "tasks")  ~ "SxT"))
R2_crossmethod$format <- as.factor(R2_crossmethod$format)
R2_crossmethod %>%
group_by(format) %>%
summarise(mean(R2), sd(R2))
# Visualize R^2 per group
# Same plot
ggplot(R2_crossmethod, aes(x = R2)) +
geom_histogram(aes(color = format, fill = format),
position = "identity", bins = 50) +
scale_color_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
scale_fill_manual(values = c("#9AC4F8", "#99EDCC", "#CB958E", "#E36588")) +
theme_minimal()
# Separate plots
par(mfrow = c(2, 2))
formats <- c("SxS", "SxT", "TxT", "TxS")
for (i in 1:4) {
hist(R2_crossmethod[which(R2_crossmethod$format == formats[i]), "R2"],
main = paste0("R2 for ", formats[i]),
col = sample(colors(), 1),
breaks = 20,
xlab = "")
}
# Nicer visualizations?
# A general note: we probably need to justify putting a bunch of task and self-report items in the same factor analysis / at least mention it !
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3268653/
# Descriptives
describe(data_efa)
# Create character strings with different classes of variables
# NOTE: do we actually want to treat ordinals as continuous? I think another option would be polytomous, but I am not sure; at least we should be consistent throughout the analyses
con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount", "GNGdprime", "GNGbetalog", "MeanGoRT", "SDGoRTlog", "GlobalToLocalPrecedencelog", "GlobalToLocalInterferencelog", "NeckerTotalRatelog", "FlexSum")
q_con <- c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICuriositySum", "DCuriositySum", "IH1Sum", "IH2Sum", "IH3Sum", "IH4Sum", "CloSum", "CogSum", "AOTSum", "RPSum", "sci_cur", "sci_tru", "sci_impo", "sci_id", "MatrixCorrectCount")
cat <- c("HEscore", "HRscore")
# Create a correlation matrix (polychoric/mixed correlations)
all_cor <- mixedCor(data = data_efa, d = cat, c = con,
use = "pairwise.complete.obs",
method = "spearman")
Q_cor <- mixedCor(data = survey_data, d = cat, c = q_con,
use = "pairwise.complete.obs",
method = "spearman")
T_cor <- mixedCor(data = task_data,
use = "pairwise.complete.obs",
method = "pearson")
# NOTE: Caitlin had specified other arguments as well but I am not sure how necessary there are?
# Store correlation matrix
all_rho <- all_cor$rho
Q_rho <- Q_cor$rho
T_rho <- T_cor$rho
# Mean correlation across items
mean(abs(all_rho[lower.tri(all_rho)]))
mean(abs(Q_rho[lower.tri(Q_rho)]))
mean(abs(T_rho[lower.tri(T_rho)]))
# Histogram of correlations
hist(abs(all_rho[lower.tri(all_rho)]),
breaks = 20, col = sample(colors(), 1))
hist(abs(Q_rho[lower.tri(Q_rho)]),
breaks = 20, col = sample(colors(), 1))
hist(abs(T_rho[lower.tri(T_rho)]),
breaks = 20, col = sample(colors(), 1))
# Corrplot without titles
corrplot(all_rho, tl.pos = "n")
# Bartlett test (p<.05 indicates data are suitable for structure detection)
cortest.bartlett(all_rho, n = nrow(data_efa))
cortest.bartlett(Q_rho, n = nrow(survey_data))
cortest.bartlett(T_rho, n = nrow(task_data))
# Kaiser-Meyer-Olkin measure (>.7 is good)
sort(round(KMO(r = all_rho)$MSAi, 2))
sort(round(KMO(r = Q_rho)$MSAi, 2))
sort(round(KMO(r = T_rho)$MSAi, 2))
# NOTE: KMO is not very good for a lot of items?
# Scree plots
# All variables
plot(eigen(all_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# Questionnaire variables
plot(eigen(Q_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# Task variables
plot(eigen(T_rho)$values, type = "b", pch = 20, col = "red",
main = "Scree Plot", ylab = "Eigenvalues",
xlab = "No. Factors")
# NFactors
# All variables
nfactors(all_rho, n = 6, n.obs  = nrow(data_efa),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Questionnaires
nfactors(Q_rho, n = 6, n.obs  = nrow(survey_data),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Tasks
nfactors(T_rho, n = 6, n.obs  = nrow(task_data),
rotate = "oblimin", diagonal = FALSE,
fm = "minrank")
# Parallel Analysis
# All variables
fa.parallel(all_rho, n.obs = nrow(data_efa), fm = "minrank")
# cor.plot(all_rho)
# Questionnaires
fa.parallel(Q_rho, n.obs = nrow(survey_data), fm = "minrank")
# cor.plot(Q_rho)
# Tasks
fa.parallel(T_rho, n.obs = nrow(task_data), fm = "minrank")
# cor.plot(T_rho)
# 4-factor model
f4 <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + EMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH1Sum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HEscore + HRscore + RPSum + sci_cur + sci_tru + sci_impo + sci_id + MatrixCorrectCount'
# Fit the model
efa_f4 <- cfa(model = f4,
data = survey_data,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HEscore", "HRscore", "RPSum"))
summary(efa_f4, fit.measures = TRUE)
parameterEstimates(efa_f4)
fitmeasures(efa_f4)
# Look at loadings
loadings_4f <- inspect(efa_f4, what = "std")[["lambda"]]
fa.diagram(inspect(efa_f4, what = "std")[["lambda"]])
loadings_4f <- as.data.frame(loadings_4f)
round(fa.sort(loadings_4f), 2)
survey_data_sub <- survey_data %>%
select(-c("EMean", "sci_tru", "HEscore"))
f4_sub <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH1Sum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HRscore + RPSum + sci_cur + sci_impo + sci_id + MatrixCorrectCount'
# Fit the model
efa_f4_sub <- cfa(model = f4_sub,
data = survey_data_sub,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HRscore", "RPSum"))
summary(efa_f4_sub, fit.measures = TRUE)
parameterEstimates(efa_f4_sub)
fitmeasures(efa_f4_sub)
loadings_4f_sub <- inspect(efa_f4_sub, what = "std")[["lambda"]]
fa.diagram(inspect(efa_f4_sub, what = "std")[["lambda"]])
loadings_4f_sub <- as.data.frame(loadings_4f_sub)
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f), 2)
round(fa.sort(loadings_4f), 2)
survey_data_sub <- survey_data %>%
select(-c("EMean", "HEscore"))  # sci_tru?
f4_sub <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH1Sum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HRscore + RPSum + sci_cur + sci_impo + sci_id + sci_tru + MatrixCorrectCount'
# Fit the model
efa_f4_sub <- cfa(model = f4_sub,
data = survey_data_sub,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HRscore", "RPSum"))
summary(efa_f4_sub, fit.measures = TRUE)
parameterEstimates(efa_f4_sub)
fitmeasures(efa_f4_sub)
loadings_4f_sub <- inspect(efa_f4_sub, what = "std")[["lambda"]]
fa.diagram(inspect(efa_f4_sub, what = "std")[["lambda"]])
loadings_4f_sub <- as.data.frame(loadings_4f_sub)
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f_sub), 2)
survey_data_sub <- survey_data %>%
select(-c("EMean", "HEscore", "IH1Sum"))  # sci_tru? IH1 happens 2nd round
f4_sub <- '
efa("efa")*f1 +
efa("efa")*f2 +
efa("efa")*f3 +
efa("efa")*f4 =~ AMean + CMean + ESMean + OMean + ICuriositySum + DCuriositySum + IH2Sum + IH3Sum + IH4Sum + CloSum  +  CogSum + AOTSum + HRscore + RPSum + sci_cur + sci_impo + sci_id + sci_tru + MatrixCorrectCount'
# Fit the model
efa_f4_sub <- cfa(model = f4_sub,
data = survey_data_sub,
rotation = "oblimin",
estimator = "WLSMV",
ordered = c("HRscore", "RPSum"))
summary(efa_f4_sub, fit.measures = TRUE)
parameterEstimates(efa_f4_sub)
fitmeasures(efa_f4_sub)
loadings_4f_sub <- inspect(efa_f4_sub, what = "std")[["lambda"]]
fa.diagram(inspect(efa_f4_sub, what = "std")[["lambda"]])
loadings_4f_sub <- as.data.frame(loadings_4f_sub)
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f_sub), 2)
# Visualize
# 22 items, 4 factors
# Create layout matrix (42 nodes altogether)
y <- c(rep(c(-0.9, -0.8), length.out = 22), # items
rep(0, 4)) # latents
x <- c(seq(from = -0.98, to = 0.98, length.out = 22), # items
-0.75, -0.25, 0.25, 0.75)
# Visualize
# 22 items, 4 factors
# Create layout matrix (42 nodes altogether)
y <- c(rep(c(-0.9, -0.8), length.out = 19), # items
rep(0, 4)) # latents
x <- c(seq(from = -0.98, to = 0.98, length.out = 19), # items
-0.75, -0.25, 0.25, 0.75)
coord <- matrix(data = c(x, y), nrow = 23, ncol = 2, byrow = FALSE)
semPaths(efa_f4_sub,
what = "est",
whatLabels = "no",
as.expression = c("nodes", "edges"),
theme = "colorblind",
curvePivot = TRUE,
sizeMan = 3,
sizeLat = 7,
edge.label.cex = 1,
reorder = FALSE,
width = 8,
height = 5,
groups = "latents",
borders = FALSE,
residuals = FALSE,
intercepts = FALSE,
thresholds = FALSE,
label.prop = .96,
label.scale = TRUE,
color = c(rep("#bfbfbf", 4)),
layout = coord,
exoCov = FALSE,
nodeLabels = c("AMean", "CMean", "EMean", "ESMean", "OMean", "ICur", "DCur", "IH1", "IH2", "IH3", "IH4", "Clo ", " Cog", "AOT", "HE", "HR", "RP", "sci_cur", "sci_tru", "sci_impo", "sci_id", "Mat_rea", "F1", "F2", "F3", "F4"),
filename = "4f_pathdiagram",
filetype = "pdf")
coord
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f_sub), 2)
round(fa.sort(loadings_4f_sub), 2)
semPaths(efa_f4_sub,
what = "est",
whatLabels = "no",
as.expression = c("nodes", "edges"),
theme = "colorblind",
curvePivot = TRUE,
sizeMan = 3,
sizeLat = 7,
edge.label.cex = 1,
reorder = FALSE,
width = 8,
height = 5,
groups = "latents",
borders = FALSE,
residuals = FALSE,
intercepts = FALSE,
thresholds = FALSE,
label.prop = .96,
label.scale = TRUE,
color = c(rep("#bfbfbf", 4)),
layout = coord,
exoCov = FALSE,
nodeLabels = c("AMean", "CMean", "ESMean", "OMean", "ICur", "DCur", "IH2", "IH3", "IH4", "Clo ", " Cog", "AOT", "HR", "RP", "sci_cur", "sci_tru", "sci_impo", "sci_id", "Mat_rea", "F1", "F2", "F3", "F4"),
filename = "4f_pathdiagram",
filetype = "pdf")
?semPaths
efa_f4_sub
loadings_4f_sub
class(loadings_4f_sub)
corrplot(loadings_4f_sub, method = "color",
addCoef.col = "black", number.cex = .75,
tl.col = "black", cl.pos = "b",
cl.length = 4)
corrplot(loadings_4f_sub)
type(loadings_4f_sub)
??type
corrplot(round(loadings_4f_sub), 2)
heatmap(loadings_4f_sub)
# THIS DOES NOT WORK FOR US YET! Need to figure out why
# obtain factor loadings and add them to data
loading_mat <- as.matrix(loadings_4f_sub)
heatmap(loading_mat)
corrplot(loading_mat)
corrplot(loading_mat, method = "color",
addCoef.col = "black", number.cex = .75,
tl.col = "black", cl.pos = "b",
cl.length = 4)
corrplot(loading_mat, method = "color",
addCoef.col = "black", number.cex = .75,
tl.col = "black", cl.pos = "b",
cl.length = 4)
corrplot(loading_mat, method = "color")
corrplot(loading_mat, method = "color")
corrplot(loading_mat, method = "color",
addCoef.col = "black",
# number.cex = .75,
# tl.col = "black", cl.pos = "b",
# cl.length = 4
)
corrplot(loading_mat, method = "color",
addCoef.col = "black",
# number.cex = .75,
# tl.col = "black", cl.pos = "b",
# cl.length = 4
)
corrplot(loading_mat, method = "color",
addCoef.col = "black",
number.cex = .75,
# tl.col = "black", cl.pos = "b",
# cl.length = 4
)
corrplot(loading_mat, method = "color",
addCoef.col = "black",
number.cex = .75,
tl.col = "black", cl.pos = "b",
# cl.length = 4
)
?corrplot
corrplot(loading_mat, method = "color",
addCoef.col = NULL,
number.cex = .75,
tl.col = "black",
cl.pos = "b",
cl.length = 4
)
names(loading_mat)
loading_mat
rownames(loading_mat)
round(fa.sort(loadings_4f_sub), 2)
# THIS DOES NOT WORK FOR US YET! Need to figure out why
# obtain factor loadings and add them to data
loading_mat <- as.matrix(fa.sort(loadings_4f_sub))
corrplot(loading_mat, method = "color",
addCoef.col = NULL,
number.cex = .75,
tl.col = "black",
cl.pos = "b",
cl.length = 4
)
loading_mat <- as.array(fa.sort(loadings_4f_sub))
fa.sort(loadings_4f_sub)
loading_mat <- as.array(fa.sort(loadings_4f_sub)[, -ncol(loadings_4f_sub)])
loadings_4f_sub
fa.sort(loadings_4f_sub)
loading_mat <- as.matrix(fa.sort(loadings_4f_sub))
loading_mat <- loading_mat[, -ncol(loading_mat)]
loading_mat
corrplot(loading_mat, method = "color",
addCoef.col = NULL,
number.cex = .75,
tl.col = "black",
cl.pos = "b",
cl.length = 4
)
corrplot(loading_mat, method = "color",
addCoef.col = NULL,
number.cex = .75,
tl.col = "black",
cl.pos = "b",
cl.length = 4
)
