---
title: "Citizen's Initiative Draft Code"
author: "Caitlin Dawson"
date: "15 6 2022"
output: html_document
---

# Notes

This is a draft version of code to format and process data from the Citizen's Initiative Task, meant to be combined with the full code Notebook after testing.

Notes: 
Last edited 15.6.2022 by Caitlin. Takes data downloaded from Gorilla in **blinded, semicolon separater, csv format, short form**, versions 22-25.

Version history: 
*version 23: HJ updated the experiment (a source was deleted from CI task so this version has only 5 sources. The Viiskunta source was taken down so we could not get a stable URL for it.)
*version 24: HJ updated CI task to include all 6 sources again, Viiskunta source as an image
*version 25: changes made elsewhere, CI is same as version 24

- Missing data needs to be replaced with NA
- version 22 has the full set of 6 links
- version 23 has fewer rows per ppt because of only 5 sources. All sources are links. 
- versions 24 and 25 have all sources but one source as a PDF. Find the source implementation in the column 'display'

# Check the Validity and Demographics

This chunk removes nonvalid participants according to the validity check and language exclusion criteria.

```{r Load Data, include=FALSE}

# Exclude nonvalid participants
data_citiT <- merge(data_citiT, data_ConsentValidity, 
                    by = "Participant.Private.ID")

# Validity/languege filter + select relevant columns
data_citiT <- data_citiT %>%
  filter(Validity.quantised %in% c(1, NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>% 
  select(Participant.Private.ID, Spreadsheet.Row:Reaction.Time, Response, display, Text, Source_topic)

# Remove the Instructions/Finish rows
data_citiT <- data_citiT %>%
  filter(display != "Instructions" & display!= "Finish")

```

# Code Source Types

```{r Code Source Types}

# Add a column to code the source authority: 1=Authority, 2=Personal
data_citiT <- data_citiT %>%
  mutate(source_authority = case_when((Source_topic == "Turvetuotanto on ajettava alas â€“ oikeudenmukaisesti") ~ 1,
                                      (Source_topic == "Suo syntyy uudestaan") ~ 1,
                                      (Source_topic == "Palaako peltoviljely pÃ¤Ã¤osin kangasmaille?") ~ 1,
                                      (Source_topic == "Punnittua puhetta turpeesta") ~ 2,
                                      (Source_topic == "Turve on uusiutuva luonnonvara") ~ 2,
                                      (Source_topic == "Auttaa akneen, reumaan, selluliittiin ja hiustenlÃ¤htÃ¶Ã¶n â€“ mikÃ¤ se on?") ~ 2))

# Add a column to code the source quality: 1=Reliable, 2=Unreliable, 3=irrelevant
data_citiT <- data_citiT %>%
  mutate(source_quality = case_when((Source_topic == "Turvetuotanto on ajettava alas â€“ oikeudenmukaisesti") ~ 1,
                                    (Source_topic == "Suo syntyy uudestaan") ~ 2,
                                    (Source_topic == "Palaako peltoviljely pÃ¤Ã¤osin kangasmaille?") ~ 3,
                                    (Source_topic == "Punnittua puhetta turpeesta") ~ 1,
                                    (Source_topic == "Turve on uusiutuva luonnonvara") ~ 2,
                                    (Source_topic == "Auttaa akneen, reumaan, selluliittiin ja hiustenlÃ¤htÃ¶Ã¶n â€“ mikÃ¤ se on?") ~ 3))

```

# Extract Reaction Times

```{r Extract Reaction Times}

# Extract reaction time for the entire task to a different df
data_citiT_RTs <- data_citiT %>% 
  filter(Trial.Number == "END TASK") %>% 
  select(Participant.Private.ID, Reaction.Time)
names(data_citiT_RTs)[2] <- "overall_rt"

# Remove BEGIN TASK and END TASK rows from df
data_citiT <- data_citiT %>% 
  filter(!Trial.Number %in% c("END TASK", "BEGIN TASK"))

# Extract reaction times for each source
# NOTE: NOT SURE ABOUT THIS
# Baseline SAM and 4 baseline topic questions (about the petition) coded as order = 1; Rest of the trials coded based on Source_topic so that order numbers always refer to the same source
data_citiT <- data_citiT %>% 
  mutate(Order = case_when((Source_topic == "") ~ 1,
                           (Source_topic == "Auttaa akneen, reumaan, selluliittiin ja hiustenlÃ¤htÃ¶Ã¶n â€“ mikÃ¤ se on?") ~ 2,
                           (Source_topic == "Palaako peltoviljely pÃ¤Ã¤osin kangasmaille?") ~ 3,
                           (Source_topic == "Punnittua puhetta turpeesta") ~ 4,
                           (Source_topic == "Suo syntyy uudestaan") ~ 5,
                           (Source_topic == "Turve on uusiutuva luonnonvara") ~ 6,
                           (Source_topic == "Turvetuotanto on ajettava alas â€“ oikeudenmukaisesti") ~ 7))
data_citiT_srcRTs <- data_citiT %>% 
  filter(Zone.Name == "advancementZone") %>% 
  select(Participant.Private.ID, Order, Reaction.Time)
names(data_citiT_srcRTs)[3] <- "src_rt"

# Combine overall RTs and source RTs
data_citiT_RTs <- merge(data_citiT_RTs, data_citiT_srcRTs,
                        by = "Participant.Private.ID",
                        all = TRUE)

# Extract reaction times for the questions
data_citiT_likertRTs <- data_citiT %>% 
  filter(Zone.Type != "continue_button") %>% 
  select(Participant.Private.ID, Reaction.Time, Zone.Type)
# NOTE: what do we want to know about these?

```

# Recode the SAM Responses as Likert Intensity and Valence Scores

Recode the SAM responses as Likert intensity and valence scores and add a line to extract the relevant rows, e.g. emotional state associated with the source topic, authority and quality. Add that to the reading time df.

```{r Recode the SAM + Petition + Source Responses}

# SAM intensity
data_citiT <- data_citiT %>%
  mutate(SAMintensity = case_when((Response == "SAM_1.1.PNG") ~ 1,
                                  (Response == "SAM_1.2.PNG") ~ 2,
                                  (Response == "SAM_1.3.PNG") ~ 3,
                                  (Response == "SAM_1.4.PNG") ~ 4,
                                  (Response == "SAM_1.5.PNG") ~ 5,
                                  (Response == "SAM_1.6.PNG") ~ 6,
                                  (Response == "SAM_1.7.PNG") ~ 7,
                                  (Response == "SAM_1.8.PNG") ~ 8,
                                  (Response == "SAM_1.9.PNG") ~ 9))

# SAM valence
data_citiT <- data_citiT %>%
  mutate(SAMvalence = case_when((Response == "SAM_2.1.PNG") ~ 1,
                                (Response == "SAM_2.2.PNG") ~ 2,
                                (Response == "SAM_2.3.PNG") ~ 3,
                                (Response == "SAM_2.4.PNG") ~ 4,
                                (Response == "SAM_2.5.PNG") ~ 5,
                                (Response == "SAM_2.6.PNG") ~ 6,
                                (Response == "SAM_2.7.PNG") ~ 7,
                                (Response == "SAM_2.8.PNG") ~ 8,
                                (Response == "SAM_2.9.PNG") ~ 9))

# Curiosity (petition)
data_citiT <- data_citiT %>%
  mutate(Curiosity = case_when((Response == "En ollenkaan uteliaasti") ~ 1,
                               (Response == "Hiukan uteliaasti") ~ 2,
                               (Response == "Jokseenkin uteliaasti") ~ 3,
                               (Response == "Hyvin uteliaasti") ~ 4,
                               (Response == "ErittÃ¤in uteliaasti") ~ 5))

# Interest (petition)
data_citiT <- data_citiT %>%
  mutate(Interest = case_when(((Response == "Ei ollenkaan kiinnostava") | 
                              (Response == "En ollenkaan kiinnostavana")) ~ 1,
                              ((Response == "Hiukan kiinnostava") | 
                              (Response == "Hiukan kiinnostavana")) ~ 2,
                              ((Response == "Jokseenkin kiinnostava") | 
                              (Response == "Jokseenkin kiinnostavana")) ~ 3,
                              ((Response == "Hyvin kiinnostava") | 
                              (Response == "Hyvin kiinnostavana")) ~ 4,
                              ((Response == "ErittÃ¤in kiinnostava") | 
                              (Response == "ErittÃ¤in kiinnostavana")) ~ 5))

# Familiar (petition)
data_citiT <- data_citiT %>%
  mutate(Familiarity = case_when((Response == "Ei ollenkaan tuttu") ~ 1,
                                 (Response == "Hiukan tuttu") ~ 2,
                                 (Response == "Jokseenkin tuttu") ~ 3,
                                 (Response == "Hyvin tuttu") ~ 4,
                                 (Response == "ErittÃ¤in tuttu") ~ 5))
# Support (petition)
data_citiT <- data_citiT %>%
  mutate(Support = case_when(((Response == "Varmasti en" & display == "Reading" & Screen.Name == "Screen 11") | (Response == "Varmasti en" & display == "Initial_assessment" & Screen.Name == "Screen 1") | (Response == "Varmasti en" & display == "PDF" & Screen.Name == "Screen 8")) ~ 1,
                                  ((Response == "Luultavasti en" & display == "Reading" & Screen.Name == "Screen 11") | (Response == "Luultavasti en" & display == "Initial_assessment" & Screen.Name == "Screen 1") | (Response == "Luultavasti en" & display == "PDF" & Screen.Name == "Screen 8")) ~ 2,
                                  ((Response == "En osaa sanoa" & display == "Reading" & Screen.Name == "Screen 11") | (Response == "En osaa sanoa" & display == "Initial_assessment" & Screen.Name == "Screen 1") | (Response == "En osaa sanoa" & display == "PDF" & Screen.Name == "Screen 8")) ~ 3,
                                  ((Response == "Luultavasti kyllÃ¤" & display == "Reading" & Screen.Name == "Screen 11") | (Response == "Luultavasti kyllÃ¤" & display == "Initial_assessment" & Screen.Name == "Screen 1") | (Response == "Luultavasti kyllÃ¤" & display == "PDF" & Screen.Name == "Screen 8")) ~ 4,
                                  ((Response == "Varmasti kyllÃ¤" & display == "Reading" & Screen.Name == "Screen 11") | (Response == "Varmasti kyllÃ¤" & display == "Initial_assessment" & Screen.Name == "Screen 1") | (Response == "Varmasti kyllÃ¤" & display == "PDF" & Screen.Name == "Screen 8")) ~ 5))

# Shareability (source)
data_citiT <- data_citiT %>%
  mutate(Shareability = case_when(((Response == "Varmasti en" & display == "Reading" & Screen.Name == "Screen 2") | (Response == "Varmasti en" & display == "PDF" & Screen.Name == "Screen 7")) ~ 1,
                                      ((Response == "Luultavasti en" & display == "Reading" & Screen.Name == "Screen 2") | (Response == "Luultavasti en" & display == "PDF" & Screen.Name == "Screen 7")) ~ 2,
                                      ((Response == "En osaa sanoa" & display == "Reading" & Screen.Name == "Screen 2") | (Response == "En osaa sanoa" & display == "PDF" & Screen.Name == "Screen 7")) ~ 3,
                                      ((Response == "Luultavasti kyllÃ¤" & display == "Reading" & Screen.Name == "Screen 2") | (Response == "Luultavasti kyllÃ¤" & display == "PDF" & Screen.Name == "Screen 7")) ~ 4,
                                      ((Response == "Varmasti kyllÃ¤" & display == "Reading" & Screen.Name == "Screen 2") | (Response == "Varmasti kyllÃ¤" & display == "PDF" & Screen.Name == "Screen 7")) ~ 5))

# Convincingness (source)
data_citiT <- data_citiT %>%
  mutate(Convincingness = case_when((Response == "Ei ollenkaan vakuuttava") ~ 1,
                                    (Response == "Ei vakuuttava") ~ 2,
                                    (Response == "Neutraali") ~ 3,
                                    (Response == "Vakuuttava") ~ 4,
                                    (Response == "ErittÃ¤in vakuuttava") ~ 5))

# Expertise (source)
data_citiT <- data_citiT %>%
  mutate(Expertise = case_when((Response == "Ei ollenkaan") ~ 1,
                               (Response == "VÃ¤hÃ¤n") ~ 2,
                               (Response == "Jonkin verran") ~ 3,
                               (Response == "Paljon") ~ 4,
                               (Response == "Hyvin paljon") ~ 5))

# Reliability (source)
data_citiT <- data_citiT %>%
  mutate(Reliability = case_when((Response == "ErittÃ¤in epÃ¤luotettava") ~ 1,
                                 (Response == "EpÃ¤luotettava") ~ 2,
                                 (Response == "Ei epÃ¤luotettava eikÃ¤ luotettava") ~ 3,
                                 (Response == "Luotettava") ~ 4,
                                 (Response == "ErittÃ¤in luotettava") ~ 5))

# Extract relevant information per participant per source
data_citiT_ratings <- data_citiT %>% 
  group_by(Participant.Private.ID, Order) %>% 
  summarise(SAMintensity_final = mean(SAMintensity, na.rm = TRUE),
            SAMvalence_final = mean(SAMvalence, na.rm = TRUE),
            Curiosity_pet = mean(Curiosity, na.rm = TRUE),
            Interest_pet = mean(Interest, na.rm = TRUE),
            Familiarity_pet = mean(Familiarity, na.rm = TRUE),
            Support_pet = mean(Support, na.rm = TRUE),
            Shareability_src = mean(Shareability, na.rm = TRUE),
            Convincingness_src = mean(Convincingness, na.rm = TRUE),
            Expertise_src = mean(Expertise, na.rm = TRUE),
            Reliability_src = mean(Reliability, na.rm = TRUE))

# Replace NaNs with NAs
data_citiT_ratings[is.nan(data_citiT_ratings)] <- NA

# Check row sum NAs
colSums(is.na(data_citiT_ratings))
# source columns should have 174 NAs except for reliability, which can have more as the participant could skip the Likert scale and only respond to the open question; the petition columns should not have any missing values

# Extract qualitative data: reason for rating, with source rating variables
data_citiT_reasons <- data_citiT %>%
  select(Participant.Private.ID, Source_topic, source_authority, source_quality, Reliability, Expertise, Convincingness, Shareability, Support, Zone.Type, Response) %>%
  filter(Zone.Type == "response_text_area")

```

# Reading Times

This section excludes data points based on reaction time and investigates RT in linked sources vs. pdf source. Lower threshold set as 150 for cognitive processing, same as other tasks. 

RT data has issues for outlier removal due to the distribution, not sure yet the best method for this kind of task. We don't set an automatic upper limit and we cannot assume that the reading times represent a single cognitive process. However, I don't think we can keep all times in, since they range from one second to over an hour, with the mean around 3 minutes. The goal should be to capture as much valid data as possible, with the acknowledgement that times e.g. 1 second are valid but mean something different than longer times, e.g. someone has skimmed or skipped that source. 

- should we look into the thresholds for skimming and reading comprehension to make a point about which times we can expect to mean actually reading and which are skipping? 
- it is clear where obviously meaningless long outliers are in this data, but the question is how to justify their removal 
- can reading times be analyzed like reaction times, or is there another way? 


```{r Reading Times, include = FALSE}

# just the same source as the pdf
reading_reactiontime <- data_citiT %>%
  filter(display == "Reading" & Zone.Name == "advancementZone" & Source_topic == "Turve on uusiutuva luonnonvara")

Q1 <- quantile(reading_reactiontime$Reaction.Time, 0.25,na.rm=TRUE)
Q3 <- quantile(reading_reactiontime$Reaction.Time, 0.75,na.rm=TRUE)
range <- (IQR(reading_reactiontime$Reaction.Time,na.rm=TRUE)*1.5)
lowbound <- (Q1 - range)
highbound <- (Q3 + range)
summary(reading_reactiontime$Reaction.Time)
lowbound
highbound

reading_reactiontime$Reaction.Time[which(reading_reactiontime$Reaction.Time > 362246 )] <- NA #this is the IQR threshold
reading_reactiontime$Reaction.Time[which(reading_reactiontime$Reaction.Time < 150 )] <- NA

plot(reading_reactiontime$Reaction.Time)
hist(reading_reactiontime$Reaction.Time)

######################################################
#pdfs
PDF_reactiontime <- data_citiT %>%
  filter(display == "PDF" & Screen.Name == "Screen 12")

Q1 <- quantile(PDF_reactiontime$Reaction.Time, 0.25,na.rm=TRUE)
Q3 <- quantile(PDF_reactiontime$Reaction.Time, 0.75,na.rm=TRUE)
range <- (IQR(PDF_reactiontime$Reaction.Time,na.rm=TRUE)*1.5)
lowbound <- (Q1 - range)
highbound <- (Q3 + range)
summary(PDF_reactiontime$Reaction.Time)
lowbound
highbound

PDF_reactiontime$Reaction.Time[which(PDF_reactiontime$Reaction.Time > 365674 )] <- NA
PDF_reactiontime$Reaction.Time[which(PDF_reactiontime$Reaction.Time < 150 )] <- NA 

plot(PDF_reactiontime$Reaction.Time)
hist(PDF_reactiontime$Reaction.Time)

wilcox.test(reading_reactiontime$Reaction.Time, PDF_reactiontime$Reaction.Time, alternative = "two.sided")

par(mfrow = c(1, 2))
boxplot(reading_reactiontime$Reaction.Time)
boxplot(PDF_reactiontime$Reaction.Time)

###################################################
#overall RT outlier exclusion

#select reaction time data associated with reading the articles
all_reactiontime <- data_citiT %>%
  filter(display == "Reading" & Zone.Name == "advancementZone" | display == "PDF" & Screen.Name == "Screen 12")


#links
Q1 <- quantile(all_reactiontime$Reaction.Time, 0.25,na.rm=TRUE)
Q3 <- quantile(all_reactiontime$Reaction.Time, 0.75,na.rm=TRUE)
range <- (IQR(all_reactiontime$Reaction.Time,na.rm=TRUE)*1.5)
lowbound <- (Q1 - range)
highbound <- (Q3 + range)
summary(all_reactiontime$Reaction.Time)
lowbound
highbound

all_reactiontime$Reaction.Time[which(all_reactiontime$Reaction.Time > 486923 )] <- NA 
all_reactiontime$Reaction.Time[which(all_reactiontime$Reaction.Time < 150 )] <- NA

plot(all_reactiontime$Reaction.Time)
hist(all_reactiontime$Reaction.Time)


boxplot(all_reactiontime$Reaction.Time~all_reactiontime$source_quality)
boxplot(all_reactiontime$Reaction.Time~all_reactiontime$source_authority)
boxplot(all_reactiontime$Reaction.Time~all_reactiontime$Source_topic)

wilcox.test(all_reactiontime$Reaction.Time~all_reactiontime$source_authority, alternative = "two.sided")

plot(all_reactiontime$Participant.Private.ID,all_reactiontime$medianRT)

all_reactiontime <- all_reactiontime %>%
  group_by(Participant.Private.ID) %>%
  mutate(medianRT = median(Reaction.Time, na.rm = TRUE))

plot(all_reactiontime$Participant.Private.ID,all_reactiontime$medianRT)
hist(all_reactiontime$medianRT)
```




#Missing data and participant exclusions

NB: there is no missing data in the CI task per se. We only kept data if a participant at least completed the whole CI task. 

```{r}


cor.test(all_reactiontime$Age,all_reactiontime$Reaction.Time,method="spearman",exact=FALSE)
cor.test(all_reactiontime$gender,all_reactiontime$Reaction.Time,method="spearman",exact=FALSE)
cor.test(all_reactiontime$Education,all_reactiontime$Reaction.Time,method="spearman",exact=FALSE)






```






