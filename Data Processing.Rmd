---
title: "Data Processing"
author: "Milla Pihlajamaki and Caitlin Dawson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

#Notes: 
Last edited 23.6.2022 by Caitlin
takes data downloaded from Gorilla **blinded, semicolon separater, csv format, short form**
cleans and processes data for the study 'Scientific thinking and decision-making in everyday life'

Version history: 
*version 22: Links fixed in information and consent
*version 23: HJ updated the experiment (source deleted from CI task--only 5 sources because of trouble getting a stable URL; Viiskunta source was taken down)
*version 24: HJ updated CI task to include all 6 sources again, one of them as image
*version 25: HJ. Word adult taken off from Study Information and Content


# Loading packages

```{r Loading packages, include=FALSE}

library(tidyverse)
library(psych)
library(lavaan)
library(dplyr)
library(ggplot2)
library(psycho)
library(tidyr)
library(GPArotation)
library(car)

```


# Loading data 

```{r Loading data,  include=FALSE}

#Versions 22-25 are included
data_epistemicQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-2wlk.csv', sep = ";")
data_heuristicQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-79hv.csv', sep = ";")
data_openminded.thinkingQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-7qsg.csv', sep = ";")
data_validityQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-81k4.csv', sep = ";")
data_demographicsQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-c7cw.csv', sep = ";")
data_science.attitudesQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-cl1u.csv', sep = ";")
data_need.cognitionQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-eygv.csv', sep = ";")
data_science.curiosityQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-go4a.csv', sep = ";")
data_need.closureQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-mz16.csv', sep = ";")
data_studyinfoQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-o43u.csv', sep = ";")
data_randomness.probabilityQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-otb8.csv', sep = ";")
data_intellectual.humilityQ_v22 <- read.csv('data_exp_55551-v22_questionnaire-oyla.csv', sep = ";")
data_big5Q_v22 <- read.csv('data_exp_55551-v22_questionnaire-w8n1.csv', sep = ";")
data_unusual.usesT_v22 <- read.csv('data_exp_55551-v22_task-7mar.csv', sep = ";")
data_NavonT_v22 <- read.csv('data_exp_55551-v22_task-8mu5.csv', sep = ";")
data_NeckerT_v22 <- read.csv('data_exp_55551-v22_task-9nll.csv', sep = ";")
data_go.nogoT_v22 <- read.csv('data_exp_55551-v22_task-n8ns.csv', sep = ";")
data_matrix.reasoningT_v22 <- read.csv('data_exp_55551-v22_task-tg12.csv', sep = ";")
data_citizen.initiativeT_v22 <- read.csv('data_exp_55551-v22_task-zryk.csv', sep = ";")

data_epistemicQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-2wlk.csv', sep = ";")
data_heuristicQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-79hv.csv', sep = ";")
data_openminded.thinkingQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-7qsg.csv', sep = ";")
data_validityQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-81k4.csv', sep = ";")
data_demographicsQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-c7cw.csv', sep = ";")
data_science.attitudesQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-cl1u.csv', sep = ";")
data_need.cognitionQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-eygv.csv', sep = ";")
data_science.curiosityQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-go4a.csv', sep = ";")
data_need.closureQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-mz16.csv', sep = ";")
data_studyinfoQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-o43u.csv', sep = ";")
data_randomness.probabilityQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-otb8.csv', sep = ";")
data_intellectual.humilityQ_v23 <- read.csv('data_exp_55551-v23_questionnaire-oyla.csv', sep = ";")
data_big5Q_v23 <- read.csv('data_exp_55551-v23_questionnaire-w8n1.csv', sep = ";")
data_unusual.usesT_v23 <- read.csv('data_exp_55551-v23_task-7mar.csv', sep = ";")
data_NavonT_v23 <- read.csv('data_exp_55551-v23_task-8mu5.csv', sep = ";")
data_NeckerT_v23 <- read.csv('data_exp_55551-v23_task-9nll.csv', sep = ";")
data_go.nogoT_v23 <- read.csv('data_exp_55551-v23_task-n8ns.csv', sep = ";")
data_matrix.reasoningT_v23 <- read.csv('data_exp_55551-v23_task-tg12.csv', sep = ";")
data_citizen.initiativeT_v23 <- read.csv('data_exp_55551-v23_task-zryk.csv', sep = ";")

data_epistemicQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-2wlk.csv', sep = ";")
data_heuristicQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-79hv.csv', sep = ";")
data_openminded.thinkingQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-7qsg.csv', sep = ";")
data_validityQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-81k4.csv', sep = ";")
data_demographicsQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-c7cw.csv', sep = ";")
data_science.attitudesQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-cl1u.csv', sep = ";")
data_need.cognitionQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-eygv.csv', sep = ";")
data_science.curiosityQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-go4a.csv', sep = ";")
data_need.closureQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-mz16.csv', sep = ";")
data_studyinfoQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-o43u.csv', sep = ";")
data_randomness.probabilityQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-otb8.csv', sep = ";")
data_intellectual.humilityQ_v24 <- read.csv('data_exp_55551-v24_questionnaire-oyla.csv', sep = ";")
data_big5Q_v24 <- read.csv('data_exp_55551-v24_questionnaire-w8n1.csv', sep = ";")
data_unusual.usesT_v24 <- read.csv('data_exp_55551-v24_task-7mar.csv', sep = ";")
data_NavonT_v24 <- read.csv('data_exp_55551-v24_task-8mu5.csv', sep = ";")
data_NeckerT_v24 <- read.csv('data_exp_55551-v24_task-9nll.csv', sep = ";")
data_go.nogoT_v24 <- read.csv('data_exp_55551-v24_task-n8ns.csv', sep = ";")
data_matrix.reasoningT_v24 <- read.csv('data_exp_55551-v24_task-tg12.csv', sep = ";")
data_citizen.initiativeT_v24 <- read.csv('data_exp_55551-v24_task-zryk.csv', sep = ";")

data_epistemicQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-2wlk.csv', sep = ";")
data_heuristicQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-79hv.csv', sep = ";")
data_openminded.thinkingQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-7qsg.csv', sep = ";")
data_validityQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-81k4.csv', sep = ";")
data_demographicsQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-c7cw.csv', sep = ";")
data_science.attitudesQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-cl1u.csv', sep = ";")
data_need.cognitionQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-eygv.csv', sep = ";")
data_science.curiosityQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-go4a.csv', sep = ";")
data_need.closureQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-mz16.csv', sep = ";")
data_studyinfoQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-o43u.csv', sep = ";")
data_randomness.probabilityQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-otb8.csv', sep = ";")
data_intellectual.humilityQ_v25 <- read.csv('data_exp_55551-v25_questionnaire-oyla.csv', sep = ";")
data_big5Q_v25 <- read.csv('data_exp_55551-v25_questionnaire-w8n1.csv', sep = ";")
data_unusual.usesT_v25 <- read.csv('data_exp_55551-v25_task-7mar.csv', sep = ";")
data_NavonT_v25 <- read.csv('data_exp_55551-v25_task-8mu5.csv', sep = ";")
data_NeckerT_v25 <- read.csv('data_exp_55551-v25_task-9nll.csv', sep = ";")
data_go.nogoT_v25 <- read.csv('data_exp_55551-v25_task-n8ns.csv', sep = ";")
data_matrix.reasoningT_v25 <- read.csv('data_exp_55551-v25_task-tg12.csv', sep = ";")
data_citizen.initiativeT_v25 <- read.csv('data_exp_55551-v25_task-zryk.csv', sep = ";")

```


#Creating questionnaire dataframe

This series of chunks loads in each dataset, cleans up general rows and columns, and merges the questionnaire datasets

NB: most task datasets are also loaded in and versions merged here, they will be used later

NB: when merging, ALWAYS ADD the argument all=TRUE, this allows for missing data from some datasets. Otherwise the merge deletes incomplete rows. 

```{r Anonymising data, include=FALSE}

#Omitting experiment-general columns from all files (except for participant ID)
data_big5Q_v22 <- data_big5Q_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_citizen.initiativeT_v22 <- data_citizen.initiativeT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_citizen.initiativeT_v22))
data_demographicsQ_v22 <- data_demographicsQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_epistemicQ_v22 <- data_epistemicQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_go.nogoT_v22 <- data_go.nogoT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_go.nogoT_v22))
data_heuristicQ_v22 <- data_heuristicQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_intellectual.humilityQ_v22 <- data_intellectual.humilityQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_matrix.reasoningT_v22 <- data_matrix.reasoningT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_matrix.reasoningT_v22))
data_NavonT_v22 <- data_NavonT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NavonT_v22))
data_NeckerT_v22 <- data_NeckerT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NeckerT_v22))
data_need.closureQ_v22 <- data_need.closureQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_need.cognitionQ_v22 <- data_need.cognitionQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_openminded.thinkingQ_v22 <- data_openminded.thinkingQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_randomness.probabilityQ_v22 <- data_randomness.probabilityQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.attitudesQ_v22 <- data_science.attitudesQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.curiosityQ_v22 <- data_science.curiosityQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_studyinfoQ_v22 <- data_studyinfoQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_unusual.usesT_v22 <- data_unusual.usesT_v22 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_unusual.usesT_v22))
data_validityQ_v22 <- data_validityQ_v22 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)

data_big5Q_v23 <- data_big5Q_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_citizen.initiativeT_v23 <- data_citizen.initiativeT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_citizen.initiativeT_v23))
data_demographicsQ_v23 <- data_demographicsQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_epistemicQ_v23 <- data_epistemicQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_go.nogoT_v23 <- data_go.nogoT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_go.nogoT_v23))
data_heuristicQ_v23 <- data_heuristicQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_intellectual.humilityQ_v23 <- data_intellectual.humilityQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_matrix.reasoningT_v23 <- data_matrix.reasoningT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_matrix.reasoningT_v23))
data_NavonT_v23 <- data_NavonT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NavonT_v23))
data_NeckerT_v23 <- data_NeckerT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NeckerT_v23))
data_need.closureQ_v23 <- data_need.closureQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_need.cognitionQ_v23 <- data_need.cognitionQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_openminded.thinkingQ_v23 <- data_openminded.thinkingQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_randomness.probabilityQ_v23 <- data_randomness.probabilityQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.attitudesQ_v23 <- data_science.attitudesQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.curiosityQ_v23 <- data_science.curiosityQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_studyinfoQ_v23 <- data_studyinfoQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_unusual.usesT_v23 <- data_unusual.usesT_v23 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_unusual.usesT_v23))
data_validityQ_v23 <- data_validityQ_v23 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)

data_big5Q_v24 <- data_big5Q_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_citizen.initiativeT_v24 <- data_citizen.initiativeT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_citizen.initiativeT_v24))
data_demographicsQ_v24 <- data_demographicsQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_epistemicQ_v24 <- data_epistemicQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_go.nogoT_v24 <- data_go.nogoT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_go.nogoT_v24))
data_heuristicQ_v24 <- data_heuristicQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_intellectual.humilityQ_v24 <- data_intellectual.humilityQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_matrix.reasoningT_v24 <- data_matrix.reasoningT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_matrix.reasoningT_v24))
data_NavonT_v24 <- data_NavonT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NavonT_v24))
data_NeckerT_v24 <- data_NeckerT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NeckerT_v24))
data_need.closureQ_v24 <- data_need.closureQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_need.cognitionQ_v24 <- data_need.cognitionQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_openminded.thinkingQ_v24 <- data_openminded.thinkingQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_randomness.probabilityQ_v24 <- data_randomness.probabilityQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.attitudesQ_v24 <- data_science.attitudesQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.curiosityQ_v24 <- data_science.curiosityQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_studyinfoQ_v24 <- data_studyinfoQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_unusual.usesT_v24 <- data_unusual.usesT_v24 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_unusual.usesT_v24))
data_validityQ_v24 <- data_validityQ_v24 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)

data_big5Q_v25 <- data_big5Q_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_citizen.initiativeT_v25 <- data_citizen.initiativeT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_citizen.initiativeT_v25))
data_demographicsQ_v25 <- data_demographicsQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_epistemicQ_v25 <- data_epistemicQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_go.nogoT_v25 <- data_go.nogoT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_go.nogoT_v25))
data_heuristicQ_v25 <- data_heuristicQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_intellectual.humilityQ_v25 <- data_intellectual.humilityQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_matrix.reasoningT_v25 <- data_matrix.reasoningT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_matrix.reasoningT_v25))
data_NavonT_v25 <- data_NavonT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NavonT_v25))
data_NeckerT_v25 <- data_NeckerT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_NeckerT_v25))
data_need.closureQ_v25 <- data_need.closureQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_need.cognitionQ_v25 <- data_need.cognitionQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_openminded.thinkingQ_v25 <- data_openminded.thinkingQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_randomness.probabilityQ_v25 <- data_randomness.probabilityQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.attitudesQ_v25 <- data_science.attitudesQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_science.curiosityQ_v25 <- data_science.curiosityQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_studyinfoQ_v25 <- data_studyinfoQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)
data_unusual.usesT_v25 <- data_unusual.usesT_v25 %>%
  select(Participant.Private.ID, Spreadsheet:ncol(data_unusual.usesT_v25))
data_validityQ_v25 <- data_validityQ_v25 %>%
  select(Participant.Private.ID, Randomise.questionnaire.elements.:END.QUESTIONNAIRE)

```


# Cleaning and formatting
This large chunk cleans and formats the data.

```{r data cleaning and formatting, include=FALSE}

#Omitting the last row of each file as this row merely signals that the experiment has ended and carries no useful information.
#concatenating the versions of each task and removing the empty last line of each file 

data_big5Q <- rbind(data_big5Q_v22,data_big5Q_v23,data_big5Q_v24,data_big5Q_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_citizen.initiativeT <- rbind(data_citizen.initiativeT_v22,data_citizen.initiativeT_v23,data_citizen.initiativeT_v23,data_citizen.initiativeT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_demographicsQ <-  rbind(data_demographicsQ_v22,data_demographicsQ_v23,data_demographicsQ_v24,data_demographicsQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_epistemicQ <- rbind(data_epistemicQ_v22,data_epistemicQ_v23,data_epistemicQ_v24,data_epistemicQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_go.nogoT <- rbind(data_go.nogoT_v22,data_go.nogoT_v23,data_go.nogoT_v24,data_go.nogoT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_heuristicQ <- rbind(data_heuristicQ_v22,data_heuristicQ_v23,data_heuristicQ_v24,data_heuristicQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_intellectual.humilityQ <- rbind(data_intellectual.humilityQ_v22,data_intellectual.humilityQ_v23,data_intellectual.humilityQ_v24,data_intellectual.humilityQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_matrix.reasoningT <- rbind(data_matrix.reasoningT_v22,data_matrix.reasoningT_v23,data_matrix.reasoningT_v24,data_matrix.reasoningT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_NavonT <- rbind(data_NavonT_v22,data_NavonT_v23,data_NavonT_v24,data_NavonT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_NeckerT <- rbind(data_NeckerT_v22,data_NeckerT_v23,data_NeckerT_v24,data_NeckerT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_need.closureQ <- rbind(data_need.closureQ_v22,data_need.closureQ_v23,data_need.closureQ_v24,data_need.closureQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_need.cognitionQ <- rbind(data_need.cognitionQ_v22,data_need.cognitionQ_v23,data_need.cognitionQ_v24,data_need.cognitionQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_openminded.thinkingQ <- rbind(data_openminded.thinkingQ_v22,data_openminded.thinkingQ_v23,data_openminded.thinkingQ_v24,data_openminded.thinkingQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_randomness.probabilityQ <- rbind(data_randomness.probabilityQ_v22,data_randomness.probabilityQ_v23,data_randomness.probabilityQ_v24,data_randomness.probabilityQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_science.attitudesQ <- rbind(data_science.attitudesQ_v22,data_science.attitudesQ_v23,data_science.attitudesQ_v24,data_science.attitudesQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_science.curiosityQ <- rbind(data_science.curiosityQ_v22,data_science.curiosityQ_v23,data_science.curiosityQ_v24,data_science.curiosityQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_studyinfoQ <- rbind(data_studyinfoQ_v22,data_studyinfoQ_v23,data_studyinfoQ_v24,data_studyinfoQ_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_unusual.usesT <- rbind(data_unusual.usesT_v22,data_unusual.usesT_v23,data_unusual.usesT_v24,data_unusual.usesT_v25) %>%
  filter(!is.na(Participant.Private.ID))
data_validityQ <- rbind(data_validityQ_v22,data_validityQ_v23,data_validityQ_v24,data_validityQ_v25) %>%
  filter(!is.na(Participant.Private.ID))

#just to clean up the environment, can keep these lines to double check the data
rm(data_big5Q_v22, data_citizen.initiativeT_v22, data_demographicsQ_v22, data_epistemicQ_v22, data_go.nogoT_v22, data_heuristicQ_v22, data_intellectual.humilityQ_v22, data_matrix.reasoningT_v22, data_NavonT_v22, data_NeckerT_v22, data_need.closureQ_v22, data_need.cognitionQ_v22, data_openminded.thinkingQ_v22, data_randomness.probabilityQ_v22, data_science.attitudesQ_v22, data_science.curiosityQ_v22, data_studyinfoQ_v22, data_unusual.usesT_v22, data_validityQ_v22)

rm(data_big5Q_v23, data_citizen.initiativeT_v23, data_demographicsQ_v23, data_epistemicQ_v23, data_go.nogoT_v23, data_heuristicQ_v23, data_intellectual.humilityQ_v23, data_matrix.reasoningT_v23, data_NavonT_v23, data_NeckerT_v23, data_need.closureQ_v23, data_need.cognitionQ_v23, data_openminded.thinkingQ_v23, data_randomness.probabilityQ_v23, data_science.attitudesQ_v23, data_science.curiosityQ_v23, data_studyinfoQ_v23, data_unusual.usesT_v23, data_validityQ_v23)

rm(data_big5Q_v24, data_citizen.initiativeT_v24, data_demographicsQ_v24, data_epistemicQ_v24, data_go.nogoT_v24, data_heuristicQ_v24, data_intellectual.humilityQ_v24, data_matrix.reasoningT_v24, data_NavonT_v24, data_NeckerT_v24, data_need.closureQ_v24, data_need.cognitionQ_v24, data_openminded.thinkingQ_v24, data_randomness.probabilityQ_v24, data_science.attitudesQ_v24, data_science.curiosityQ_v24, data_studyinfoQ_v24, data_unusual.usesT_v24, data_validityQ_v24)

rm(data_big5Q_v25, data_citizen.initiativeT_v25, data_demographicsQ_v25, data_epistemicQ_v25, data_go.nogoT_v25, data_heuristicQ_v25, data_intellectual.humilityQ_v25, data_matrix.reasoningT_v25, data_NavonT_v25, data_NeckerT_v25, data_need.closureQ_v25, data_need.cognitionQ_v25, data_openminded.thinkingQ_v25, data_randomness.probabilityQ_v25, data_science.attitudesQ_v25, data_science.curiosityQ_v25, data_studyinfoQ_v25, data_unusual.usesT_v25, data_validityQ_v25)

``` 


# Merging questionnaire dataframes

```{r Renaming the END.QUESTIONNAIRE + Randomise.questionnaire.elements. columns for each questionnaire, include=FALSE}

#Renaming two columns before combining all the questionnaires into one df. END.QUESTIONNAIRE column gives you the response time for that questionnaire, and Randomise.questionnaire.elements. column gives you a logical value indicating whether the questionnaire items were randomised for that questionnaire.

#END.QUESTIONNAIRE
names(data_demographicsQ)[names(data_demographicsQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.DEMOGRAPHICS"
names(data_big5Q)[names(data_big5Q) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.BIG5"
names(data_epistemicQ)[names(data_epistemicQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.EPISTEMIC"
names(data_heuristicQ)[names(data_heuristicQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.HEURISTIC"
names(data_intellectual.humilityQ)[names(data_intellectual.humilityQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.INT.HUM"
names(data_need.closureQ)[names(data_need.closureQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.NEED.CLO"
names(data_need.cognitionQ)[names(data_need.cognitionQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.NEED.COG"
names(data_openminded.thinkingQ)[names(data_openminded.thinkingQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.OPEN.THINK"
names(data_randomness.probabilityQ)[names(data_randomness.probabilityQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.RANDOM.PROB"
names(data_science.attitudesQ)[names(data_science.attitudesQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.SCIENCE.ATT"
names(data_science.curiosityQ)[names(data_science.curiosityQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.SCIENCE.CUR"
names(data_studyinfoQ)[names(data_studyinfoQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.INFO"
names(data_validityQ)[names(data_validityQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.VALIDITY"

#Randomise.questionnaire.elements
names(data_demographicsQ)[names(data_demographicsQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..DEMOGRAPHICS"
names(data_big5Q)[names(data_big5Q) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..BIG5"
names(data_epistemicQ)[names(data_epistemicQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..EPISTEMIC"
names(data_heuristicQ)[names(data_heuristicQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..HEURISTIC"
names(data_intellectual.humilityQ)[names(data_intellectual.humilityQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..INT.HUM"
names(data_need.closureQ)[names(data_need.closureQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..NEED.CLO"
names(data_need.cognitionQ)[names(data_need.cognitionQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..NEED.COG"
names(data_openminded.thinkingQ)[names(data_openminded.thinkingQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..OPEN.THINK"
names(data_randomness.probabilityQ)[names(data_randomness.probabilityQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..RANDOM.PROB"
names(data_science.attitudesQ)[names(data_science.attitudesQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..SCIENCE.ATT"
names(data_science.curiosityQ)[names(data_science.curiosityQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..SCIENCE.CUR"
names(data_studyinfoQ)[names(data_studyinfoQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..INFO"
names(data_validityQ)[names(data_validityQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..VALIDITY"


#The questionnaire files currently include the participant private ID and the questionnaire-specific columns.

#Merging by participant ID
#The way the dataframes are joined means that all rows in both dfs are kept. We need to keep all unique rows because some ppts have not done all the tasks, so the dfs are different lengths

data1 <- merge(data_demographicsQ, data_big5Q, by = "Participant.Private.ID", all=TRUE)
data2 <- merge(data_epistemicQ, data_heuristicQ, by = "Participant.Private.ID", all=TRUE)
data3 <- merge(data_intellectual.humilityQ, data_need.closureQ, by = "Participant.Private.ID", all=TRUE)
data4 <- merge(data_need.cognitionQ, data_openminded.thinkingQ, by = "Participant.Private.ID", all=TRUE)
data5 <- merge(data_randomness.probabilityQ, data_science.attitudesQ, by = "Participant.Private.ID", all=TRUE)
data6 <- merge(data_science.curiosityQ, data_studyinfoQ, by = "Participant.Private.ID", all=TRUE)
data7 <- merge(data1, data2, by = "Participant.Private.ID", all=TRUE)
data8 <- merge(data3, data4, by = "Participant.Private.ID", all=TRUE)
data9 <- merge(data5, data6, by = "Participant.Private.ID", all=TRUE)
data10 <- merge(data7, data8, by = "Participant.Private.ID", all=TRUE)
data11 <- merge(data9, data_validityQ, by = "Participant.Private.ID", all=TRUE)
data_Q_total <- merge(data10, data11, by = "Participant.Private.ID", all=TRUE)

#cleaning up the environment
rm(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11)

```

Now the file we have (data_Q_total) includes all the questionnaire data. Before merging the files, two columns per file had to be renamed as there would have been columns with the same name otherwise (END.QUESTIONNAIRE and Randomise.questionnaire.elements.).

Finally, the dfs were merged using the merge() function and merging them by private participant ID (the function matches the rows based on this column's value).

From now on, the questionnaire data can be accessed either through the separate variables that contain the data for that questionnaire (e.g., data_demographicsQ) **or** using the variable that contains all the questionnaire data (data_Q_total). Having one big dataframe means that it is easier to omit rows that shouldn't be there (e.g., participants who have not consented / who said their data is not valid for some reason).


# Participant exclusions and demographics 

This chunk removes nonvalid participants and analyzes demographics.

First, check comments for those who chose something other than "you can use my data" to see what else is chosen and why. Here, there were a few "other, what?" that can be kept, e.g. ppts worried that making mistakes in a few trials of Navon makes their data invalid

Participants' data is omitted completely if they have stated that a) their responses are not valid, and/or s) their Finnish isn't Äidinkieli or Keskusteleva. Ppts who declined to consent were taken away from the study and no data was collected for them. 

```{r Cleaning questionnaire data, include=FALSE}
 
#2 nonvalid ppts "älä huomioi aineistoani"
data_nonvalid <- data_Q_total %>%
  filter(Validity == "Ã„lÃ¤ huomioi aineistoani. Jokin muu syy esti minua osallistumasta kunnolla." | Validity == "Ã„lÃ¤ huomioi aineistoani. En suurimmaksi osaksi keskittynyt tai lukenut kysymyksiÃ¤ kunnolla.")

#nonvalid language answers: there was one "muu" who said they had fluent but not native level, included them
#the remaining "ei ole" is a test by CD
data_Q_lang_omit <- data_Q_total %>%
  filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

## Subsetting: 
#check that the strings are correct and check for any blanks or NAs that should not be there

#1 nonvalid language, 2 validity check, 1 has NAs in all columns
#total N= 178 -> 174 ppts. 
#table(data_Q_total$ConsentFlag) #1=consent, 0=no ; there should be 100% consent
table(data_Q_total$Validity) 
table(data_Q_total$Language)

data_Q_total <- data_Q_total %>%
  filter(Validity %in% c("Aineistoani voi kÃ¤yttÃ¤Ã¤.","Muu, mikÃ¤? ",NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?"))


## Demographics: checking the class and range of the data
typeof(data_Q_total$gender)
data_Q_total$gender <- factor(data_Q_total$gender) #changing gender into factor

typeof(data_Q_total$Age) #Age should be integer so we leave it

typeof(data_Q_total$Country) 
data_Q_total$Country <- factor(data_Q_total$Country) #changing country into factor

typeof(data_Q_total$Language)
data_Q_total$Language <- factor(data_Q_total$Language) #changing language into factor

typeof(data_Q_total$Education)
data_Q_total$Education <- factor(data_Q_total$Education) #changing education into factor


#demographics visuals

par(mfrow=c(2,3))

#this one works for categorical data 
barplot(table(data_Q_total$gender),ylim=(c(0,150)),main="Gender",col = 'skyblue3')
barplot(table(data_Q_total$Country),ylim=(c(0,180)),main="Country",col = 'skyblue3')

x <- barplot(table(data_Q_total$Education.quantised), ylim=(c(0, 80)),col = 'skyblue3',xaxt="n",main="Education level")
labs <- paste(c("Tohtorintutkinto / lisensiaattitutkinto","Ylempi korkeakoulututkinto","Alempi korkeakoulututkinto","Ammattikoulututkinto","Ylioppislastutkinto","Peruskoulu tai kansakoulu","Muu tutkinto, mikä?"))
text(cex=.65, x=x-.25, y=-9, labs, xpd=TRUE, srt=30)

hist(data_Q_total$Age, xlim=c(15,80), ylim=c(0,50),col = 'skyblue3',breaks = 7,xlab = "Age", ylab = "Frequency",main="Age")

```


#Questionnaire processing 

The following chunks deal with TIPI, EC, IH, AOT, NFC, and NFcog. They remove bad quality data from each questionnaire, runs CFA on all but TIPI, and calculate sum scores. 

The data from each questionnaire is checked: if a participant was suspiciously quick at responding to the questionnaire (I've used <1s/item for now), that participant's data for that questionnaire is replaced with NAs. After this, items are reverse-coded (if necessary), the structure is checked with CFA (prior to which the distributions of the items are checked so that CFA assumptions are met), and sum scores/mean scores are calculated for each questionnaire according to the scoring instructions.

Additionally, for scales that have reverse-coded items, if 95% of a participant's responses fall on the same response, their data for that scale are replaced with NAs (this indicates that they have not even read the questions properly).

****Note to self: check the issues with CFA: single factor, methods, nonnormality, model indices****

***GENERAL CFA NOTES***
Maximum Likelihood Estimation (MLE) assumes large sample size, normality of data, and continuous data; if data are non-normal, we should use robust MLE; if data are ordinal, we should use unweighted least squares or diagonally weighted least squares.

estimator = "MLF" or "MLR" for incomplete data, robust estimator 
https://lavaan.ugent.be/tutorial/est.html 

Should be noted that it is common to still treat data as continuous if there are more than 5 response options in your scale and participants are using the full range of responses. This is due to the fact that MLE has benefits that WLS doesn't have. **This should be discussed.** 

The default scaling constraint/identifcation constraints imposed when using the cfa() function are to fix the loading of the first item of each latent variable to 1. We can override this by setting std.lv=TRUE. This will instead scale the latent variables by fixing them to 1.
https://stats.stackexchange.com/questions/134348/when-a-cfa-model-has-a-covariance-matrix-was-not-positive-definite-problem-is : there are problems with this model (as expected) due to small sample size in the pilot data; this should hopefully not be an issue once the actual data is being analysed

summary(modelB5.est, fit.measures = T, standardised = T) 

look at SRMR and RMSEA (<.05) and CFI and TLI (>.95); These will tell you whether the hypothesized model fits the data or not

modindices(modelB5.est, sort = T) 
this allows us to look at the local mis-fit

Some parameters are estimated or fixed by default when you estimate the model with the cfa() function. In this case, the residual factor variances and loadings are missing because the former are estimated by default and the latter are fixed to 1 by default. Latent factor variances are also estimated by default.

modelB5.est<-cfa(modelB5, data=data_Q_total, std.lv=TRUE)

https://journals.sagepub.com/doi/pdf/10.1177/0734282911406653 
https://link.springer.com/article/10.3758/s13428-015-0619-7

ASSUMPTIONS
Large sample size: we will probably have that
Normality of the data: this needs to be checked (plotting, Shapiro-Wilks)
Kolmogorov-smirnov is better for larger datasets, but they both have the problem of being oversensitive in large sets
Continuous data: Likert-scales are not continuous; some sources assert that it's ok to use MLE when you have a certain number of response options (typically 5 or more)
It is especially safe to treat Likert data as continuous if there 5 or more response options AND participants are actually using all of them. 

***NOTES ON RELIABILITY***

Not sure if CFA should work for the single-factor surveys.
When calculating alpha, nonnormal data is a problem. 
"Given the results of the study, we suggest that in order for the sample coefficient alpha to be fairly accurate and in a reasonable range, a minimum of 1000 subjects is needed for a small reliability, and a minimum of 100 is needed for a moderate reliability when the sample data depart from normality." https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3279724/ 


##TIPI

CFA or reliability are not calculated for TIPI, see Gosling's website for explanation. http://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/ 

```{r Scoring TIPI, include=FALSE}
## Big Five (range 1-7)

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (B5 has reverse-coded items so this applies here)
   #minimum response time (if participant was too quick to fill the survey;(1s/item -> 10000ms total)

#Distribution of responses: Here, I look at the table/distribution of responses for each survey (Big 5 in this context) for each participant, creating a separate column with values corresponding to whether the participant's data should be omitted (1=yes=more than 95% of this participant's responses were the same value; 0=no=less than 95% of this participant's response were the same value) If B5=1, that participant's B5 data should be omitted/replaced with NAs

data_Q_total <- data_Q_total %>%
  mutate(B5_omit = case_when(((max(table(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse)))/length(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse))) >= .95) | (END.QUESTIONNAIRE.BIG5 <= 10000) ~ 1,
         ((max(table(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse)))/length(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse)) < .95) & (END.QUESTIONNAIRE.BIG5 > 10000) ~ 0))) 
  
#Omitting B5 data based on the B5_omit column
data_Q_total$agreeablenessNormal[which(data_Q_total$B5_omit == 1)] <- NA
data_Q_total$agreeablenessReverse[which(data_Q_total$B5_omit ==1)] <- NA
data_Q_total$conscientiousnessNormal[which(data_Q_total$B5_omit == 1)] <- NA
data_Q_total$conscientiousnessReverse[which(data_Q_total$B5_omit ==1)] <- NA
data_Q_total$extroversionNormal[which(data_Q_total$B5_omit == 1)] <- NA
data_Q_total$extroversionReverse[which(data_Q_total$B5_omit ==1)] <- NA
data_Q_total$opennessNormal[which(data_Q_total$B5_omit == 1)] <- NA
data_Q_total$opennessReverse[which(data_Q_total$B5_omit ==1)] <- NA
data_Q_total$emotionalStabilityNormal[which(data_Q_total$B5_omit == 1)] <- NA
data_Q_total$emotionalStabilityReverse[which(data_Q_total$B5_omit ==1)] <- NA

#Reverse-coding
data_Q_total$agreeableness.rev <- reverse.code(keys = c(-1), items = data_Q_total$agreeablenessReverse, mini = c(1), maxi = c(7)) 
data_Q_total$emostability.rev <- reverse.code(keys = c(-1), items = data_Q_total$emotionalStabilityReverse, mini = c(1), maxi = c(7))
data_Q_total$extroversion.rev <- reverse.code(keys = c(-1), items = data_Q_total$extroversionReverse, mini = c(1), maxi = c(7))
data_Q_total$conscientiousness.rev <- reverse.code(keys = c(-1), items = data_Q_total$conscientiousnessReverse, mini = c(1), maxi = c(7))
data_Q_total$openness.rev <- reverse.code(keys = c(-1), items = data_Q_total$opennessReverse, mini = c(1), maxi = c(7))


# Item level
#Normality assumption

#Visualising the data
#par(mfrow=c(2,5))
#hist(data_Q_total$agreeablenessNormal,main="Agreeableness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$agreeableness.rev,main="Reversed Agreeableness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$emotionalStabilityNormal,main="EmotionalStability",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$emostability.rev,main="Reversed EmotionalStability",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$extroversionNormal,main="Extroversion",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$extroversion.rev,main="Reversed Extroversion",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$conscientiousnessNormal,main="Conscientiousness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$conscientiousness.rev,main="Reversed Conscientiousness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$opennessNormal,main="Openness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$openness.rev,main="Reversed Openness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")

#Describe (skew, kurtosis, mean)
#TIPI_items <- (describe(data_Q_total$agreeablenessNormal))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$agreeableness.rev))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$emotionalStabilityNormal))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$emostability.rev))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$extroversionNormal))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$extroversion.rev))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$conscientiousnessNormal))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$conscientiousness.rev))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$opennessNormal))
#TIPI_items <- rbind(TIPI_items,describe(data_Q_total$openness.rev))
#row.names(TIPI_items) <- c("AN","AR","EN","ER","EXN","EXR","CN","CR","ON","OR")
#View(TIPI_items)


#Shapiro-Wilks test
#If p<.05, we need to look into it
#they're all signficant
#shapiro.test(data_Q_total$agreeablenessNormal)
#shapiro.test(data_Q_total$agreeableness.rev)
#shapiro.test(data_Q_total$emotionalStabilityNormal)
#shapiro.test(data_Q_total$emostability.rev)
#shapiro.test(data_Q_total$extroversionNormal)
#shapiro.test(data_Q_total$extroversion.rev)
#shapiro.test(data_Q_total$conscientiousnessNormal)
#shapiro.test(data_Q_total$conscientiousness.rev)
#shapiro.test(data_Q_total$opennessNormal)
#shapiro.test(data_Q_total$openness.rev) 

#Big 5 Scoring instructions
#http://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/ 

#Means
data_Q_total$AMean <- rowMeans(cbind(data_Q_total$agreeablenessNormal, data_Q_total$agreeableness.rev), na.rm = TRUE)
data_Q_total$CMean <- rowMeans(cbind(data_Q_total$conscientiousnessNormal, data_Q_total$conscientiousness.rev), na.rm = TRUE)
data_Q_total$EMean <- rowMeans(cbind(data_Q_total$extroversionNormal, data_Q_total$extroversion.rev), na.rm = TRUE)
data_Q_total$ESMean <- rowMeans(cbind(data_Q_total$emotionalStabilityNormal, data_Q_total$emostability.rev), na.rm = TRUE)
data_Q_total$OMean <- rowMeans(cbind(data_Q_total$opennessNormal, data_Q_total$openness.rev), na.rm = TRUE)

#describing factor scores
#TIPI_task <- (describe(data_Q_total$AMean))
#TIPI_task <- rbind(TIPI_task,describe(data_Q_total$CMean))
#TIPI_task <- rbind(TIPI_task,describe(data_Q_total$EMean))
#TIPI_task <- rbind(TIPI_task,describe(data_Q_total$ESMean))
#TIPI_task <- rbind(TIPI_task,describe(data_Q_total$OMean))
#row.names(TIPI_task) <- c("AMean","CMean","EMean","ESMean","OMean")
#View(TIPI_task)

#not working
#abs.skew <- (mean(as.numeric(data_Q_total$AMean,na.rm = TRUE)- median(as.numeric(data_Q_total$AMean,na.rm = TRUE))))

#Shapiro-Wilks test
#If p<.05, we need to look into it
#they're all signficant
#shapiro.test(data_Q_total$AMean)
#shapiro.test(data_Q_total$CMean)
#shapiro.test(data_Q_total$EMean)
#shapiro.test(data_Q_total$ESMean)
#shapiro.test(data_Q_total$OMean)


#outliers not really relevant here


#visualizing B5 total scores
#par(mfrow=c(2,3))
#hist(data_Q_total$AMean,main="Agreeableness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$CMean,main="Conscientiousness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$EMean,main="Extroversion",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$ESMean,main="Emotional Stability",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$OMean,main="Openness",col=rainbow(14),ylim=c(0,60),breaks=seq(0,7,1),xlab="")
```

##Epistemic Curiosity

```{r Scoring Epistemic Curiosity, include=FALSE}
## Epistemic Curiosity (range 1-5)

#Exclusion criteria
   # min response time (1s/item -> 10000ms total)

data_Q_total <- data_Q_total %>%
  mutate(EpiCur_omit = case_when(END.QUESTIONNAIRE.EPISTEMIC <= 10000 ~ 1,
                                 END.QUESTIONNAIRE.EPISTEMIC > 10000 ~ 0)) #again, if EpiCur_omit=1, that participant's Epistemic Curiosity data should be omitted

#Omitting Epistemic Curiosity data based on the EpiCur_omit column
data_Q_total$Icuriosity1[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Icuriosity2[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Icuriosity3[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Icuriosity4[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Icuriosity5[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Dcuriosity1[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Dcuriosity2[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Dcuriosity3[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Dcuriosity4[which(data_Q_total$EpiCur_omit == 1)] <- NA
data_Q_total$Dcuriosity5[which(data_Q_total$EpiCur_omit == 1)] <- NA

## Checking the structure with CFA

## Assumptions
#Normality
#par(mfrow=c(2,5))
#hist(data_Q_total$Icuriosity1,main="I Curiosity 1",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Icuriosity2,main="I Curiosity 2",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Icuriosity3,main="I Curiosity 3",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Icuriosity4,main="I Curiosity 4",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Icuriosity5,main="I Curiosity 5",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Dcuriosity1,main="D Curiosity 1",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Dcuriosity2,main="D Curiosity 2",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Dcuriosity3,main="D Curiosity 3",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Dcuriosity4,main="D Curiosity 4",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$Dcuriosity5,main="D Curiosity 5",col=rainbow(14),ylim=c(0,100),breaks=seq(0,5,1),xlab="")


#Summary (mean, skew, kurtosis)
#EC_items <- (describe(data_Q_total$Icuriosity1))
#EC_items <- rbind(EC_items,describe(data_Q_total$Icuriosity2))
#EC_items <- rbind(EC_items,describe(data_Q_total$Icuriosity3))
#EC_items <- rbind(EC_items,describe(data_Q_total$Icuriosity4))
#EC_items <- rbind(EC_items,describe(data_Q_total$Icuriosity5))
#EC_items <- rbind(EC_items,describe(data_Q_total$Dcuriosity1))
#EC_items <- rbind(EC_items,describe(data_Q_total$Dcuriosity2))
#EC_items <- rbind(EC_items,describe(data_Q_total$Dcuriosity3))
#EC_items <- rbind(EC_items,describe(data_Q_total$Dcuriosity4))
#EC_items <- rbind(EC_items,describe(data_Q_total$Dcuriosity5))
#row.names(EC_items) <- c("IC1","I2C","IC3","IC4","IC5","DC1","DC2","DC3","DC4","DC5")
#View(EC_items)


#Shapiro-Wilks
#all significant
#shapiro.test(data_Q_total$Icuriosity1)
#shapiro.test(data_Q_total$Icuriosity2)
#shapiro.test(data_Q_total$Icuriosity3)
#shapiro.test(data_Q_total$Icuriosity4)
#shapiro.test(data_Q_total$Icuriosity5)
#shapiro.test(data_Q_total$Dcuriosity1)
#shapiro.test(data_Q_total$Dcuriosity2)
#shapiro.test(data_Q_total$Dcuriosity3)
#shapiro.test(data_Q_total$Dcuriosity4)
#shapiro.test(data_Q_total$Dcuriosity5)


#Checking structure with CFA
round(cor(data_Q_total[,c()], method = "spearman"),2)
round(cov(data_Q_total[,c()], method = "spearman"),2)
modelEpi <- 'Dcuriosity=~Dcuriosity1+Dcuriosity2+Dcuriosity3+Dcuriosity4+Dcuriosity5
             Icuriosity=~Icuriosity1+Icuriosity2+Icuriosity3+Icuriosity4+Icuriosity5
Dcuriosity ~~ Icuriosity'
modelEpi.est<-cfa(modelEpi, data=data_Q_total, std.lv=TRUE, estimator = "ULS")
summary(modelEpi.est, fit.measures = T, standardized = T) #American English spelling for "standardized"
modindices(modelEpi.est, sort = T)

#Sum scores
data_Q_total$ICuriositySum <- rowSums(cbind(data_Q_total$Icuriosity1, data_Q_total$Icuriosity2, data_Q_total$Icuriosity3, data_Q_total$Icuriosity4, data_Q_total$Icuriosity5))
data_Q_total$DCuriositySum <- rowSums(cbind(data_Q_total$Dcuriosity1, data_Q_total$Dcuriosity2, data_Q_total$Dcuriosity3, data_Q_total$Dcuriosity4, data_Q_total$Dcuriosity5))

#sample level sum score descriptives and outliers
#Q1 <- quantile(data_Q_total$ICuriositySum, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_Q_total$ICuriositySum, 0.75,na.rm=TRUE)
#range <- (IQR(data_Q_total$ICuriositySum,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_Q_total$ICuriositySum)
#lowbound
#highbound

data_Q_total$ICuriositySum[which(data_Q_total$ICuriositySum < 11.5)] <- NA
#data_Q_total$DCuriositySum[which(data_Q_total$ICuriositySum < )] <- NA #No outliers in D curiosity


#Summary (mean, skew, kurtosis)
describe(data_Q_total$ICuriositySum)
describe(data_Q_total$DCuriositySum)

#EC_task <- (describe(data_Q_total$ICuriositySum))
#EC_task <- rbind(EC_task,describe(data_Q_total$DCuriositySum))
#row.names(EC_task) <- c("ICurSum","DCurSum")
#View(EC_task)

#Shapiro-Wilks
#ICuriosity nonnormal, DCuriosity normal
#shapiro.test(data_Q_total$ICuriositySum)
#shapiro.test(data_Q_total$DCuriositySum)

#ploting task total scores
#par(mfrow=c(1,2))
#hist(data_Q_total$ICuriositySum,main="Interest Curiosity",col=rainbow(14),breaks=seq(0,25,1),ylim=c(0,30),xlab="")
#hist(data_Q_total$DCuriositySum,main="Deprivation Curiosity",col=rainbow(14),breaks=seq(0,25,1),ylim=c(0,30),xlab="")
```

##Intellectual Humility

```{r Scoring Intellectual Humility, include=FALSE}
## Intellectual Humility (range 1-4)

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (because it's a partially reverse-coded scale)
   #response time (1s/item -> 22000ms total)

## Distribution of responses & min response time

data_Q_total <- data_Q_total %>%
  mutate(IH_omit = case_when(((max(table(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4)))/length(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4))) >= .95) | (END.QUESTIONNAIRE.INT.HUM <= 22000) ~ 1,
         ((max(table(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4)))/length(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4)) < .95) & (END.QUESTIONNAIRE.INT.HUM > 22000) ~ 0))) #again, if IH_omit=1, that participant's Epistemic Curiosity data should be omitted


#Omitting IH data based on the IH_omit column
data_Q_total$IH1rev1[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH2rev1[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH3rev1[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH4rev1[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH5rev1[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH6norm2[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH7norm2[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH8norm2[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH9norm2[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH10norm2[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH11norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH12norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH13norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH14norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH15norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH16norm3[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH17rev4[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH18rev4[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH19rev4[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH20rev4[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH21rev4[which(data_Q_total$IH_omit == 1)] <- NA
data_Q_total$IH22rev4[which(data_Q_total$IH_omit == 1)] <- NA


#Reverse-coding
data_Q_total$IH1.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH1rev1, mini = c(1), maxi = c(4))
data_Q_total$IH2.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH2rev1, mini = c(1), maxi = c(4))
data_Q_total$IH3.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH3rev1, mini = c(1), maxi = c(4))
data_Q_total$IH4.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH4rev1, mini = c(1), maxi = c(4))
data_Q_total$IH5.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH5rev1, mini = c(1), maxi = c(4))

data_Q_total$IH17.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH17rev4, mini = c(1), maxi = c(4))
data_Q_total$IH18.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH18rev4, mini = c(1), maxi = c(4))
data_Q_total$IH19.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH19rev4, mini = c(1), maxi = c(4))
data_Q_total$IH20.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH20rev4, mini = c(1), maxi = c(4))
data_Q_total$IH21.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH21rev4, mini = c(1), maxi = c(4))
data_Q_total$IH22.rev <- reverse.code(keys = c(-1), items = data_Q_total$IH22rev4, mini = c(1), maxi = c(4))


## Checking the structure with CFA

## Assumptions

#Normality
#par(mfrow=c(4,6))
#hist(data_Q_total$IH1.rev,main="IH1 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH2.rev,main="IH2 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH3.rev,main="IH3 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH4.rev,main="IH4 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH5.rev,main="IH5 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH6norm2,main="IH6 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH7norm2,main="IH7 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH8norm2,main="IH8 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH9norm2,main="IH9 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH10norm2,main="IH10 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$IH11norm3,main="IH11 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")

#hist(data_Q_total$IH12norm3,main="IH12 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH13norm3,main="IH13 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH14norm3,main="IH14 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH15norm3,main="IH15 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH16norm3,main="IH16 Norm",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH17.rev,main="IH17 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH18.rev,main="IH18 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH19.rev,main="IH19 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH20.rev,main="IH20 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH21.rev,main="IH21 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")
# hist(data_Q_total$IH22.rev,main="IH22 Rev",col=rainbow(14),breaks=seq(0,5,1),xlab="")

#Summary (mean, skew, kurtosis)
# IH_item <- (describe(data_Q_total$IH1.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH2.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH3.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH4.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH5.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH6norm2))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH7norm2))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH8norm2))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH9norm2))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH10norm2))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH11norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH12norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH13norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH14norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH15norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH16norm3))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH17.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH18.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH19.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH20.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH21.rev))
# IH_item <- rbind(IH_item,describe(data_Q_total$IH22.rev))
# row.names(IH_item) <- c("IH.rev1","IH2.rev","IH3.rev","IH4.rev","IH5.rev","IH6norm2","IH7norm2","IH8norm2","IH9norm2","IH10norm2","IH11norm3","IH12norm3","IH13norm3","IH14norm3","IH15norm3","IH16norm3","IH17.rev","IH18.rev","IH19.rev","IH20.rev","IH21.rev","IH22.rev")
# View(IH_item)

#Shapiro-Wilks
#all nonnormal
# shapiro.test(data_Q_total$IH1.rev)
# shapiro.test(data_Q_total$IH2.rev)
# shapiro.test(data_Q_total$IH3.rev)
# shapiro.test(data_Q_total$IH4.rev)
# shapiro.test(data_Q_total$IH5.rev)
# shapiro.test(data_Q_total$IH6norm2)
# shapiro.test(data_Q_total$IH7norm2)
# shapiro.test(data_Q_total$IH8norm2)
# shapiro.test(data_Q_total$IH9norm2)
# shapiro.test(data_Q_total$IH10norm2)
# shapiro.test(data_Q_total$IH11norm3)
# shapiro.test(data_Q_total$IH12norm3)
# shapiro.test(data_Q_total$IH13norm3)
# shapiro.test(data_Q_total$IH14norm3)
# shapiro.test(data_Q_total$IH15norm3)
# shapiro.test(data_Q_total$IH16norm3)
# shapiro.test(data_Q_total$IH17.rev)
# shapiro.test(data_Q_total$IH18.rev)
# shapiro.test(data_Q_total$IH19.rev)
# shapiro.test(data_Q_total$IH20.rev)
# shapiro.test(data_Q_total$IH21.rev)
# shapiro.test(data_Q_total$IH22.rev)


#CFA
round(cor(data_Q_total[,c()], method = "spearman"),2)
round(cov(data_Q_total[,c()], method = "spearman"),2)
modelIH <- 'IH1 =~ IH1.rev + IH2.rev + IH3.rev + IH4.rev + IH5.rev
           IH2 =~ IH6norm2 + IH7norm2 + IH8norm2 + IH9norm2 + IH10norm2
            IH3 =~ IH11norm3 + IH12norm3 + IH13norm3 + IH14norm3 + IH15norm3 + IH16norm3
            IH4 =~ IH17.rev + IH18.rev + IH19.rev+ IH20.rev + IH21.rev + IH22.rev
IH1 ~~ IH2
IH1 ~~ IH3
IH1 ~~ IH4
IH2 ~~ IH3
IH2 ~~ IH4
IH3 ~~ IH4'

modelIH.est<-cfa(modelIH, data=data_Q_total, std.lv = T, estimator = "ULS") 
summary(modelIH.est, fit.measures = T, standardized = T)
modindices(modelIH.est, sort = T)

#Intellectual Humility Scoring
#https://seaver.pepperdine.edu/social-science/content/comprehensive-intellectual-humility.pdf
#Again, this suggests sum scores for the IH subscales

#Calculating Means
data_Q_total$IH1Sum <- rowSums(cbind(data_Q_total$IH1.rev, data_Q_total$IH2.rev, data_Q_total$IH3.rev, data_Q_total$IH4.rev, data_Q_total$IH5.rev), na.rm = TRUE)
data_Q_total$IH2Sum <- rowSums(cbind(data_Q_total$IH6norm2, data_Q_total$IH7norm2, data_Q_total$IH8norm2, data_Q_total$IH9norm2, data_Q_total$IH10norm2), na.rm = TRUE)
data_Q_total$IH3Sum <- rowSums(cbind(data_Q_total$IH11norm3, data_Q_total$IH12norm3, data_Q_total$IH13norm3, data_Q_total$IH14norm3, data_Q_total$IH15norm3), na.rm = TRUE)
data_Q_total$IH4Sum <- rowSums(cbind(data_Q_total$IH17.rev, data_Q_total$IH18.rev, data_Q_total$IH19.rev, data_Q_total$IH20.rev, data_Q_total$IH21.rev), na.rm = TRUE)


data_Q_total$IH1Sum[which(data_Q_total$IH1Sum == 0)] <- NA
data_Q_total$IH2Sum[which(data_Q_total$IH2Sum == 0)] <- NA
data_Q_total$IH3Sum[which(data_Q_total$IH3Sum == 0)] <- NA
data_Q_total$IH4Sum[which(data_Q_total$IH4Sum == 0)] <- NA

#sample level sum score descriptives 

#outlier exclusion (IQR)
#Q1 <- quantile(data_Q_total$AOTSum, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_Q_total$AOTSum, 0.75,na.rm=TRUE)
#range <- (IQR(data_Q_total$AOTSum,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_Q_total$AOTSum)
#lowbound
#highbound

#data_Q_total$IH1Sum[which(data_Q_total$IH1Sum < )] <- NA #no outliers
data_Q_total$IH2Sum[which(data_Q_total$IH2Sum < 13)] <- NA 
data_Q_total$IH3Sum[which(data_Q_total$IH3Sum < 7.5)] <- NA
data_Q_total$IH4Sum[which(data_Q_total$IH4Sum < 5)] <- NA

#Summary (mean, skew, kurtosis)
#IH_task <- (describe(data_Q_total$IH1Sum))
#IH_task <- rbind(IH_task,describe(data_Q_total$IH2Sum))
#IH_task <- rbind(IH_task,describe(data_Q_total$IH3Sum))
#IH_task <- rbind(IH_task,describe(data_Q_total$IH4Sum))
#row.names(IH_task) <- c("IH1Sum","IH2Sum","IH3Sum","IH4Sum")
#View(IH_task)

#Shapiro-Wilks
#all nonnormal
#shapiro.test(data_Q_total$IH1Sum)
#shapiro.test(data_Q_total$IH2Sum)
#shapiro.test(data_Q_total$IH3Sum)
#shapiro.test(data_Q_total$IH4Sum)

#plotting
#par(mfrow=c(2,2))
#hist(data_Q_total$IH1Sum,main="Factor 1, independence of intellect and ego",col=rainbow(14),breaks=seq(0,25,1),xlab="")
#hist(data_Q_total$IH2Sum,main="Factor 2, openness to revising one’s viewpoint",col=rainbow(14),breaks=seq(0,25,1),xlab="")
#hist(data_Q_total$IH3Sum,main="Factor 3, respect for others’ viewpoints",col=rainbow(14),breaks=seq(0,25,1),xlab="")
#hist(data_Q_total$IH4Sum,main="Factor 4, lack of intellectual overconﬁdence",col=rainbow(14),breaks=seq(0,25,1),xlab="")

```

##Need for closure

```{r Scoring need for closure, include=FALSE}
## Need for Closure (range 1-6)

#Exclusion criteria
   #Response time (1s/item -> 15000ms total)

## min response time

data_Q_total <- data_Q_total %>%
  mutate(Clo_omit = case_when(END.QUESTIONNAIRE.NEED.CLO <= 15000 ~ 1,
                              END.QUESTIONNAIRE.NEED.CLO > 15000 ~ 0)) 

#add: case_when(Participant.Private.ID == "ppt ID that needs to be rejected for this task")

#again, if Clo_omit=1, that participant's need for closure data should be omitted

#Omitting Need for closure data based on Clo_omit
data_Q_total$closure1[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure2[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure3[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure4[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure5[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure6[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure7[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure8[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure9[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure10[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure11[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure12[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure13[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure14[which(data_Q_total$Clo_omit == 1)] <- NA
data_Q_total$closure15[which(data_Q_total$Clo_omit == 1)] <- NA

## Checking structure with CFA
#one factor?

## Assumptions

#Normality
#par(mfrow=c(3,5))
#hist(data_Q_total$closure1,main="NFC1",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure2,main="NFC2",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure3,main="NFC3",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure4,main="NFC4",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure5,main="NFC5",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure6,main="NFC6",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure7,main="NFC7",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure8,main="NFC8",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure9,main="NFC9",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure10,main="NFC10",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure11,main="NFC11",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure12,main="NFC12",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure13,main="NFC13",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure14,main="NFC14",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$closure15,main="NFC15",col=rainbow(14),breaks=seq(0,6,1),xlab="")

#Summary (mean, skew, kurtosis)
#NFC_item <- (describe(data_Q_total$closure1))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure2))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure3))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure4))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure5))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure6))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure7))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure8))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure9))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure10))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure11))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure12))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure13))
#FC_item <- rbind(NFC_item,describe(data_Q_total$closure14))
#NFC_item <- rbind(NFC_item,describe(data_Q_total$closure15))
#row.names(NFC_item) <- c("closure1","closure2","closure3","closure4","closure5","closure6","closure7","closure8","closure9","closure10","closure11","closure12","closure13","closure14","closure15")
#View(NFC_item)

#Shapiro-Wilks
#all nonnormal
#shapiro.test(data_Q_total$closure1)
#shapiro.test(data_Q_total$closure2)
#shapiro.test(data_Q_total$closure3)
#shapiro.test(data_Q_total$closure4)
#shapiro.test(data_Q_total$closure5)
#shapiro.test(data_Q_total$closure6)
#shapiro.test(data_Q_total$closure7)
#shapiro.test(data_Q_total$closure8)
#shapiro.test(data_Q_total$closure9)
#shapiro.test(data_Q_total$closure10)
#shapiro.test(data_Q_total$closure11)
#shapiro.test(data_Q_total$closure12)
#shapiro.test(data_Q_total$closure13)
#shapiro.test(data_Q_total$closure14)
#shapiro.test(data_Q_total$closure15)



#Using MLE for now as range=5

#what are these numbers?
#CFA
round(cor(data_Q_total[,c(160,162,164,166,168,170,172,174,176,178,180,182,184,186,188)], method = "spearman"),2)
round(cov(data_Q_total[,c(160,162,164,166,168,170,172,174,176,178,180,182,184,186,188)], method = "spearman"),2)
modelClo <- 'Closure =~ closure1 + closure2 + closure3 + closure4 + closure5 + closure6 +              closure7 + closure8 +  closure9 + closure10 + closure11 + closure12 +                     closure13 + closure14 + closure15'
modelClo.est<-cfa(modelClo, data=data_Q_total, std.lv=TRUE) #Same errors
summary(modelClo.est, fit.measures = T, standardized = T)
modindices(modelClo.est, sort = T)

#Need for Closure Scoring
#https://www.midss.org/sites/default/files/need_for_closure_scale.pdf
#Not entirely sure if this is the correct file but it says to sum so I'll do that here

#Calculating Sum score
data_Q_total$CloSum <- rowSums(cbind(data_Q_total$closure1, data_Q_total$closure2, data_Q_total$closure3, data_Q_total$closure4, data_Q_total$closure5, data_Q_total$closure6, data_Q_total$closure7, data_Q_total$closure8, data_Q_total$closure9, data_Q_total$closure10, data_Q_total$closure11, data_Q_total$closure12, data_Q_total$closure13, data_Q_total$closure14, data_Q_total$closure15), na.rm = TRUE)


data_Q_total$CloSum[which(data_Q_total$CloSum == 0)] <- NA

#sample level
#sample level is actually normally distributed

summary(data_Q_total$CloSum)

data_Q_total$CloSum[which(data_Q_total$CloSum > 75)] <- NA


shapiro.test(data_Q_total$CloSum)

#hist(data_Q_total$CloSum,main="Need for Closure",col=rainbow(14),ylim=c(0,12),breaks=seq(0,80,1),xlab="")

#NFC_task <- describe(data_Q_total$CloSum)
#row.names(NFC_task) <- c("CloSum")
#View(NFC_task)

#basic alpha reliability

tibble::as_tibble(data_Q_total)

#already reverse scored
NeedforClos <- select(data_Q_total, closure1,closure2,closure3,closure4,closure5,closure6,closure7,closure8,closure9,closure10,closure11,closure12,closure13,closure14,closure15)

alpha(NeedforClos)
#raw alpha 0.84
#reliability if item dropped; 1 item higher to .85
```

## Need for cognition

```{r Scoring need for cognition, include=FALSE}
## Need for Cognition (range 1-6)

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (because it's a partially reverse-coded scale)
   #Response time (1s/item -> 18000ms total)

## Distribution of responses & response time
#Distribution of responses: there probably is an easier way to do this (maybe by creating a function?) but this is the first way I came up with. Here, I look at the table/distribution of responses for each survey for each participant, creating a separate column with values corresponding to whether the participant's data should be omitted (1=yes=more than 95% of this participant's responses were the same value; 0=no=less than 95% of this participant's response were the same value)

data_Q_total <- data_Q_total %>%
  mutate(Cog_omit = case_when((max((table(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18))) / length(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18))) >= .95) | (END.QUESTIONNAIRE.NEED.COG <= 18000) ~ 1,
         ((max(table(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18))) / length(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18)) < .95) & (END.QUESTIONNAIRE.NEED.COG > 18000) ~ 0))) 

#Omitting Need for cognition data based on Cog_omit column
data_Q_total$cognition1[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition2[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition3.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition4.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition5.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition6[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition7.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition8.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition9.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition10[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition11[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition12.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition13[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition14[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition15[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition16.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition17.rev[which(data_Q_total$Cog_omit == 1)] <- NA
data_Q_total$cognition18[which(data_Q_total$Cog_omit == 1)] <- NA


#Reverse-coding
data_Q_total$cognition3.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition3.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition4.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition4.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition5.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition5.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition7.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition7.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition8.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition8.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition9.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition9.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition12.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition12.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition16.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition16.rev, mini = c(1), maxi = c(6))
data_Q_total$cognition17.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$cognition17.rev, mini = c(1), maxi = c(6))

## Checking structure with CFA

## Assumptions

#Normality
#par(mfrow=c(3,6))
#hist(data_Q_total$cognition1,main="Cognition1",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition2,main="Cognition2",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition3.rev2,main="Cognition3rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition4.rev2,main="Cognition4rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition5.rev2,main="Cognition5rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition6,main="Cognition6",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition7.rev2,main="Cognition7rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition8.rev2,main="Cognition8rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition9.rev2,main="Cognition9rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition10,main="Cognition10",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition11,main="Cognition11",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition12.rev2,main="Cognition12rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition13,main="Cognition13",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition14,main="Cognition14",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition15,main="Cognition15",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition16.rev2,main="Cognition16rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition17.rev2,main="Cognition17rev",col=rainbow(14),breaks=seq(0,6,1),xlab="")
#hist(data_Q_total$cognition18,main="Cognition18",col=rainbow(14),breaks=seq(0,6,1),xlab="")

#Summary (mean, skew, kurtosis)
#Cog_item <- (describe(data_Q_total$cognition1))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition3.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition4.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition5.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition6))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition7.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition8.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition9.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition10))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition11))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition12.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition13))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition14))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition15))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition16.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition17.rev2))
#Cog_item <- rbind(Cog_item,describe(data_Q_total$cognition18))
#row.names(Cog_item) <- c("cognition1","cognition2","cognition3.rev2","cognition4.rev2","cognition5.rev2","cognition6","cognition7.rev2","cognition8.rev2","cognition9.rev2","cognition10","cognition11","cognition12.rev2","cognition13","cognition14","cognition15","cognition16.rev2","cognition17.rev2","cognition18")
#View(Cog_item)


#Shapiro-Wilks
#all nonnormal
#shapiro.test(data_Q_total$cognition1)
#shapiro.test(data_Q_total$cognition2)
#shapiro.test(data_Q_total$cognition3.rev2)
#shapiro.test(data_Q_total$cognition4.rev2)
#shapiro.test(data_Q_total$cognition5.rev2)
#shapiro.test(data_Q_total$cognition6)
#shapiro.test(data_Q_total$cognition7.rev2)
#shapiro.test(data_Q_total$cognition8.rev2)
#shapiro.test(data_Q_total$cognition9.rev2)
#shapiro.test(data_Q_total$cognition10)
#shapiro.test(data_Q_total$cognition11)
#shapiro.test(data_Q_total$cognition12.rev2)
#shapiro.test(data_Q_total$cognition13)
#shapiro.test(data_Q_total$cognition14)
#shapiro.test(data_Q_total$cognition15)
#shapiro.test(data_Q_total$cognition16.rev2)
#shapiro.test(data_Q_total$cognition17.rev2)
#shapiro.test(data_Q_total$cognition18)


#CFA
names(data_Q_total[,c()])
round(cor(data_Q_total[,c()], method = "spearman"),2)
round(cov(data_Q_total[,c()], method = "spearman"),2)
modelCog <- 'Cognition =~ cognition1 + cognition2 + cognition3.rev2 + cognition4.rev2 + cognition5.rev2 + cognition6 + cognition7.rev2 + cognition8.rev2 + cognition9.rev2 + cognition10 + cognition11 + cognition12.rev2 + cognition13 + cognition14 + cognition15 + cognition16.rev2 + cognition17.rev2 + cognition18'
modelCog.est<-cfa(modelCog, data=data_Q_total, std.lv=TRUE) #Same errors
summary(modelCog.est, fit.measures = T, standardized = T)
modindices(modelCog.est, sort = T)

#Need for Cognition Scoring
#https://centerofinquiry.org/uncategorized/need-for-cognition-scale-wabash-national-study/
#According to this source you should calculate the sum score for this scale

#Calculating Sum score
data_Q_total$CogSum <- rowSums(cbind(data_Q_total$cognition1, data_Q_total$cognition2, data_Q_total$cognition3.rev2, data_Q_total$cognition4.rev2, data_Q_total$cognition5.rev2, data_Q_total$cognition6, data_Q_total$cognition7.rev2, data_Q_total$cognition8.rev2, data_Q_total$cognition9.rev2, data_Q_total$cognition10, data_Q_total$cognition11, data_Q_total$cognition12.rev2, data_Q_total$cognition13, data_Q_total$cognition14, data_Q_total$cognition15, data_Q_total$cognition16.rev2, data_Q_total$cognition17.rev2, data_Q_total$cognition18), na.rm=TRUE)

data_Q_total$CogSum[which(data_Q_total$CogSum == 0)] <- NA

#sample level

summary(data_Q_total$CogSum)
data_Q_total$CogSum[which(data_Q_total$CogSum < 51.5)] <- NA

#NFCog_task <- describe(data_Q_total$CogSum)
#row.names(NFCog_task) <- c("NFCog")
#View(NFCog_task)

shapiro.test(data_Q_total$CogSum)

#hist(data_Q_total$CogSum,main="Need for Cognition",col=rainbow(14),ylim=c(0,15),breaks=seq(40,110,1),xlab="")

#basic alpha reliability

tibble::as_tibble(data_Q_total)

#already reverse scored
NeedforCog <- select(data_Q_total, cognition1,cognition2,cognition3.rev2,cognition4.rev2,cognition5.rev2,cognition6,cognition7.rev2,cognition8.rev2, cognition9.rev2,cognition10,cognition11,cognition12.rev2,cognition13,cognition14,cognition15,cognition16.rev2,cognition17.rev2,cognition18)

alpha(NeedforCog)
#raw alpha 0.88
#reliability if item dropped; 2 items higher to .89
#item distribution very skewed
```

## Actively openminded thinking

```{r Scoring actively openminded thinking, include=FALSE}
## Actively Openminded Thinking (range 1-7)

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (because it's a partially reverse-coded scale)
   #response time (1s/item -> 7000ms total)

## Distribution of responses & min response time

data_Q_total <- data_Q_total %>%
  mutate(AOT_omit = case_when(((max(table(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3))) / length(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3))) >= .95) | (END.QUESTIONNAIRE.OPEN.THINK <= 7000) ~ 1,
         ((max(table(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3))) / length(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3)) < .95) & (END.QUESTIONNAIRE.OPEN.THINK > 7000) ~ 0))) #again, if AOT_omit=1, that participant's AOT data should be omitted

#Omitting AOT data based on the AOT_omit column
data_Q_total$openNormal1[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openNormal2[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openNormal3[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openReverse1[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openReverse2[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openReverse3[which(data_Q_total$AOT_omit == 1)] <- NA
data_Q_total$openReverse4[which(data_Q_total$AOT_omit == 1)] <- NA

#Using MLE for nor as range is >5

#Reverse-coding
data_Q_total$open.rev1 <- reverse.code(keys = c(-1), items = data_Q_total$openReverse1, mini = c(1), maxi = c(7))
data_Q_total$open.rev2 <- reverse.code(keys = c(-1), items = data_Q_total$openReverse2, mini = c(1), maxi = c(7))
data_Q_total$open.rev3 <- reverse.code(keys = c(-1), items = data_Q_total$openReverse3, mini = c(1), maxi = c(7))
data_Q_total$open.rev4 <- reverse.code(keys = c(-1), items = data_Q_total$openReverse4, mini = c(1), maxi = c(7))


## Checking the structure with CFA

## Assumptions

#Normality
#par(mfrow=c(2,4))
#hist(data_Q_total$openNormal1,main="ActiveOpen1",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$openNormal2,main="ActiveOpen2",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$openNormal3,main="ActiveOpen3",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$open.rev1,main="ActiveOpen4.rev",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$open.rev2,main="ActiveOpen5.rev",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$open.rev3,main="ActiveOpen6.rev",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")
#hist(data_Q_total$open.rev4,main="ActiveOpen7.rev",col=rainbow(14),ylim=c(0,100),breaks=seq(0,7,1),xlab="")

#Summary (mean, skew, kurtosis)
#ActiveOpen_item <- (describe(data_Q_total$openNormal1))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$openNormal2))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$openNormal3))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$open.rev1))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$open.rev2))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$open.rev3))
#ActiveOpen_item <- rbind(ActiveOpen_item,describe(data_Q_total$open.rev4))
#row.names(ActiveOpen_item) <- c("openNormal1","openNormal2","openNormal3","open.rev1","open.rev2","open.rev3","open.rev4")
#View(ActiveOpen_item)

#Shapiro-Wilks
#nonnormal
#shapiro.test(data_Q_total$openNormal1)
#shapiro.test(data_Q_total$openNormal2)
#shapiro.test(data_Q_total$openNormal3)
#shapiro.test(data_Q_total$open.rev1)
#shapiro.test(data_Q_total$open.rev2)
#shapiro.test(data_Q_total$open.rev3)
#shapiro.test(data_Q_total$open.rev4)


#CFA
names(data_Q_total[,c()])
round(cor(data_Q_total[,c()], method = "spearman"),2)
round(cov(data_Q_total[,c()], method = "spearman"),2)
modelAOT <- 'AOT =~ openNormal1 + openNormal2 + openNormal3 + open.rev1 + open.rev2 + open.rev3 + open.rev4'
modelAOT.est<-cfa(modelAOT, data=data_Q_total, std.lv=TRUE) 
summary(modelAOT.est, fit.measures = T, standardized = T)
modindices(modelAOT.est, sort = T)

#Actively Openminded Thinking Scoring
#https://www.sciencedirect.com/science/article/pii/S1871187119303700
#Again, this article says to do a sum score

#Calculating Sum score
data_Q_total$AOTSum <- rowSums(cbind(data_Q_total$openNormal1, data_Q_total$openNormal2, data_Q_total$openNormal3, data_Q_total$open.rev1, data_Q_total$open.rev2, data_Q_total$open.rev3, data_Q_total$open.rev4), na.rm = TRUE)


data_Q_total$AOTSum[which(data_Q_total$AOTSum == 0)] <- NA

#excluding outliers
#Q1 <- quantile(data_Q_total$AOTSum, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_Q_total$AOTSum, 0.75,na.rm=TRUE)
#range <- (IQR(data_Q_total$AOTSum,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_Q_total$AOTSum)
#lowbound
#highbound

#data_Q_total$AOTSum[which(data_Q_total$AOTSum < )] <- NA # no outliers here


#sample level
#nonnormal

#hist(data_Q_total$AOTSum,main="Actively Openminded Thinking",col=rainbow(14),ylim=c(0,25),breaks=seq(30,50,1),xlab="")

#ActiveOpen_task <- describe(data_Q_total$AOTSum)
#row.names(ActiveOpen_task) <- c("AOT")
#View(ActiveOpen_task)

shapiro.test(data_Q_total$AOTSum)


#a simple reliability

library(psych)
tibble::as_tibble(data_Q_total)

#already reverse scored
AOT <- select(data_Q_total, openNormal1, openNormal2, openNormal3,open.rev1,open.rev2,open.rev3,open.rev4)

alpha(AOT)
#raw alpha 0.69 
#reliability if item dropped; only one is higher and it's to .70
#item distribution very skewed


```


## Matrix Reasoning

This was coded as a Task in Gorilla but analyzed like a questionnaire

```{r Scoring matrix reasoning, include=FALSE}

## ppts with potentially invalid data; check these and replace their sum data with NA if necessary 
#7u35oatv	5555882 : there was a bug
#5jgzfsrk	5608075 : there was a bug
#o1lnepu8	4887607 : did not understand the task

data_matrix.reasoningT$Participant.Private.ID <- factor(data_matrix.reasoningT$Participant.Private.ID)

#Omitting columns that are not relevant (experiment-general columns)
data_matrix.reasoningT <- data_matrix.reasoningT %>%
  select(Participant.Private.ID, Spreadsheet:ANSWER)

#Omitting rows that are not relevant (e.g., practice trials)
data_matrix.reasoningT <- data_matrix.reasoningT %>%
  filter(display %in% c("TehtÃ¤vÃ¤_6", "TehtÃ¤vÃ¤_8"))

#keeping a copy of the original dataset in case something goes wrong with validity
data_matrix.reasoningT_original <- data_matrix.reasoningT
#data_matrix.reasoningT <- data_matrix.reasoningT_original

## Exclusion Criteria
#Median RT & Accuracy

#trying to ID a median reaction time overall to reject ppts, but IQR doesn't work for these kinds of RTs

data_matrix.reasoningT <- data_matrix.reasoningT %>%
  group_by(Participant.Private.ID) %>%
  mutate(medianRT = median(Reaction.Time, na.rm = TRUE)) %>%
  mutate(Matrix_omit = case_when((medianRT > 500) ~ 0,
                                (medianRT <= 500) ~ 1))


#Creating a separate df for subsetting purposes
data_matrix_omit <- data_matrix.reasoningT %>%
  group_by(Participant.Private.ID) %>%
  summarise(Matrix_omit = mean(Matrix_omit)) %>%
  select(Participant.Private.ID, Matrix_omit)


#Extracting the relevant information
data_matrix.reasoningT <- data_matrix.reasoningT %>%
  group_by(Participant.Private.ID) %>%
  summarise(MatrixCorrectCount = sum(Correct, na.rm = TRUE)) %>%
  select(Participant.Private.ID, MatrixCorrectCount)

#Omitting data based on matrix_omit
data_matrix.reasoningT_final <- merge(data_matrix.reasoningT, data_matrix_omit, by = "Participant.Private.ID",all=TRUE)
data_matrix.reasoningT_final$MatrixCorrectCount[which(data_matrix.reasoningT_final$Matrix_omit == "1")] <- NA
data_matrix.reasoningT_final <- data_matrix.reasoningT_final %>%
  select(Participant.Private.ID, MatrixCorrectCount)


# Excluding participants with invalid responses
data_ValidityFlag <- data_validityQ %>%
  select(Participant.Private.ID, Validity.quantised)
data_Language <- data_demographicsQ %>%
  select(Participant.Private.ID, Language)
data_matrixValidity <- merge(data_Language, data_ValidityFlag, by = "Participant.Private.ID",all=TRUE)

data_matrix.reasoningT_final <- merge(data_matrix.reasoningT_final, data_matrixValidity, by = "Participant.Private.ID",all=TRUE)

# from main validity, creating separate df for nonvalid ppts, check against other ppt rejection chunks
data_nonvalid_matrix <- data_matrix.reasoningT_final %>%
  filter(Validity.quantised %in% c("2",3,4))

data_Q_lang_omit_matrix <- data_matrix.reasoningT_final %>%
  filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

data_matrix.reasoningT_final <- data_matrix.reasoningT_final %>%
  filter(Validity.quantised %in% c("1",NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?"))

#omitting specific participants who commented that they had technical issues with this task or did not understand the task
data_matrix.reasoningT_final <- data_matrix.reasoningT_final %>%
  filter(Participant.Private.ID != "5555882" & Participant.Private.ID != "5608075" & Participant.Private.ID != "4887607")


#Deleting the irrelevant columns
data_matrix.reasoningT_final <- data_matrix.reasoningT_final %>%
  select(Participant.Private.ID, MatrixCorrectCount)

#merging with the large final dataframe is done in the section Merging 
#no outliers

#Q1 <- quantile(data_matrix.reasoningT_final$MatrixCorrectCount, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_matrix.reasoningT_final$MatrixCorrectCount, 0.75,na.rm=TRUE)
#range <- (IQR(data_matrix.reasoningT_final$MatrixCorrectCount,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_matrix.reasoningT_final$MatrixCorrectCount)
#lowbound
#highbound

#hist(data_matrix.reasoningT_final$MatrixCorrectCount,main="Matrix Score",col=rainbow(14),ylim=c(0,40),breaks=seq(0,10,1),xlab="")

#Matrix_task <- (describe(data_matrix.reasoningT_final$MatrixCorrectCount))
#row.names(Matrix_task) <- c("Correct")
#View(Matrix_task)

```


## Science Attitudes Questionnaire

This section has 12 questions with Likert responses that represent a (possible) 3 factor model based on the sources of the questions, from an early version of the Science Capital Scale from the FINSCI population survey study. The first 8 questions originally come from Archer, 2015, and the last 4 are modified from the Trust in Science and Scientists Scale (Nadelson et al., 2014). 

There are 3 additional questions that can be analyzed separately or used in demographic info. We hadn't really decided what to do with those questions yet.


```{r Scoring science attitudes, include=FALSE}
## Science Attitudes (range 1-5)

#a) I am aware of science, scientific research and developments in it.
#***b) Science is not for me.
#***d) I don’t think I’m smart enough to understand science.
#g) I have a good understanding of scientific terminology such as hypothesis, theory, experiment and clinical testing.

#c) Young people's interest in science is essential to our future well-being.
#e) Science is so important in our lives that everyone should be interested in it.
#f) Scientific knowledge is useful in my daily life.
#h) Science is important for me to understand the world.

#***a) My confidence in researchers is diminished if they change their perceptions of scientific phenomena.
#***b) Investigators will disregard evidence that is inconsistent with their own work.
#c) Scientific theories are reliable.
#***d) Researchers cannot be trusted because their views are biased.

data_Q_total %>%
  select(Randomise.questionnaire.elements..SCIENCE.ATT:END.QUESTIONNAIRE.SCIENCE.ATT)

#Science identity
data_Q_total %>%
  select(sa.1a, sa.1b, sa.1d, sa.1g) #b, d reverse-coded

#Importance of science in everyday life
data_Q_total %>%
  select(sa.1c, sa.1e, sa.1h, sa.1f)

#Trust in scientists
data_Q_total %>%
  select(sa.2a, sa.2b, sa.2c, sa.2d) #a, b, d reverse-coded

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (because it's a partially reverse-coded scale)
   #response time (1s/item -> 15000ms total)

data_Q_total <- data_Q_total %>%
  mutate(Sci.att_omit = case_when(((max(table(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d))) / length(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d))) >= .95) | (END.QUESTIONNAIRE.SCIENCE.ATT <= 15000) ~ 1,
         ((max(table(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d))) / length(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d)) < .95) & (END.QUESTIONNAIRE.SCIENCE.ATT > 15000) ~ 0))) 


#Omitting SA data based on the Sci.att_omit column
data_Q_total$sa.1a[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1b[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1c[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1d[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1e[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1f[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1g[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.1h[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.2a[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.2b[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.2c[which(data_Q_total$Sci.att_omit == 1)] <- NA
data_Q_total$sa.2d[which(data_Q_total$Sci.att_omit == 1)] <- NA


#Reverse-coding
#there was a mistake and originally sa.1g was coded as reversed, I have now changed the coding for that item
data_Q_total$sa.1b.rev <- reverse.code(keys = c(-1), items = data_Q_total$sa.1b, mini = c(1), maxi = c(5))
data_Q_total$sa.1d.rev <- reverse.code(keys = c(-1), items = data_Q_total$sa.1d, mini = c(1), maxi = c(5))
data_Q_total$sa.2a.rev <- reverse.code(keys = c(-1), items = data_Q_total$sa.2a, mini = c(1), maxi = c(5))
data_Q_total$sa.2b.rev <- reverse.code(keys = c(-1), items = data_Q_total$sa.2b, mini = c(1), maxi = c(5))
data_Q_total$sa.2d.rev <- reverse.code(keys = c(-1), items = data_Q_total$sa.2d, mini = c(1), maxi = c(5))


## Checking the structure with CFA

## Assumptions

#Normality
#these HAVE BEEN reverse coded, so 5 is always MORE SCIENCE
#par(mfrow=c(3,4))
#hist(data_Q_total$sa.1a,main="Science identity 1",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1b.rev,main="Science identity 2 rev",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1d.rev,main="Science identity 3 rev",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1g,main="Science identity 4",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")

#hist(data_Q_total$sa.1c,main="Everyday life 1",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1e,main="Everyday life 2",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1f,main="Everyday life 3",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.1h,main="Everyday life 4",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")

#hist(data_Q_total$sa.2a.rev,main="Trust in scientists 1 rev",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.2b.rev,main="Trust in scientists 2 rev",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.2c,main="Trust in scientists 3",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sa.2d.rev,main="Trust in scientists 4 rev",col=rainbow(14),ylim = c(0,90),breaks=seq(0,5,1),xlab="")


#Summary (mean, skew, kurtosis)
#SA_items <- (describe(data_Q_total$sa.1a))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1b.rev))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1c))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1d.rev))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1e))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1f))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1g))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.1h))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.2a.rev))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.2b.rev))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.2c))
#SA_items <- rbind(SA_items,describe(data_Q_total$sa.2d.rev))
#row.names(SA_items) <- c("sa.1a","sa.1b.rev","sa.1c","sa.1d.rev","sa.1e","sa.1f","sa.1g","sa.1h","sa.2a.rev","sa.2b.rev","sa.2c","sa.2d.rev")
#View(SA_items)


#Shapiro-Wilks
#shapiro.test(data_Q_total$sa.1a)
#shapiro.test(data_Q_total$sa.1b.rev)
#shapiro.test(data_Q_total$sa.1c)
#shapiro.test(data_Q_total$sa.1d.rev)
#shapiro.test(data_Q_total$sa.1e)
#shapiro.test(data_Q_total$sa.1f)
#shapiro.test(data_Q_total$sa.1g)
#shapiro.test(data_Q_total$sa.1h)
#shapiro.test(data_Q_total$sa.2a.rev)
#shapiro.test(data_Q_total$sa.2b.rev)
#shapiro.test(data_Q_total$sa.2c)
#shapiro.test(data_Q_total$sa.2d.rev)


#does this hold up?
#CFA
names(data_Q_total[,c()])
round(cor(data_Q_total[,c()], method = "spearman"),2)
round(cov(data_Q_total[,c()], method = "spearman"),2)
model_Sci.att <- 'Sci_id =~ sa.1a + sa.1b.rev + sa.1d.rev + sa.1g
                  Sci_impo =~ sa.1c + sa.1e + sa.1h + sa.1f
                  Sci_tru =~ sa.2a.rev + sa.2b.rev + sa.2c + sa.2d.rev
Sci_id ~~ Sci_impo
Sci_id ~~ Sci_tru
Sci_impo ~~ Sci_tru'
model_Sci.att.est<-cfa(model_Sci.att, data=data_Q_total, estimator = "MLF",std.lv=TRUE) 
summary(model_Sci.att.est, fit.measures = T, standardized = T)
modindices(model_Sci.att.est, sort = T)


#Calculating Sum score
data_Q_total$Sci.id_Sum <- rowSums(cbind(data_Q_total$sa.1a, data_Q_total$sa.1b.rev, data_Q_total$sa.1d.rev, data_Q_total$sa.1g), na.rm = TRUE)
data_Q_total$Sci.impo_Sum <- rowSums(cbind(data_Q_total$sa.1c, data_Q_total$sa.1e, data_Q_total$sa.1h, data_Q_total$sa.1f), na.rm = TRUE)
data_Q_total$Sci.tru_Sum <- rowSums(cbind(data_Q_total$sa.2a.rev, data_Q_total$sa.2b.rev, data_Q_total$sa.2c, data_Q_total$sa.2d.rev), na.rm = TRUE)

#replace total score zeroes with NA
data_Q_total$Sci.id_Sum[which(data_Q_total$Sci.id_Sum == 0)] <- NA
data_Q_total$Sci.impo_Sum[which(data_Q_total$Sci.impo_Sum == 0)] <- NA
data_Q_total$Sci.tru_Sum[which(data_Q_total$Sci.tru_Sum == 0)] <- NA


#scale level descriptives

#use this to ID outlier boundaries
#Q1 <- quantile(data_Q_total$Sci.id_Sum,na.rm= TRUE, 0.25)
#Q3 <- quantile(data_Q_total$Sci.id_Sum,na.rm=TRUE, 0.75)
#range <- (IQR(data_Q_total$Sci.id_Sum,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_Q_total$Sci.id_Sum)
#lowbound
#highbound

#no outliers in sci.id_sum
#data_Q_total$Sci.id_Sum[which(data_Q_total$Sci.id_Sum == 0)] <- NA
data_Q_total$Sci.impo_Sum[which(data_Q_total$Sci.impo_Sum < 11.5)] <- NA
data_Q_total$Sci.tru_Sum[which(data_Q_total$Sci.tru_Sum < 12)] <- NA

#plot cleaned data

#par(mfrow=c(1,3))
#hist(data_Q_total$Sci.id_Sum,main="Science identity",col=rainbow(14),ylim = c(0,70),breaks=seq(0,20,2),xlab="")
#hist(data_Q_total$Sci.impo_Sum,main="Importance in everyday life",col=rainbow(14),ylim = c(0,70),breaks=seq(0,20,2),xlab="")
#hist(data_Q_total$Sci.tru_Sum,main="Trust in scientists",col=rainbow(14),ylim = c(0,70),breaks=seq(0,20,2),xlab="")

#shapiro.test(data_Q_total$Sci.id_Sum)
#shapiro.test(data_Q_total$Sci.impo_Sum)
#shapiro.test(data_Q_total$Sci.tru_Sum)

#SA_task <- (describe(data_Q_total$Sci.id_Sum))
#SA_task <- rbind(SA_task,describe(data_Q_total$Sci.impo_Sum))
#SA_task <- rbind(SA_task,describe(data_Q_total$Sci.tru_Sum))
#row.names(SA_task) <- c("Sci.id_Sum","Sci.impo_Sum","Sci.tru_Sum")
#View(SA_task)

```


## Science Curiosity

This is a 4-item scale, scored as a single sum score from the quantised responses. No reverse scoring. 
Modified from Landrum et al., 2016 and Motta et al., 2019

```{r Scoring science curiosity, include=FALSE}
## Science Curiosity (Range 1-5)

#How often, if at all, did you attend a science or technology-related public lecture or other presentation (e.g., a webinar) outside of study or work?
 #Not once
 #Once a year
 #Twice a year
 #3-4 times a year
 #More than 5 times a year
#How many books on scientific research or scientific discoveries have you read in the last year?
 #Not at all
 #Equally
 #Two
 #Three or four
 #Five or more
#I am interested in scientific research and scientific discoveries.
#I follow the news about new technologies.
 #Completely disagree
 #Different opinion
 #Neither different nor agree
 #Agree
 #Completely agree


data_Q_total %>%
  select(Randomise.questionnaire.elements..SCIENCE.CUR:END.QUESTIONNAIRE.SCIENCE.CUR) #Note: I am writing the code with the assumption that q2 is a scale as it will be in the later versions

#Exclusion criteria
   #response time (1s/item -> 4000ms total)

data_Q_total <- data_Q_total %>%
  mutate(Sci.cur_omit = case_when(END.QUESTIONNAIRE.SCIENCE.CUR <= 4000 ~ 1,
                                  END.QUESTIONNAIRE.SCIENCE.CUR > 4000 ~ 0))

#Omitting SC data based on the Sci.cur_omit column
data_Q_total$sc.1.quantised[which(data_Q_total$Sci.cur_omit == 1)] <- NA
data_Q_total$sc.2.quantised[which(data_Q_total$Sci.cur_omit == 1)] <- NA
data_Q_total$sc.3.quantised[which(data_Q_total$Sci.cur_omit == 1)] <- NA
data_Q_total$sc.4.quantised[which(data_Q_total$Sci.cur_omit == 1)] <- NA

## Assumptions

#Normality
#par(mfrow=c(2,2))
#hist(data_Q_total$sc.1.quantised,ylim = c(0,80),main="Attending public presentations",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sc.2.quantised,ylim = c(0,80),main="How many books did you read",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sc.3.quantised,ylim = c(0,80),main="Interested in research",col=rainbow(14),breaks=seq(0,5,1),xlab="")
#hist(data_Q_total$sc.4.quantised,ylim = c(0,80),main="Follow new technology",col=rainbow(14),breaks=seq(0,5,1),xlab="")

#Summary (mean, skew, kurtosis)
#SC_items <- (describe(data_Q_total$sc.1.quantised))
#SC_items <- rbind(SC_items,describe(data_Q_total$sc.2.quantised))
#SC_items <- rbind(SC_items,describe(data_Q_total$sc.3.quantised))
#SC_items <- rbind(SC_items,describe(data_Q_total$sc.4.quantised))
#row.names(SC_items) <- c("sc.1","sc.2","sc.3","sc.4")
#View(SC_items)

#Shapiro-Wilks
#shapiro.test(data_Q_total$sc.1.quantised)
#shapiro.test(data_Q_total$sc.2.quantised)
#shapiro.test(data_Q_total$sc.3.quantised)
#shapiro.test(data_Q_total$sc.4.quantised)

#CFA
#names(data_Q_total[,c()])
#round(cor(data_Q_total[,c()], method = "spearman"),2)
#round(cov(data_Q_total[,c()], method = "spearman"),2)
#model_Sci.cur <- 'Sci_id =~ sc.1.quantised + sc.2.quantised + sc.3.quantised + sc.4.quantised'
#model_Sci.cur.est<-cfa(model_Sci.cur, data=data_Q_total, std.lv=TRUE)
#summary(model_Sci.cur.est, fit.measures = T, standardized = T)
#modindices(model_Sci.cur.est, sort = T)


#Calculating Sum score
data_Q_total$Sci.cur_Sum <- rowSums(cbind(data_Q_total$sc.1.quantised, data_Q_total$sc.2.quantised, data_Q_total$sc.3.quantised, data_Q_total$sc.4.quantised), na.rm = TRUE)

data_Q_total$Sci.cur_Sum[which(data_Q_total$Sci.cur_Sum == 0)] <- NA

#Q1 <- quantile(data_Q_total$Sci.cur_Sum, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_Q_total$Sci.cur_Sum, 0.75,na.rm=TRUE)
#range <- (IQR(data_Q_total$Sci.cur_Sum,na.rm=TRUE)*1.5)
#lowbound <- Q1 - range
#highbound <- Q3 + range
#highbound
#lowbound
# no outliers here

#sum score distribution
#SC_items <- (describe(data_Q_total$Sci.cur_Sum))
#row.names(SC_items) <- c("Sci.cur_Sum")
#View(SC_items)

#shapiro.test(data_Q_total$Sci.cur_Sum)

#hist(data_Q_total$Sci.cur_Sum,ylim = c(0,40),main="Science curiosity",col=rainbow(14),breaks=seq(0,20,2),xlab="")

```

##Heuristic Reasoning

***is this scoring method correct??***

6 items selected from Morsanyi et al., 2009. Each question has three possible answers: normative (correct), incorrect, and heuristic. The heuristic response options are either Representativeness Heuristic or Equiprobability Heuristic, depending on the question. The 3 final scores of interest (H-R, H-E, and N) are calculated as a percentage of total (6) responses. E.g. if a ppt gives N responses for questions 1, 2, 4, and 5, and heuristic responses for questions 3 and 6, their scores are: .17, .17, and .67. The heuristic responses can be calculated as either a percentage of each category (1/3) or of the total (1/6)--they will be proportional to each other, so it doesn't really matter.

For these purposes, incorrect answers will be excluded from analysis because they are not useful as most people don't give any wrong answers, and heuristic responses are binned together per participant. Participants each then have an HE score (0 or 1), and an HR score (0 or 1), each representing whether or not they made at least one heuristic mistake of that type (equiprobability or representativeness). 0 0 is a perfect normative tendency. 

H-R: #Q1,2,3
H-R: #Q4,5,6

```{r Scoring heuristic reasoning, include=FALSE}

#Exclusion criteria
   #distribution of responses for each survey per participant: if >95% of responses fall on the same response option (e.g., 6), data for that participant for that survey should be omitted (because it's a partially reverse-coded scale)
   #response time (1s/item -> 6000ms total)

## min response time
data_Q_total <- data_Q_total %>%
  mutate(HR_omit = case_when(END.QUESTIONNAIRE.HEURISTIC <= 6000 ~ 1,
                             END.QUESTIONNAIRE.HEURISTIC > 6000 ~ 0))

#Q1
#Luonnollinen sukupuolijakauma syntyvien lasten osalta on arviolta yksi mies naista kohden. Tämä tarkoittaa sitä, että syntyvä lapsi on 50% todennäköisyydellä poika ja 50 % todennäköisyydellä tyttö. Kuvittele perhe, johon on syntynyt viisi lasta, kaikki heistä poikia. Mikä seuraavista on todennäköisin?
 #Kuudes lapsi on tyttö = H-R
 #Kuudes lapsi on poika = X
 #Kumpikin on yhtä todennäköistä = N

data_Q_total$hr.1 <- as.factor(data_Q_total$hr.1)
#data_Q_total$hr.1 <- factor(data_Q_total$hr.1, levels = c(levels(data_Q_total$hr.1), "Kuudes lapsi on tyttÃ¶", "Kuudes lapsi on poika"))

#levels(data_Q_total$hr.1) #I added an empty level here as we do not currently have answers on each level; this enables renaming all the levels **DOES NOT NEED TO BE DONE FOR FINAL DATA**

levels(data_Q_total$hr.1) <- list("N"="Kumpikin on yhtÃ¤ todennÃ¤kÃ¶istÃ¤", "H-R" = "Kuudes lapsi on tyttÃ¶", "Neither"= "Kuudes lapsi on poika")
data_Q_total$hr.1
#Yhta todennakoista = N; Tytto = H-R
#barplot(table(data_Q_total$hr.1),ylim=(c(0,160)),main="H-R child",col = rainbow(14))

#Q2
#Kolikkoa heitetään kuusi kertaa. Kumpi seuraavista sarjoista on todennäköisempi kuuden kolikonheiton jälkeen? (H: Head = kruuna, T: Tails = klaava)
 #THHTHT
 #HTHTHT
 #Kummatkin sarjat ovat yhtä todennäköisiä
data_Q_total$hr.2 <- as.factor(data_Q_total$hr.2)

#data_Q_total$hr.2 <- factor(data_Q_total$hr.2, levels = c(levels(data_Q_total$hr.2), "THHTHT", "HTHTHT")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**

levels(data_Q_total$hr.2) <- list("N" = "Kummatkin sarjat ovat yhtÃ¤ todennÃ¤kÃ¶isiÃ¤", "H-R" = "THHTHT", "Neither" = "HTHTHT")
data_Q_total$hr.2
#Yhta todennakoista = N; THHTHT = H-R

#Q3
#Terveystutkimus toteutettiin 100 aikuisen miehen otokselle, jossa kaikki ikäluokat ja ammattiryhmät olivat edustettuina. Herra F. valittiin osallistujien joukosta satunnaisesti. Herra F. on johtaja. Hän vietti pitkään todella kiireistä elämää. Hän osallistui useina iltoina yritysillallisiin ja hän oli harvoin lomalla. Hiljattain hänen piti lopettaa työskentely vähäksi aikaa. Hän on aloittanut työskentelyn uudelleen, mutta nykyisin hän ei ole yhtä kiireinen. Aiemmin hän hölkkäsi puistossa, mutta nyt hän menee mieluummin kävelylle. Raahaa seuraavat väittämät järjestykseen siten, että todennäköisin on ylimpänä ja epätodennäköisin alimpana.
#Todennäköisin

 #Herra F. on yli 55-vuotias ja on saanut sydänkohtauksen
 #Herra F. sai sydänkohtauksen
 #Herra F.:llä on suuri perhe

#Giving lower rating to response a.) than to response b.) is considered a heuristic response (H-R), and the opposite of this is considered a normative response (N).


#3.1
data_Q_total$hr.3.1 <- as.factor(data_Q_total$hr.3.1)

#data_Q_total$hr.3.1 <- factor(data_Q_total$hr.3.1, levels = c(levels(data_Q_total$hr.3.1), "Herra F.:llÃ¤ on suuri perhe", "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**

levels(data_Q_total$hr.3.1) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")

#3.2
data_Q_total$hr.3.2 <- as.factor(data_Q_total$hr.3.2)
#data_Q_total$hr.3.2 <- factor(data_Q_total$hr.3.2, levels = c(levels(data_Q_total$hr.3.2), "Herra F.:llÃ¤ on suuri perhe", "Herra F. sai sydÃ¤nkohtauksen")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**
levels(data_Q_total$hr.3.2) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")

#3.3
data_Q_total$hr.3.3 <- as.factor(data_Q_total$hr.3.3)
#data_Q_total$hr.3.3 <- factor(data_Q_total$hr.3.3, levels = c(levels(data_Q_total$hr.3.3), "Herra F. sai sydÃ¤nkohtauksen", "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**
levels(data_Q_total$hr.3.3)
levels(data_Q_total$hr.3.3) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")


#Creating the variables for the combinations of answers
#abc / acb / cab = N; bac / bca /cba = H-R
data_Q_total <- data_Q_total %>%
  mutate(hr.3.updated = case_when(
  ((hr.3.1 == "b" & (hr.3.2 == "a"|hr.3.3 == "a")) | hr.3.2 == "b" & hr.3.3 == "a") ~ "H-R",
  ((hr.3.1 == "a" & (hr.3.2 == "b"|hr.3.3 == "b")) | (hr.3.2 == "a" & hr.3.3 == "b")) ~ "N"
  ))
data_Q_total$hr.3.updated <- factor(data_Q_total$hr.3.updated)


#Q4

#Kaksi eri tutkimusta selvittivät unettomuuden hoidossa kahden eri hoitomuodon vaikuttavuutta. Ensimmäisessä tutkimuksessa 400 lääkettä saaneesta henkilöstä 140 sai huomattavaa helpotusta. Toisessa tutkimuksessa 40 kognitiivis-behavioraalista terapiaa saaneesta potilaasta 16 kykeni nukkumaan paremmin kuin ennen hoitoa. Kumpaa hoitoa (jos kumpaakaan) suosittelisit unettomalle potilaalle?
 #Lääkehoitoa
 #Kognitiivis-behavioraalista terapiaa
 #Kumpikin on yhtä tehokas

data_Q_total$hr.4 <- as.factor(data_Q_total$hr.4)
#data_Q_total$hr.4 <- factor(data_Q_total$hr.4, levels = c(levels(data_Q_total$hr.4), "LÃ¤Ã¤kehoitoa", "Kumpikin on yhtÃ¤ tehokas")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**
levels(data_Q_total$hr.4) <- list("H-E" = "Kumpikin on yhtÃ¤ tehokas", "N" = "Kognitiivis-behavioraalista terapiaa", "Neither" = "LÃ¤Ã¤kehoitoa")
data_Q_total$hr.4
#Kognitiivis-behavioraalista terapiaa = N; Yhta tehokas = H-E

#Q5
#Mitä tarkoittaa, kun sääennusteessa kerrotaan sateen todennäköisyyden olevan huomenna 70%?
 #Huomenna luultavasti sataa
 #On mahdotonta sanoa sataako huomenna vai ei
 #Huomenna sataa

data_Q_total$hr.5 <- as.factor(data_Q_total$hr.5)
#data_Q_total$hr.5 <- factor(data_Q_total$hr.5, levels = c(levels(data_Q_total$hr.5), "Huomenna luultavasti sataa", "Huomenna sataa")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**
levels(data_Q_total$hr.5) <- list("N" = "Huomenna luultavasti sataa", "H-E" = "On mahdotonta sanoa sataako huomenna vai ei", "Neither" = "Huomenna sataa")
data_Q_total$hr.5
#Huomenna luultavasti sataa = N; On mahdotonta sanoa sataako huomenna vai ei = H-E

#Q6
#Luokassa on 13 poikaa ja 16 tyttöä. Opettaja suorittaa arvonnan. Jokaisen oppilaan nimi on kirjoitettuna paperilapulle. Kaikki laput laitetaan hattuun. Opettaja nostaa yhden lapun katsomatta hattuun. Kuka voittaa arvonnassa?
 #Poika
 #Tyttö
 #Kumpikin on yhtä todennäköistä

data_Q_total$hr.6 <- as.factor(data_Q_total$hr.6)
#data_Q_total$hr.6 <- factor(data_Q_total$hr.6, levels = c(levels(data_Q_total$hr.6), "Kumpikin on yhtÃ¤ todennÃ¤kÃ¶istÃ¤")) #adding empty levels for renaming purposes **DOES NOT NEED TO BE DONE FOR FINAL DATA**
levels(data_Q_total$hr.6) <- list("N" = "TyttÃ¶", "H-E" = "Kumpikin on yhtÃ¤ todennÃ¤kÃ¶istÃ¤", "Neither" = "Poika")
data_Q_total$hr.6
#Tytto = N; Kumpikin on yht? todenn?k?ist? = H-E

#Sums
data_Q_total <- data_Q_total %>%
  mutate(
    total_N = apply(., 1, function(x) length(which(x == "N"))),
    total_HR = apply(., 1, function(x) length(which(x == "H-R"))),
    total_HE = apply(., 1, function(x) length(which(x == "H-E"))),
    total_Neither = apply(., 1, function(x) length(which(x == "Neither")))
  )

#Omitting heuristic reasoning data based on the HR_omit column
data_Q_total$total_N[which(data_Q_total$HR_omit == 1)] <- NA
data_Q_total$total_HR[which(data_Q_total$HR_omit == 1)] <- NA
data_Q_total$total_HE[which(data_Q_total$HR_omit == 1)] <- NA
data_Q_total$total_Neither[which(data_Q_total$HR_omit == 1)] <- NA

#this replaces the zeroes in these new columns with NA--only if there are zeroes in all 4 of these sum columns, because that indicates missing data (the participant didn't do the task), not true zeroes. The lines going down are different because after the first column's value gets replaced with NA, the logic of the whole set is changed, so there is now a combination of NAs and zeroes
data_Q_total$total_N[which(data_Q_total$total_N == 0 & data_Q_total$total_HR == 0 & data_Q_total$total_HE == 0 & data_Q_total$total_Neither == 0)] <- NA
data_Q_total$total_HR[which(is.na(data_Q_total$total_N) == TRUE & data_Q_total$total_HR == 0 & data_Q_total$total_HE == 0 & data_Q_total$total_Neither == 0)] <- NA
data_Q_total$total_HE[which(is.na(data_Q_total$total_N) == TRUE & is.na(data_Q_total$total_HR) == TRUE & data_Q_total$total_HE == 0 & data_Q_total$total_Neither == 0)] <- NA
data_Q_total$total_Neither[which(is.na(data_Q_total$total_N) == TRUE & is.na(data_Q_total$total_HR) == TRUE & is.na(data_Q_total$total_HE) == TRUE & data_Q_total$total_Neither == 0)] <- NA

#creating the proportion scores per type
#data_Q_total$Nprop <- (data_Q_total$total_N/6)
#data_Q_total$HRprop <- (data_Q_total$total_HR/6)
#data_Q_total$HEprop <- (data_Q_total$total_HE/6)

#copying the heuristic scores to new variables
data_Q_total$HEscore <- data_Q_total$total_HE
data_Q_total$HRscore <- data_Q_total$total_HR

#converting the new variables to binary while preserving the original sums. If a ppt's total HE or HR score is 1 or greater, they get a 1 for that category
data_Q_total$HEscore[which(data_Q_total$HEscore >= 1)] <- 1
data_Q_total$HRscore[which(data_Q_total$HRscore >= 1)] <- 1

#adding an additional measure of total heuristic response. 1 = at least one mistake in one heuristic category, 2 = at least 1 heuristic mistake in both heuristic categories, 0 = all normative responses
data_Q_total <- data_Q_total %>%
group_by(Participant.Private.ID) %>% 
  mutate(HEHRscore = HEscore + HRscore)
        

#sample wise frequency distributions
#par(mfrow=c(2,3))
#barplot(table(data_Q_total$total_N),ylim=(c(0,160)),main="Total N",col = rainbow(14))
#barplot(table(data_Q_total$total_HR),ylim=(c(0,160)),main="Total HR",col = rainbow(14))
#barplot(table(data_Q_total$total_HE),ylim=(c(0,160)),main="Total HE",col = rainbow(14))
#barplot(table(data_Q_total$total_Neither),ylim=(c(0,160)),main="Total X",col = rainbow(14))
#barplot(table(data_Q_total$HEscore),ylim=(c(0,160)),main="HEscore",col = rainbow(14))
#barplot(table(data_Q_total$HRscore),ylim=(c(0,160)),main="HRscore",col = rainbow(14))

#par(mfrow=c(1,3))
#hist(data_Q_total$Nprop,main="Normative %",col=rainbow(14),breaks=seq(0,1,0.2),xlab="")
#hist(data_Q_total$HRprop,main="Representativeness %",col=rainbow(14),breaks=seq(0,1,0.2),xlab="")
#hist(data_Q_total$HEprop,main="Equiprobability %",col=rainbow(14),breaks=seq(0,1,0.2),xlab="")

#Heuristics_task <- (describe(data_Q_total$HEscore))
#Heuristics_task <- rbind(Heuristics_task,describe(data_Q_total$HRscore))
#Heuristics_task <- rbind(Heuristics_task,describe(data_Q_total$HEHRscore))
#row.names(Heuristics_task) <- c("HEScore","HRScore","HEHRScore")
#View(Heuristics_task)

#sum(as.numeric(data_Q_total$HRscore),na.rm=TRUE)
#[1] 91 # this means 91 ppts made at least 1 representativeness error 
#sum(as.numeric(data_Q_total$HEscore),na.rm=TRUE)
#[1] 94 # this means 94 ppts made at least 1 equiprobability error 

```


## Randomness and Probability

This section is complicated because each question is scored differently. It could probably use cleaned up, and see if there is a way to more straightforwardly not end up with spurious zeroes. 

```{r Scoring randomness and probability, include=FALSE}

#Exclusion criteria
   #response time (1s/item -> 7000ms total)

## min response time
data_Q_total <- data_Q_total %>%
  mutate(RP_omit = case_when(END.QUESTIONNAIRE.RANDOM.PROB <= 4000 ~ 1,
                             END.QUESTIONNAIRE.RANDOM.PROB > 4000 ~ 0))

#Q1
#Sairaala B is the correct answer
class(data_Q_total$rp.1) 
data_Q_total$rp.1 <- as.factor(data_Q_total$rp.1) #transforming into a factor
levels(data_Q_total$rp.1)

#Creating a new column
data_Q_total <- data_Q_total %>%
  mutate(rp.1.int = case_when(rp.1 == "Sairaalassa B (jossa syntyy 10 lasta pÃ¤ivÃ¤ssÃ¤)." ~ 1,
                              rp.1 != "Sairaalassa B (jossa syntyy 10 lasta pÃ¤ivÃ¤ssÃ¤)." ~ 0)) #rows with correct answer take value 1 in the new column

#Q2
#Robottiteht?v?: Pyydys1 AND Pyydys 2. You only get a point if you have both of these and no other options.
class(data_Q_total$rp.2.1) 
data_Q_total$rp.2.1 <- as.factor(data_Q_total$rp.2.1)
levels(data_Q_total$rp.2.1)
data_Q_total$rp.2.2 <- as.factor(data_Q_total$rp.2.2)
data_Q_total$rp.2.3 <- as.factor(data_Q_total$rp.2.3)
data_Q_total$rp.2.4 <- as.factor(data_Q_total$rp.2.4)
data_Q_total$rp.2.5 <- as.factor(data_Q_total$rp.2.5)
data_Q_total$rp.2.6 <- as.factor(data_Q_total$rp.2.6)
data_Q_total$rp.2.7 <- as.factor(data_Q_total$rp.2.7)
data_Q_total$rp.2.8 <- as.factor(data_Q_total$rp.2.8)


#Creating a new column
#original code used isn.na(var) for the first chunk (assigning 1 point to correct answers) but the df cells are blank, not NA, so there were no correct answers. Can use the empty string "" for blank cells. This way assigns 1 to all cases that match the one correct answer combination and NA to anything else.  This way avoids missing something if we were to try to list all the possible combinations.

data_Q_total <- data_Q_total %>%
  mutate(rp.2.int = case_when((rp.2.1 == "Pyydys 1" & rp.2.2 == "Pyydys 2" & rp.2.3 == "" & rp.2.4 == "" & rp.2.5 == "" & rp.2.6 == "" & rp.2.7 == "" & rp.2.8 == "") ~ 1))
  
#this keeps the 1s but replaces NAs with zeroes. In the last part of this chunk, we'll NA all ppts who didn't actually complete this task and get rid of any spurious zeroes
data_Q_total <- data_Q_total %>%
  mutate(rp.2.int = case_when(rp.2.int == "1" ~ 1,
                            (is.na(rp.2.int) ~ 0)))       

#Q3
#Kanava 1; 2 tai 3 is the correct answer
#It's easier to use rp.3.quantised to score this question than deal with the strings
#Kanava 1; 2 tai 3 = 4
#Kanava 2 tai 3 = 2
#Kanava 2 = 5
#Kanava 1 tai 3 = 3
#Kanava 1 tai 2 = 7
#Kanava 3 = 6

#class(data_Q_total$rp.3.quantised)

#Creating a new column
data_Q_total <- data_Q_total %>%
  mutate(rp.3.int = case_when(rp.3.quantised == "4" ~ 1,
                              rp.3.quantised != "4" ~ 0))

#Q4
#Ruudukot A; B ja C is the correct answer
#used rp.4.quantised for scoring this one too
###Ruudukot A; B ja C = 5
#Ruudukko B = 2
#Ruudukko A = 1
#Ruudukko C = 3
#Ruudukot A ja C = 4

#class(data_Q_total$rp.4)

data_Q_total <- data_Q_total %>%
  mutate(rp.4.int = case_when(rp.4.quantised == "5" ~ 1,
                              rp.4.quantised != "5" ~ 0))

#Calculating the sum score for the randomness/probability questions
data_Q_total <- data_Q_total %>%
  mutate(RPSum = rp.1.int + rp.2.int + rp.3.int + rp.4.int)



#Omitting Randomness-Probability data based on the RP_omit column
data_Q_total$RPSum[which(data_Q_total$RP_omit == 1)] <- NA
data_Q_total$RPSum[which(is.na(data_Q_total$RP_omit))] <- NA 
#The way we've processed the questions resulted in some spurious zeroes, e.g. for ppts who didn't actually complete the task. If RP_omit = NA, then the ppt didn't do the task, and RPSum is replaced with NA based on this.  
#An alternative way to do it:
#data_Q_total$RPSum <- rowSums(cbind(data_Q_total$rp.1.int, data_Q_total$rp.2.int, data_Q_total$rp.3.int, data_Q_total$rp.4.int), na.rm=TRUE)

#hist(data_Q_total$RPSum,main="Randomness/Probability Sum Score",col=rainbow(14),breaks=seq(0,4,1),xlab="")

#RP_task <- (describe(data_Q_total$RPSum))
#row.names(RP_task) <- c("RPSum")
#View(RP_task)

```


# Merging Questionnaire variables

```{r Merging questionnaire variables, include=FALSE}
## Merging the important columns
data_Q_sub <- data_Q_total %>%
  select(Participant.Private.ID, gender, Age, Country, Language, Education, AMean, CMean, EMean, ESMean, OMean, ICuriositySum, DCuriositySum, IH1Sum, IH2Sum, IH3Sum, IH4Sum, CloSum, CogSum, AOTSum, HEscore, HRscore, RPSum, Sci.cur_Sum, Sci.tru_Sum, Sci.impo_Sum, Sci.id_Sum)

#for now leaving out this variable I created that isn't in the original variable list
#HEHRscore

#Adding matrix to the dataframe
#I think this syntax can be used to add all the other parts not included in data_Q_total, because they are within their own dfs but do not need to be added to data_Q_total first if they're able to be added separately here 
#double check that merge is keeping unique rows; if not, use cbind 
#this has to be added separately because it's a questionnaire coded as a task. Other task variables are put into their own dataframe separately which can be merged to create a total minimal variable set for EFA

data_Q_sub <- merge(data_Q_sub, data_matrix.reasoningT_final, by = "Participant.Private.ID", all=TRUE)

#Make sure to include the argument all= TRUE! This includes rows that contain NA, which is necessary to include ppts with missing data. The default in merge() is to get rid of rows containing NA. 

#use this to get rid of NaNs or string NAs introduced by calculations
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))

data_Q_sub[is.nan(data_Q_sub)] <- NA

#probably need to coerce the numeric variables to numeric, don't do the whole data frame because then you lose the factors. Do it here so you don't have to do it later.
data_Q_sub$MatrixCorrectCount <- as.numeric(data_Q_sub$MatrixCorrectCount)
data_Q_sub$Age <- as.numeric(data_Q_sub$Age)


```

# Q missing data

Analyzing missing data in questionnaires. 

Better to do this for tasks and questionnaires separately, because they have different reasons for being missing and different implications. Do this before checking distributions because ppts with large amounts of missing data or suspicious patterns of missing data are removed here from the final dataset. 

Current N after this chunk N=162 

```{r Analyzing Q missing data, include=FALSE}

#some cool missing data packages
library(ggplot2)
library(naniar)

#add a column for count of missing data per ppt, to sub df
data_Q_sub <- data_Q_sub %>%
  mutate(missingdata = rowSums(is.na(data_Q_sub)))

View(data_Q_sub)

#hard to ID a cutoff point because cutting at the elbow gets rid of too much data. 11 missing variables is ppts with at least 50% of usable data--about 5 ppts difference between cutoff of 30% or 50% (11 or 15 variables)
#we need to specify some cutoff point because 20 missing variables out of 22 is too many 
ggplot(data_Q_sub, aes(x=as.factor(Participant.Private.ID), y=missingdata)) + 
     geom_boxplot(fill="slateblue", alpha=0.2) + 
     xlab("Missing variables count")

#see if there's an elbow in the number of missing variables per ppt
MissingData<-sort(data_Q_sub$missingdata, decreasing = FALSE)
plot(MissingData)

gg_miss_fct(x = data_Q_sub, fct = Age)
cor.test(data_Q_sub$Age,data_Q_sub$missingdata,method="spearman",exact=FALSE)

#visualizing missing data by demographics
gg_miss_fct(x = data_Q_sub, fct = Language)
gg_miss_fct(x = data_Q_sub, fct = Country)
gg_miss_fct(x = data_Q_sub, fct = gender)
gg_miss_fct(x = data_Q_sub, fct = Education)

#removing ppts with 16 or fewer variables missing out of total 22 (30%)
data_Q_sub <- data_Q_sub %>%
  group_by(Participant.Private.ID) %>%
  filter(missingdata < 16)

View(data_Q_sub)

```


# Q distributions and correlations

This chunk checks distributions of questionnaire variables and correlations between them. It's recommended that if two variables are highly correlated, to drop one of them. 

It also transforms variables that need to be transformed--no transformations applied yet.


```{r Checking the normality of the questionnaire variables, include=FALSE}

#Further subsetting the data as we probably won't need the demographic variables here (?)
#data_Q_sub2 <- data_Q_sub %>%
  #select(AMean:MatrixCorrectCount)

## Normality of variables: visualising with histograms
AMean <- ggplot(data_Q_sub, aes(x=AMean)) +
  geom_histogram(color = "black", fill = "lightblue")
AMean
CMean <- ggplot(data_Q_sub, aes(x=CMean)) +
  geom_histogram(color = "black", fill = "lightblue")
CMean
EMean <- ggplot(data_Q_sub, aes(x=EMean)) +
  geom_histogram(color = "black", fill = "lightblue")
EMean
OMean <- ggplot(data_Q_sub, aes(x=OMean)) +
  geom_histogram(color = "black", fill = "lightblue")
OMean
ESMean <- ggplot(data_Q_sub, aes(x=ESMean)) +
  geom_histogram(color = "black", fill = "lightblue")
ESMean
ICuriositySum <- ggplot(data_Q_sub, aes(x=ICuriositySum)) +
  geom_histogram(color = "black", fill = "lightblue")
ICuriositySum
DCuriositySum <- ggplot(data_Q_sub, aes(x=DCuriositySum)) +
  geom_histogram(color = "black", fill = "lightblue")
DCuriositySum
IH1Sum <- ggplot(data_Q_sub, aes(x=IH1Sum)) +
  geom_histogram(color = "black", fill = "lightblue")
IH1Sum
IH2Sum <- ggplot(data_Q_sub, aes(x=IH2Sum)) +
  geom_histogram(color = "black", fill = "lightblue")
IH2Sum
IH3Sum <- ggplot(data_Q_sub, aes(x=IH3Sum)) +
  geom_histogram(color = "black", fill = "lightblue")
IH3Sum
IH4Sum <- ggplot(data_Q_sub, aes(x=IH4Sum)) +
  geom_histogram(color = "black", fill = "lightblue")
IH4Sum
CloSum <- ggplot(data_Q_sub, aes(x=CloSum)) +
  geom_histogram(color = "black", fill = "lightblue")
CloSum
CogSum <- ggplot(data_Q_sub, aes(x=CogSum)) +
  geom_histogram(color = "black", fill = "lightblue")
CogSum
AOTSum <- ggplot(data_Q_sub, aes(x=AOTSum)) +
  geom_histogram(color = "black", fill = "lightblue")
AOTSum

RPSum <- ggplot(data_Q_sub, aes(x=RPSum)) +
  geom_histogram(color = "black", fill = "lightblue")
RPSum
MatrixCorrectCount <- ggplot(data_Q_sub, aes(x=MatrixCorrectCount)) +
  geom_histogram(color = "black", fill = "lightblue")
MatrixCorrectCount


#Transformations 

## Normality of variables: skewness
#which(abs(skew(data_Q_sub))>1) 
#almost all variables are skewed to some extent...

## Correlation matrix
#If two (or more) variables from the same questionnaire or task correlate so that r>.85, one of them should be omitted (from Eisenberg et al.)
#no omissions needed from questionnaires

#check the indexes, it changes if you've deleted the demographic columns
#no strong corelations in TIPI
#TRUE values: we should consider omitting one of the variables 
cor(data_Q_sub[,2:6], method = "pearson", use = "pairwise.complete.obs")  
abs(cor(data_Q_sub[,2:6], method = "pearson", use = "pairwise.complete.obs")) > .85 

#correlation 0.558, but I think EC is supposed to correlate, and is still under .85
cor(data_Q_sub[,7:8], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[,7:8], method = "pearson", use = "pairwise.complete.obs")) > .85

#no strong correlations in intellectual humility either
cor(data_Q_sub[,9:12], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[,9:12], method = "pearson", use = "pairwise.complete.obs")) > .85

#no strong correlations in science attitudes either
cor(data_Q_sub[,20:22], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[,20:22], method = "pearson", use = "pairwise.complete.obs")) > .85

#subsetting now: this is the cleaned copy with only variables to be used in EFA
data_Q_sub <- data_Q_sub %>%
  select(AMean:MatrixCorrectCount)

``` 


# Tasks

It's useful to extract the information we want for each participant, and then merge that to the questionnaire data (for example); this way we can keep the data in short/wide format. The following chunks process each task and then a small chunk merges them to the main task dataframe, which can then be merged to the questionnaire df if necessary to combine tasks and questionnaires in the EFA. 

It should be noted that I only omitted participants who did not consent/stated their responses are not valid at the very end of each chunk, i.e. after cleaning the data and extracting the relevant info. This has to be done for each task chunk separately, whereas it was done at the beginning of the questionnaire chunks for all questionnaires. 

Tasks also include lines to exclude outlier *trials* based on reaction time, since individual trials with outlier RTs probably indicate 1) technical error, 2)ppts pressing buttons without trying, 3)long RTs caused by ppts taking unsanctioned breaks. 

Participants who stopped the study during a Task have all their data from that Task excluded, because that data is not Missing At Random and thus affects both total scores/calculations and the validity of the data. 

## Go No Go
N=134 usable ppts (146??)


```{r Go No-Go, include=FALSE}

#potentially problematic ppts, check if data needs to be made NA 
# 0vnopw72	5845513 : was interrupted in the task 

#It's not really possible to exclude ppts who stopped in the middle of this task any other way. These ppts stopped the experiment during GNG.
# 7mik8ed5 4886650
# xt9lwzwk 5117494
# 73bdl37a 5282634
# tfn355ew 5500754
# 5aakmlti 5552405
# kqn3t62x 5635997


data_go.nogoT$Participant.Private.ID <- factor(data_go.nogoT$Participant.Private.ID)

## Omitting experiment-general columns & practice (etc.) rows
data_go.nogoT <- data_go.nogoT %>%
  select(Participant.Private.ID, Spreadsheet:Answer)  %>%
  filter(display == "Trials")

#Outlier trial exclusions first
# interquartile range: 1.5*(Q3-Q1), subtract this value from Q1 and add to Q3 to get the outlier boundaries. Here it was 1072. At least everything above 4000 is clearly an outlier, according to boxplots there are 4 trials between 1072 and 3000 that are also outliers. Need to do this first because outlier trials mess up the ppt level calculations. 
#In GNG the screens advance automatically after 1000ms (250ms stimulus presentation and 750ms wait, so e.g. a no-go response should be recorded as 1000ms). According to Gorilla, there is also the 16.67ms refresh rate and about 8ms latency between a computer and mouse, which adds something. https://support.gorilla.sc/support/info/timing#onlinetimingaccuracy A glance says that most NG responses are only up to about 1004ms, but it could be that there are some up to 1050? 

# Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
#  0      342      416     1113      634 20694243

#trying to ID a median reaction time overall to reject ppts, but this doesn't work for Matrix because the RTs are so variable
#Q1 <- quantile(data_go.nogoT$Reaction.Time, 0.25)
#Q3 <- quantile(data_go.nogoT$Reaction.Time, 0.75)
#range <- (IQR(data_go.nogoT$Reaction.Time)*1.5)
#lowbound <- Q1 - range
#highbound <- Q3 + range
#summary(data_go.nogoT$Reaction.Time)
#lowbound
#highbound
#boxplot(data_go.nogoT$Reaction.Time)

#upper outliers need to be rejected in order to look at mean RT measures
#the upper bound is reasonable based on what looks like only a few outliers above it
#there are a lot of responses around 1000ms, these are "no go" responses which moved to the next trial automatically. We will only look at mean/SD RTs of HITS and FA (correct hits and commission errors)
data_go.nogoT$Reaction.Time[which(data_go.nogoT$Reaction.Time > 1072)] <- NA

#setting a lower bound based on Jaana's 2017 paper: brain needs this much time to react
data_go.nogoT$Reaction.Time[which(data_go.nogoT$Reaction.Time < 150)] <- NA

## Participant exclusion criteria
#median RT<200ms, accuracy <60%
#both of these conditions designed to catch ppl who are just pressing buttons too quickly

#Median RT + Accuracy, participant level rejections
#nobody rejected
data_go.nogoT <- data_go.nogoT %>%
  group_by(Participant.Private.ID) %>% 
  mutate(medianRT = median(Reaction.Time), Accuracy = sum(Correct)/(sum(Correct)+sum(Incorrect))) %>% #Creating a new column that gives the median response time for each participant
  mutate(go.nogo_omit = case_when((medianRT > 200 & Accuracy > .60) ~ 0, (medianRT <= 200 | Accuracy <= .60)  ~ 1)) #assigning 1 to rows where median RT is <200ms
  
#Omitting rows based on exclusion criteria
data_go.nogoT$Response[which(data_go.nogoT$go.nogo_omit == 1)] <- NA


## Signal Detection Theory categories for each row
#can also use the Response and Answer columns but the logic is pretty much the same
data_go.nogoT <- data_go.nogoT %>%
  filter(display == "Trials") %>%
  mutate(SDT = case_when(((Array == "H.png" | Array == "T.png") & Response == "Go")  ~ "Hit",
                         ((Array == "H.png" | Array == "T.png") & Response == "No Go") ~ "Miss",
                         (Array == "N.png" & Response == "Go") ~ "False Alarm",
                         (Array == "N.png" & Response == "No Go") ~ "Correct Rejection")) #This is in case we want to look at how these relate to reaction times or EEG data at some point?

#Hit = H.png or T.png and Go (Array and Response)
#Miss = H-png or T.png and No Go
#False alarm = N.png and Go
#Correct rejection = N.png and No Go

#D-Prime and Bias for each participant

#https://www.rdocumentation.org/packages/psycho/versions/0.6.1/topics/dprime
#http://wise.cgu.edu/wise-tutorials/tutorial-signal-detection-theory/signal-detection-d-defined-2/
  
library(psycho)

data_go.nogoT <- data_go.nogoT %>%
  mutate(Hit = case_when(SDT == "Hit" ~ 1,
                         SDT != "Hit" ~ 0),
         Miss = case_when(SDT == "Miss" ~ 1,
                          SDT != "Miss" ~ 0),
         FA = case_when(SDT == "False Alarm" ~ 1,
                        SDT != "False Alarm" ~ 0),
         CR = case_when(SDT == "Correct Rejection" ~ 1,
                        SDT != "Correct Rejection" ~ 0))

#calculating the mean and sd of hits and FA
data_hit <- filter(data_go.nogoT , SDT == "Hit")
data_hit_RT <- data_hit %>%
  group_by(Participant.Private.ID) %>%
  summarise(meanHitRT=mean(Reaction.Time,na.rm=TRUE), sdHitRT=sd(Reaction.Time,na.rm=TRUE))

#Q1 <- quantile(data_hit_RT$sdHitRT, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_hit_RT$sdHitRT, 0.75,na.rm=TRUE)
#range <- (IQR(data_hit_RT$sdHitRT,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_hit_RT$sdHitRT)
#lowbound
#highbound

#one high outlier identified and removed
data_hit_RT$meanHitRT[which(data_hit_RT$meanHitRT > 593)] <- NA
#about 6 high outliers removed. They aren't clearly outliers from plotting but are higher values. It helps the skewness only slightly. 
data_hit_RT$sdHitRT[which(data_hit_RT$sdHitRT > 165)] <- NA

#FAs
data_FA <- filter(data_go.nogoT , SDT == "False Alarm")
data_FA_RT <- data_FA %>%
  group_by(Participant.Private.ID) %>%
  summarise(meanFA_RT=mean(Reaction.Time,na.rm=TRUE), sdFA_RT=sd(Reaction.Time,na.rm=TRUE))

#e.g. remember to change the variables to calculate the quartiles 
#Q1 <- quantile(data_FA_RT$meanFA_RT, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_FA_RT$meanFA_RT, 0.75,na.rm=TRUE)
#range <- (IQR(data_FA_RT$meanFA_RT,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_FA_RT$meanFA_RT)
#lowbound
#highbound

#data_FA_RT$meanFA_RT[which(data_FA_RT$meanFA_RT > ??)] <- NA
#no outliers in the mean  
data_FA_RT$sdFA_RT[which(data_FA_RT$sdFA_RT > 198)] <- NA


#Calculating d-prime + bias
data_dprime <- data_go.nogoT %>%
  group_by(Participant.Private.ID) %>%
  summarise(dp = dprime(n_hit=sum(Hit), n_fa=sum(FA), n_miss=sum(Miss), n_cr=sum(CR), n_targets=300, n_distractors=100))

#Adding a row to specify what the five different values given mean
names <- c("GNGdprime","GNGbeta","GNGaprime","GNGbppd","GNGc") #we are interested in dprime and beta which means bias
value <- rep_len(names,length.out=nrow(data_dprime))
data_dprime$value <- value

#Into wide format
data_dprime <- data_dprime %>%
  pivot_wider(names_from = value, values_from = dp)
data_GNGdprime <- as.data.frame(data_dprime)

#Creating a sum score of each response category for each participant
data_go.nogoT_final <- data_go.nogoT %>%
  select(Participant.Private.ID, Hit, Miss, FA, CR) %>%
  group_by(Participant.Private.ID) %>%
  summarise(GNGHitSum = sum(Hit, na.rm=TRUE), GNGMissSum = sum(Miss, na.rm=TRUE), GNGFASum = sum(FA, na.rm=TRUE), GNGCRSum = sum(CR, na.rm=TRUE))

#Combining the dataframes, keeping all rows
data_go.nogoT_final <- merge(data_go.nogoT_final, data_GNGdprime, by = "Participant.Private.ID", all=TRUE)
data_go.nogoT_final <- merge(data_go.nogoT_final, data_hit_RT, by = "Participant.Private.ID", all=TRUE)
data_go.nogoT_final <- merge(data_go.nogoT_final, data_FA_RT, by = "Participant.Private.ID", all=TRUE)


## Excluding participants with invalid responses
#this contains validity data for all tasks
data_ConsentValidity <- data_Q_total %>%
  select(Participant.Private.ID,Language,Validity.quantised)
  
data_go.nogoT_final <- merge(data_go.nogoT_final, data_ConsentValidity, by = "Participant.Private.ID")

#######creating new sets to double check that rejected ppts match the other df
#I think one ppt was already excluded because of validity etc. These are the ones that didn't complete the task
#data_nonvalid_gng <- data_go.nogoT_final %>%
  #filter(Participant.Private.ID %in% c("4886650","5117494","5282634", "5500754", "5552405", "5635997"))
  #filter(Validity.quantised %in% c("2",3,4))

#data_Q_lang_omit_gng <- data_go.nogoT_final %>%
  #filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

#final set. Somehow this ppt who didn't actually do the task (zeroes in sum scores) has squeaked through, so removing them now. 
data_go.nogoT_final <- data_go.nogoT_final %>%
  filter(Validity.quantised %in% c(1,NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?") & Participant.Private.ID != "5201242" & Participant.Private.ID != "4886650" & Participant.Private.ID != "5117494" & Participant.Private.ID != "5282634" & Participant.Private.ID != "5500754" & Participant.Private.ID != "5552405" & Participant.Private.ID != "5635997")
#there are some rows with NAs or other missing data still but I think those are gotten rid of during the merging or formatting task variables chunks

#omitting specific participants who commented that they were interrupted in the task
#first see if they were included in the first place based on quality
#it's mostly the hits and misses that are much lower/higher, but they are not the worst score. They are not an outlier. Keep them or no?

# 7mik8ed5 4886650
# xt9lwzwk 5117494
# 73bdl37a 5282634
# tfn355ew 5500754
# 5aakmlti 5552405
# kqn3t62x 5635997

# 5845513 the one who was interrupted during the task 

#######

#Subsetting by validity and consent info + omitting the irrelevant columns
#Technically we will likely only need d prime and bias but extra columns can easily be dropped later on
#has 148 ppts now but should eventually be 146
data_go.nogoT_final <- data_go.nogoT_final %>%
  select(Participant.Private.ID, GNGHitSum, GNGMissSum, GNGFASum, GNGCRSum, meanHitRT, sdHitRT, meanFA_RT, sdFA_RT, GNGdprime, GNGbeta, GNGaprime, GNGbppd, GNGc) 

# no outliers (dprime only??)
#par(mfrow=c(2,3))
#hist(as.numeric(data_go.nogoT_final$GNGdprime),main="dprime",ylim=c(0,40),col=rainbow(14),xlab="")
#hist(as.numeric(data_go.nogoT_final$GNGbeta),main="beta",col=rainbow(14),xlab="")
#hist(as.numeric(data_go.nogoT_final$GNGaprime),main="aprime",col=rainbow(14),xlab="")
#hist(as.numeric(data_go.nogoT_final$GNGbppd),main="bppd",ylim=c(0,100),col=rainbow(14),xlab="")
#hist(as.numeric(data_go.nogoT_final$GNGc),main="c",ylim=c(0,40),col=rainbow(14),xlab="")


#shapiro.test(as.numeric(data_go.nogoT_final$GNGdprime))

#GNG_task <- (describe(data_go.nogoT_final$dprime))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGbeta))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGaprime))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGbppd))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGc))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGHitSum))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGMissSum))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGFASum))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$GNGCRSum))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$meanHitRT))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$sdHitRT))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$meanFA_RT))
#GNG_task <- rbind(GNG_task,describe(data_go.nogoT_final$sdFA_RT))
#row.names(GNG_task) <- c("GNGdprime","GNGbeta","GNGaprime","GNGbppd","GNGc","GNGHitSum","GNGMissSum","GNGFASum","GNGCRSum","meanHitRT","sdHitRT","meanFA_RT","sdFA_RT")
#View(GNG_task)

```


## Navon

The two measures of interest are 1. the global-local precedence index, which quantifies the bias toward a global processing level. Responses are typically faster to a target stimulus that appears in the global condition versus the local; and 2. Global-to-local interference index, for which positive values indicate the extent to which the bias toward global stimuli interferes with processing local information. 

N=135 usable ppts
started with 140 who finished 

*******is using the interquartile method to delete trials based on reaction time OK for this task with this RT distribution??? ****

```{r Navon task, include=FALSE}

# potentially problematic ppts, replace data with NA if necessary
# qphf172f	5867681: thought their handedness would affect Navon (unlikely) 
#7mr6hy7i	5446208: probably 25% of their responses are wrong--did not fully get the task/realized they were doing it wrong

#these ppts stopped the experiment during Navon, and thus don't have a full dataset for this task
#xb2ctdsi 4907987
#u7uqmiee 4960307
#qxvqj34s 5317567
#huo5rege 5372338
#uy3ewu4f 5526450
#1jssdk6e 5578226
#ajrc2dxp 5626669
#l802ayaq 5808176

#Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only  

#Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only  

#Positive values indicate the extent to which global stimuli interfere with the local info  

#I calculated these manually. I first extracted the SDs for the reaction times for the two conditions in question (global consistent and local consistent for global precedence, local consistent and local inconsistent for global-to-local interference). I then calculated the pooled mean (https://www.statisticshowto.com/pooled-standard-deviation/). After that, I calculated the mean reaction time to the two trial types for each participant (e.g., global consistent and local consistent for global precedence). Finally, I compared the difference between these means for each participant to the pooled SD (https://www.statisticshowto.com/cohens-d/).

data_NavonT$Participant.Private.ID <- factor(data_NavonT$Participant.Private.ID)

## Omitting experiment-general columns & practice (etc.) rows
data_NavonT <- data_NavonT %>%
  select(Participant.Private.ID, Spreadsheet:Image) %>%
  filter(display %in% c("task1", "task2"))

## Only Including the relevant rows for us: this means rows where Screen.name = "Screen 3" 
data_NavonT <- data_NavonT %>%
  filter(Screen.Name == "Screen 3")

#Creating a column for consistency
data_NavonT <- data_NavonT %>%
  mutate(Consistency = case_when((Image == "bigHsmallH.png" | Image == "bigSsmallS.png") ~ "Consistent",
                                 (Image == "bigHsmallS.png" | Image == "bigSsmallH.png") ~ "Inconsistent"))
data_NavonT$Consistency <- factor(data_NavonT$Consistency)

data_NavonT$display <- factor(data_NavonT$display)
## Checking the accuracy per group (global/local + consistent/inconsistent)

#Accuracy is now its own df, summary(Accuracy_Navon) gives Accuracy_cond minimum 91.21%
Accuracy_Navon <- data_NavonT %>%
  group_by(Consistency, display) %>%
  summarise(Accuracy_cond = sum(Correct)/(sum(Correct)+sum(Incorrect)))

## Exclusion criteria

#for ppt level median RT<50ms (this is arbitrary, I've just chosen 50ms here (so that actually means 250+50=300 in this task), i.e. the previous screen is stimulus presentation and advances automatically after 250ms, while the response screen advances only on response, but we should probably look at the distribution of RTs later on), accuracy <60%, <95% RESPONSES fall on the same value
  
#Outlier trial exclusions first
# interquartile range: 1.5*(Q3-Q1), subtract this value from Q1 and add to Q3 to get the outlier boundaries. Here it was 671.8. Need to do this first because outlier trials mess up the ppt level calculations. There seem to be a lot of outliers on a gradient from around 5000ms up to 20000ms, different to GNG 

#Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
#0.6    211.0    307.1    389.2    441.4 183064.1 

#store_data_Navon <- data_NavonT
#data_NavonT <- store_data_Navon 

#getting rid of trials outside of range -- IQR method doesn't really work here because of an extreme skew
#instead, start with an arbitrary cutoff of 3000 (3s)
data_NavonT$Reaction.Time[which(data_NavonT$Reaction.Time > 3000)] <- NA

#this removes TRIALS that are outside 2.5 standard deviations of the mean PER PARTICIPANT
#########keep this or no?##############

data_NavonT <- data_NavonT %>%
  group_by(Participant.Private.ID) %>%
  filter(between(Reaction.Time, mean(Reaction.Time, na.rm=TRUE) - (2.5 * sd(Reaction.Time, na.rm=TRUE)), 
                     mean(Reaction.Time, na.rm=TRUE) + (2.5 * sd(Reaction.Time, na.rm=TRUE))))

#Q1 <- quantile(data_NavonT$Reaction.Time, 0.25)
#Q3 <- quantile(data_NavonT$Reaction.Time, 0.75)
#range <- (IQR(data_NavonT$Reaction.Time)*1.5)
#lowbound <- Q1 - range
#highbound <- Q3 + range


#this rejects PARTICIPANTS based on their MEDIAN RT being too short or too long 
#1 ppt has a clearly too high median RT
#no ppt has a median RT of 50ms or less

#Median RT & Accuracy
data_NavonT <- data_NavonT %>%
  group_by(Participant.Private.ID) %>%
  mutate(MedianRT = median(Reaction.Time), Accuracy = sum(Correct)/(sum(Correct)+sum(Incorrect)), Ratio = max(table(Response))/length(Response)) %>%
  mutate(Navon_omit = case_when(MedianRT > 50 & MedianRT < 1000 & Accuracy > .60 & Ratio < .95 ~ 0,
                                MedianRT <= 50 | Accuracy <= .60 | Ratio >= .95 ~ 1))

#Omitting data based on Navon_omit
data_NavonT$Reaction.Time[which(data_NavonT$Navon_omit == 1)] <- NA

## Subsetting: only looking at the correct answers
data_NavonT <- data_NavonT %>%
  filter(Correct == "1")

## Calculating pooled SDs

data_NavonT <- ungroup(data_NavonT)

#Global SD 1 (consistent trials only)
#again need to include the argument na.rm=TRUE otherwise NA values will cause the sd calculation to return empty
sd_Global_con <- data_NavonT %>%
  filter((Consistency == "Consistent") & display == "task1") %>%
  summarise(sd(Reaction.Time,na.rm = TRUE))

#Local SD 1 (consistent trials only)
sd_Local_con <- data_NavonT %>%
  filter((Consistency == "Consistent") & display == "task2") %>%
  summarise(sd(Reaction.Time,na.rm = TRUE))

#Local SD 2 (inconsistent trials only)
sd_Local_incon <- data_NavonT %>%
  filter((Consistency == "Inconsistent") & display == "task2") %>%
  summarise(sd(Reaction.Time,na.rm = TRUE))
  
#Calculating pooled SD
#https://www.statisticshowto.com/pooled-standard-deviation/
#I used the simplest formula and calculated it manually but there might be a quicker way to do it
#The more complex formula on the website is to correct for small sample sizes but this shouldn't be a problem once we have our data, so I just used the simpler formula.

#Pooled SD consistent (local and global)
pooled_SD_con <- sqrt((sd_Global_con^2 + sd_Local_con^2)/2)
pooled_SD_con

#Pooled SD local (consistent and inconsistent)
pooled_SD_local <- sqrt((sd_Local_incon^2 + sd_Local_con^2)/2)
pooled_SD_local

#pooled_SD_con
  #sd(Reaction.Time, na.rm = TRUE)
#1                         130.033

#pooled_SD_local
  #sd(Reaction.Time, na.rm = TRUE)
#1                        137.5748

#Final form of the Navon data: selecting relevant columns and transforming the data so that the columns reflect mean reaction times in each of the four conditions (local/global x consistent/inconsistent)
data_NavonT_final <- data_NavonT %>% 
  select(Participant.Private.ID, Consistency, display, Reaction.Time) %>%
  group_by(Participant.Private.ID, Consistency, display) %>%
  summarise(NavonReactionTimeMean = mean(Reaction.Time, na.rm = TRUE), .groups = "keep") %>%
  pivot_wider(names_from = c(Consistency, display), values_from = NavonReactionTimeMean)



#Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only 
data_NavonT_final <- data_NavonT_final %>%
  mutate(GlobalToLocalPrecedence = ((Consistent_task1 - Consistent_task2)/as.numeric(pooled_SD_con)))

## Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only
data_NavonT_final <- data_NavonT_final %>%
  mutate(GlobalToLocalInterference = ((Inconsistent_task1 - Consistent_task2)/as.numeric(pooled_SD_local)))

## Excluding nonvalid participants
data_NavonT_final <- merge(data_NavonT_final, data_ConsentValidity, by = "Participant.Private.ID")

#xb2ctdsi 4907987
#u7uqmiee 4960307
#qxvqj34s 5317567
#huo5rege 5372338
#uy3ewu4f 5526450
#1jssdk6e 5578226
#ajrc2dxp 5626669
#l802ayaq 5808176

#data_NavonT_final <- data_NavonT_final %>%
  #filter(ConsentFlag == 1 & Validity.quantised == 1 & Language == "Sujuva / Ã¤idinkieli") %>%
  #select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)

#getting rid of ppts who stopped halfway through, some have already been caught by quality control
data_NavonT_final <- data_NavonT_final %>%
  filter(Participant.Private.ID != "4907987"  & Participant.Private.ID != "4960307" & Participant.Private.ID != "5317567" & Participant.Private.ID != "5372338" & Participant.Private.ID != "5526450" & Participant.Private.ID != "5578226" & Participant.Private.ID != "5626669" & Participant.Private.ID != "5808176")

#validity filter
data_NavonT_final <- data_NavonT_final %>%
  filter(Validity.quantised %in% c("1",NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>%
  select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)
#there are 3 rows of NAN 

#final score outlier exclusions
#not going to do this right now. The spread seems to include some upper and lower extremes, but the distribution shape is good 

#Q1 <- quantile(data_NavonT_final$GlobalToLocalInterference, 0.25,na.rm=TRUE)
#Q3 <- quantile(data_NavonT_final$GlobalToLocalInterference, 0.75,na.rm=TRUE)
#range <- (IQR(data_NavonT_final$GlobalToLocalInterference,na.rm=TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_NavonT_final$GlobalToLocalInterference)
#lowbound
#highbound

#plot(data_NavonT_final$GlobalToLocalPrecedence)
#plot(data_NavonT_final$GlobalToLocalInterference)

#summary(data_NavonT_final$GlobalToLocalPrecedence)
#summary(data_NavonT_final$GlobalToLocalInterference)
#mean(data_NavonT_final$GlobalToLocalPrecedence, na.rm=TRUE) + (2.5 * sd(data_NavonT_final$GlobalToLocalPrecedence, na.rm=TRUE))
#mean(data_NavonT_final$GlobalToLocalPrecedence, na.rm=TRUE) - (2.5 * sd(data_NavonT_final$GlobalToLocalPrecedence, na.rm=TRUE))

#data_NavonT_final$GlobalToLocalPrecedence[which(data_NavonT_final$GlobalToLocalPrecedence < -1.29128)] <- NA
#data_NavonT_final$GlobalToLocalInterference[which(data_NavonT_final$GlobalToLocalInterference > 1.16392)] <- NA

#they're "almost normal"
#shapiro.test(data_NavonT_final$GlobalToLocalPrecedence)
#shapiro.test(data_NavonT_final$GlobalToLocalInterference)

#par(mfrow=c(1,2))
#hist(data_NavonT_final$GlobalToLocalPrecedence,main="GlobalToLocalPrecedence",ylim=c(0,60),col=rainbow(14),breaks=seq(-2,2,.5),xlab="")
#hist(data_NavonT_final$GlobalToLocalInterference,main="GlobalToLocalInterference",ylim=c(0,60),col=rainbow(14),breaks=seq(-2,2,.5),xlab="")

#Navon_task <- (describe(data_NavonT_final$GlobalToLocalPrecedence))
#Navon_task <- rbind(Navon_task,describe(data_NavonT_final$GlobalToLocalInterference))
#row.names(Navon_task) <- c("GlobalToLocalPrecedence","GlobalToLocalInterference")
#View(Navon_task)

```

##Necker

about 7 ppts didn't experience switching at all, which is a valid option
6 are outliers according to IQR
no exclusions made currently
N=153

```{r Necker cube, include=FALSE}

#Necker: switches per second for each session

data_NeckerT$Participant.Private.ID <- factor(data_NeckerT$Participant.Private.ID)

#Omitting irrelevant columns
data_NeckerT <- data_NeckerT %>%
  select(Participant.Private.ID, Spreadsheet:Image)

#Omitting irrelevant rows (Instructions / empty rows)
data_NeckerT <- data_NeckerT %>%
  filter(display %in% c("Trial 1", "Trial 2"))

#Exclusion criteria: none for now, but consider high outliers and ppts who reported no switching--can check later if there is a difference there

#this ppt stopped during Necker
#t98f4qif  5385143

## Sum score for how many times space bar was hit in total
data_NeckerT_final <- data_NeckerT %>%
  select(Participant.Private.ID, Response) %>%
  group_by(Participant.Private.ID) %>%
  summarise(NeckerCountTotal = sum(Response == "space", na.rm = TRUE))

## Switches per second
data_NeckerT_final <- data_NeckerT_final %>%
  mutate(NeckerTotalRate = NeckerCountTotal/60)

# rate interquartile max 0.35832, 6 ppts NA'd here
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#0.00000 0.06667 0.11667 0.13647 0.18333 0.48333 

#data_NeckerT_final$NeckerTotalRate[which(data_NeckerT_final$NeckerTotalRate > 0.35832)] <- NA
#data_NeckerT_final$NeckerCountTotal[which(data_NeckerT_final$NeckerTotalRate > 0.35832)] <- NA

data_NeckerT_final <- merge(data_NeckerT_final, data_ConsentValidity, by = "Participant.Private.ID")

#creating ppt omit sets
#data_nonvalid_Necker <- data_NeckerT_final %>%
#  filter(Validity.quantised %in% c(2,3,4))

#data_Necker_lang_omit <- data_NeckerT_final %>%
#  filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

#Subsetting by validity and consent info + omitting the irrelevant columns
data_NeckerT_final <- data_NeckerT_final %>%
  filter(Validity.quantised %in% c("1",NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>%
  select(Participant.Private.ID, NeckerCountTotal, NeckerTotalRate)

#ppt 5385143 stopped during necker, exclude their data (already NA) Participant.Private.ID != "5385143" 

#boxplot(data_NeckerT_final$NeckerTotalRate)
#boxplot(data_NeckerT_final$NeckerCountTotal)
#hist(data_NeckerT_final$NeckerTotalRate,main="Perceptual Switching Rate",col="blue",breaks=seq(0,.35,.01),xlab="")

```

##Unusual Uses Task

NB: FIRST conduct interrater reliability using UUT_Analysis.Rmd. Then create a file that contains at least columns for participant number, fluency and flexibility ratings for at least 2 raters. Rows are individual participant responses.  Rows are individual participant responses.

Fluency is a measure of how many unique unusual uses a ppt can think of for each item. FluencySum is the count of all unique uses over all items for a ppt. Flexibility score refers to the uniquenes of the functional categories of items, i.e. a participant gets two point for using a shoe as a doorstop and a flowerpot but only one point for a houseplant pot and a bonsai tree pot (same functional use).FlexSum is the sum of flexibility points over all items for a participant. Refer to UUT scoring instructions for further detail.

N=150

```{r Unusual Uses Task, include=FALSE}

data_UUT <- read.csv('UUT_scoring_COMBINED_REVISED_Rcsv.csv', sep = ";")
#View(data_UUT)

# potentially problematic ppts: 
# ghufyqzr	5691497 : wasn't sure if UUT answers were saved
# 6r93nkqg	5686104 : wasn't sure if UUT answers were saved 
# sssb0k4g	5507405 : wrote all UUT answers in same space
##these were checked by hand during rating and are all OK

########################################################################################################
##did they use these processing chunks in the reliability analysis?? maybe move them to there? 
#data_unusual.usesT$Participant.Private.ID <- factor(data_unusual.usesT$Participant.Private.ID)

#Omitting experiment-general columns and excluding practice trials
#data_unusual.usesT <- data_unusual.usesT %>%
#  select(Participant.Private.ID, Spreadsheet:text) %>%
#  filter(Screen.Name != "Screen 3")

#Omitting irrelevant rows (with empty cells)
#data_unusual.usesT$Response[which(data_unusual.usesT$Response == "")] <- NA

#data_unusual.usesT <- data_unusual.usesT %>%
#  filter(!is.na(Response)) #only keeping rows with responses (not NAs)

#Splitting cells that have multiple responses (if participant forgot to press enter between answers)
#data_unusual.usesT <- separate_rows(data_unusual.usesT, Response, sep = ",", convert = TRUE)

#Creating fake columns for flexibility and fluency to demonstrate how they would be calculated
#data_unusual.usesT$Fluency <- rbinom(n=nrow(data_unusual.usesT), 1, p=0.90)
#data_unusual.usesT$Flexibility <- rbinom(n=nrow(data_unusual.usesT), 1, p=0.70)

############################################################################################################

###can put a little section here looking at any differences in Fluency and Flexibility scores per ppt between the different items. probably we don't need to worry about this, but in case someone asks if there are some items that may seem invalid because of weird response patterns####

#######################################################################################

### Calculating the fluency and flexibility sum score for each participant per rater
data_UUT_scores <- data_UUT %>%
  select(Participant.Private.ID, S.Flex, S.Fluency,K.Flex,K.Fluency) %>%
  group_by(Participant.Private.ID) %>%
  summarise(SFlexibilitySum = sum(S.Flex), SFluencySum = sum(S.Fluency),KFlexibilitySum = sum(K.Flex), KFluencySum = sum(K.Fluency))
#View(data_UUT_scores)

#participant sum scores as a mean of rater scores
data_UUT_scores$FlexSum <- rowMeans(cbind(data_UUT_scores$SFlexibilitySum, data_UUT_scores$KFlexibilitySum), na.rm = TRUE)
data_UUT_scores$FluencySum <-rowMeans(cbind(data_UUT_scores$SFluencySum, data_UUT_scores$KFluencySum), na.rm = TRUE)

#checking distributions
#par(mfrow=c(2,2))
#hist(data_UUT_scores$SFlexibilitySum)
#hist(data_UUT_scores$SFluencySum)
#hist(data_UUT_scores$KFlexibilitySum)
#hist(data_UUT_scores$KFluencySum)

#generally flexibility more normal than fluency
#(data_UUT_scores$SFlexibilitySum)
#shapiro.test(data_UUT_scores$SFluencySum)
#shapiro.test(data_UUT_scores$KFlexibilitySum)
#shapiro.test(data_UUT_scores$KFluencySum)

#total
#hist(data_UUT_scores$FlexSum)
#hist(data_UUT_scores$FluencySum)
#shapiro.test(data_UUT_scores$FlexSum)
#shapiro.test(data_UUT_scores$FluencySum)

#checking validity
data_UUT_scores <- merge(data_UUT_scores, data_ConsentValidity, by = "Participant.Private.ID")

#data_nonvalid_UUT <- data_UUT_scores %>%
  #filter(Validity.quantised %in% c(2,3,4))

#data_UUT_lang_omit <- data_UUT_scores %>%
  #filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

#extracting the columns we want
data_UUT_scores <- data_UUT_scores %>%
  filter(Validity.quantised %in% c("1",NA,"") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva","Muu, mikÃ¤?")) %>%
  select(Participant.Private.ID, FlexSum, FluencySum)

```


#Merging task variables

Doesn't yet include the CI task! 

N=155

```{r Combining the task dataframes, include=FALSE}

data_T_total1 <- merge(data_go.nogoT_final, data_NavonT_final, by = "Participant.Private.ID", all=TRUE)
data_T_total2 <- merge(data_UUT_scores, data_NeckerT_final, by = "Participant.Private.ID", all=TRUE)
#data_T_total <- merge(data_T_total, data_NeckerT_final, by = "Participant.Private.ID", all=TRUE)
data_T_total <- merge(data_T_total1, data_T_total2, by = "Participant.Private.ID", all=TRUE)
rm(data_T_total1, data_T_total2)


## Extracting the relevant columns

data_T_sub <- data_T_total %>%
  select(Participant.Private.ID, GNGdprime, GNGbeta, meanHitRT,sdHitRT,meanFA_RT,sdFA_RT, GlobalToLocalPrecedence, GlobalToLocalInterference, NeckerTotalRate,FlexSum,FluencySum)


#getting rid of values that should be NAs 
#is.nan.data.frame <- function(x)
#  do.call(cbind, lapply(x, is.nan))
#data_T_sub[is.nan(data_T_sub)] <- NA

# need to coerce the numeric variables to numeric through unlist and get rid of the NULLs in the meantime
data_T_sub$GNGdprime[which(data_T_sub$GNGdprime == "NULL")] <- NA
data_T_sub$GNGbeta[which(data_T_sub$GNGbeta == "NULL")] <- NA
data_T_sub$GNGdprime <- as.numeric(unlist(data_T_sub$GNGdprime))
data_T_sub$GNGbeta <- as.numeric(unlist(data_T_sub$GNGbeta))

str(data_T_sub)


```


# T missing data

Better to do this for tasks and questionnaires separately, because they have different reasons for being missing and different implications. Do this before checking distributions because ppts with large amounts of missing data or suspicious patterns of missing data are removed here from the final dataset.

Final N after cleaning: N=143 ppts with task data

```{r}
library(ggplot2)
library(naniar)

#add a column for count of missing data per ppt, to task sub df
data_T_sub1 <- data_T_sub %>%
  mutate(missingtasks = rowSums(is.na(data_T_sub)))

View(data_T_sub)

#there is a clear elbow at around 3 missing variables, the next step is 6 missing which adds 2 more ppts, and above that is 8 missing
#so for this I'll choose to cut off at below 4 missing
ggplot(data_T_sub, aes(x=as.factor(Participant.Private.ID), y=missingtasks)) +
     geom_boxplot(fill="slateblue", alpha=0.2) + 
     xlab("Missing variables count")

#try to see if there's an elbow in the number of missing variables per ppt 
MissingTasks<-sort(data_T_sub$missingtasks, decreasing = FALSE)
plot(MissingTasks)

#just temporarily getting the demographic info to the task df so I can investigate missingness
data_T_all <- data_Q_total %>%
  select(Participant.Private.ID, gender, Age, Country, Language, Education)

data_T_sub <- merge(data_T_all, data_T_sub, by = "Participant.Private.ID", all=TRUE)

#getting rid of some NaNs in the Navon variables
is.nan.data.frame <- function(x)
  do.call(cbind, lapply(x, is.nan))
data_T_sub[is.nan(data_T_sub)] <- NA

#there is a significant correlation between age and missing data in the tasks before ppt removal, probably because older ppts struggle more in the timed tasks
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age,data_T_sub$missing,method="spearman",exact=FALSE)

#gg_miss_fct(x = data_T_sub, fct = Language)
#gg_miss_fct(x = data_T_sub, fct = Country)
#gg_miss_fct(x = data_T_sub, fct = gender)
#gg_miss_fct(x = data_T_sub, fct = Education)


#removing ppts with 5 or more task variables missing (total 9 variables, looks like most ppts have no more than 3 missing)
data_T_sub <- data_T_sub %>%
  group_by(Participant.Private.ID)  %>%
  filter(missing < 4)

#checking whether there is still a correlation between age and missing data--it's better but still there
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age,data_T_sub$missing,method="spearman",exact=FALSE)

#removing the columns we don't need again
data_T_sub <- data_T_sub %>%
  select(GNGdprime:FluencySum)

View(data_T_sub)

```


#T distributions and correlations

Done according to our plan: 
Transform GNGbeta, meanHitRT and sdHitRT and sdFA_RT
Removing meanFA_RT and GlobalLocalInterference for having high correlations >.85 with other variables in the same measure

NB: not entirely sure about the processing here. 


```{r Checking the normality of the task variables, include=FALSE}

#each of the measures (mean, skew, kurtosis) should be inspected and transformations should be conducted accordingly

#this has already basically been checked in each processing section

## Normality of variables: visualising with histograms
#GNGdprime <- ggplot(data_T_sub, aes(x=GNGdprime)) +
#  geom_histogram(color = "black", fill = "lightblue")
#GNGdprime
#GNGbeta <- ggplot(data_T_sub, aes(x=GNGbeta)) +
#  geom_histogram(color = "black", fill = "lightblue")
#GNGbeta
#meanHitRT <- ggplot(data_T_sub, aes(x=meanHitRT)) +
#  geom_histogram(color = "black", fill = "lightblue")
#meanHitRT
#meanFA_RT <- ggplot(data_T_sub, aes(x=meanFA_RT)) +
#  geom_histogram(color = "black", fill = "lightblue")
#meanFA_RT
#sdHitRT <- ggplot(data_T_sub, aes(x=sdHitRT)) +
#  geom_histogram(color = "black", fill = "lightblue")
#sdHitRT
#sdFA_RT <- ggplot(data_T_sub, aes(x=sdFA_RT)) +
#  geom_histogram(color = "black", fill = "lightblue")
#sdFA_RT
#GlobalToLocalPrecendence <- ggplot(data_T_sub, aes(x=GlobalToLocalPrecendence)) +
#  geom_histogram(color = "black", fill = "lightblue")
#GlobalToLocalPrecendence
#GlobalToLocalInterference <- ggplot(data_T_sub, aes(x=GlobalToLocalInterference)) +
#  geom_histogram(color = "black", fill = "lightblue")
#GlobalToLocalInterference
#NeckerTotalRate <- ggplot(data_T_sub, aes(x=NeckerTotalRate)) +
#  geom_histogram(color = "black", fill = "lightblue")
#NeckerTotalRate

#Transformations 

## Normality of variables: skewness
#which(abs(skew(data_T_sub))>1) #The variables that need to be transformed (no code for this yet)
#which(abs(skew(data_T_total))>1)

#I think the task variables need to be transformed

## Correlation matrix
#If two (or more) variables from the same questionnaire or task correlate so that r>.85, one of them should be omitted (from Eisenberg et al.)
#no omissions needed from questionnaires

#check the indexes, it changes if you've deleted the demographic columns
#GNG variables
#mean hit RT and mean FA RT are correlated 0.8775609  
cor(data_T_sub[,2:7], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[,2:7], method = "pearson", use = "pairwise.complete.obs")) > .85 #TRUE values: we should consider omitting one of the variables 

#Navon variables
#correlated with each other 0.8947398       
cor(data_T_sub[,8:9], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[,8:9], method = "pearson", use = "pairwise.complete.obs")) > .85

#UUT variables
#correlated with each other .984135
cor(data_T_sub[,11:12], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[,11:12], method = "pearson", use = "pairwise.complete.obs")) > .85


#GNGbeta has high positive skew; transforming it and replacing it in the df 

#the mean and sd hit and FA RTs are also skewed positively, so trying to transform them too just to see how it goes 


data_T_sub$GNGbetalog<-log10(data_T_sub$GNGbeta)
#GNGbetalog <- ggplot(data_T_sub, aes(x=GNGbetalog)) +
#  geom_histogram(color = "black", fill = "lightblue")
#GNGbetalog
#qqnorm(data_T_sub$GNGbetalog)
#it's not as bad as it could be? keeping for now?? 

data_T_sub$meanHitRTlog<-log10(data_T_sub$meanHitRT)
#meanHitRTlog <- ggplot(data_T_sub, aes(x=meanHitRTlog)) +
#  geom_histogram(color = "black", fill = "lightblue")
#meanHitRTlog
#good enough according to shapiro. The original wasn't that bad. 

data_T_sub$sdHitRTlog<-log10(data_T_sub$sdHitRT)
#sdHitRTlog <- ggplot(data_T_sub, aes(x=sdHitRTlog)) +
#  geom_histogram(color = "black", fill = "lightblue")
#sdHitRTlog
#again wasn't that bad but helped

data_T_sub$sdFA_RTlog<-log10(data_T_sub$sdFA_RT)
#sdFA_RTlog <- ggplot(data_T_sub, aes(sdFA_RTlog)) +
#  geom_histogram(color = "black", fill = "lightblue")
#sdFA_RTlog
#was a bit worse but helped, still not great

#selecting a final set of task variables including the transformed ones
#here abribtrarily remove variables that were highly correlated with others from the same task
data_T_sub <- data_T_sub %>%
  select(GNGdprime,GNGbetalog,meanHitRTlog,sdHitRTlog,sdFA_RTlog,GlobalToLocalPrecedence,NeckerTotalRate,FlexSum)


```


# Formatting T & Q dataframes 

there are now N=163 in the full set (data_all_sub_cleaned) because there is one ppt who has NA for all Q data but has some T data. Q set N=162, T set N=143

These dfs have the final full set of variables and ppts, including transformed variables and cleaned data. 

```{r Combining task and questionnaire dataframes, include=FALSE}

data_all_sub_cleaned <- merge(data_Q_sub, data_T_sub, by = "Participant.Private.ID", all=TRUE)
View(data_all_sub_cleaned)

#ungroup(data_all_sub_cleaned)
#clustdata <- data_all_sub_cleaned %>%
  #select(Participant.Private.ID:AOTSum,RPSum:FluencySum)

#need to ungroup and select to get rid of ppt private id. This can also be done earlier. Ungrouping turns the df into a tibble, so have to coerce back to a df before selecting to remove ppt private id
ungroup(data_all_sub_cleaned)
data_all_sub_cleaned <- data_all_sub_cleaned %>%
  select(AMean:FluencySum)
View(data_all_sub_cleaned)

ungroup(data_Q_sub)
data_Q_sub<-data.frame(data_Q_sub)
data_Q_sub <- data_Q_sub %>%
  select(AMean:MatrixCorrectCount)

ungroup(data_T_sub)
data_T_sub<-data.frame(data_T_sub)
data_T_sub <- data_T_sub %>%
  select(GNGdprime:NeckerTotalRate)

#this set removes GNGbetalog and the other RT based GNG measures which are generally correlated and clustered with themselves and nothing else 
#trying this to see if it solves the ultra-Heywood case issue
data_all_without_GNG <- data_all_sub_cleaned %>%
  select(AMean:GNGdprime,GlobalToLocalPrecedence:FlexSum)

#without binary variables, use this for clustering raw (not correlation matrix)
data_all_without_binary <- data_all_sub_cleaned %>%
  select(AMean:AOTSum,RPSum:FlexSum)

#data without GNG or binary, use this for the cross validated ridge regression predictions of tasks by surveys etc. 
data_without_GNG_or_binary <- data_all_without_GNG %>%
  select(AMean:AOTSum,RPSum:FlexSum)

#data set based on predictions: surveys plus navon and necker
data_from_predictions <- data_all_sub_cleaned %>%
  select(AMean:MatrixCorrectCount,GlobalToLocalPrecedence:NeckerTotalRate)

#########################################################################
#First start from the beginning---sets for EFA process
#no need to worry about correlated variables, they were removed in the previous section
#whole set
all_new <- data_all_sub_cleaned %>%
  select(AMean:FlexSum)

#eventually leaving out HEscore, EMean, sci.tru.sum
Q_new <- data_all_sub_cleaned %>%
  select(AMean:MatrixCorrectCount)
#Q_new <- na.omit(Q_new) #dont use this, it gets rid of all rows with NAs
  #select(AMean:CMean,ESMean:AOTSum,HRscore:Sci.cur_Sum,Sci.impo_Sum:MatrixCorrectCount)

#Task set for EFA process
#UUT as a task
T_new <- data_T_sub %>%
  select(GNGdprime:FlexSum)
  
```





#Citizen's Initiative
Potentially problematic ppts for CI: 
ri0gfe1h	5767733	skipped reading at least one article
vu1mvwkd	5691188	didn't focus on the first CI text
8zz2teyh	5629594	is dyslexic
tjh0tjq3	4887029	CI task invalid


```{r}

# will add the code when it works on its own 


```




