---
title: "Data Processing"
author: "Milla Pihlajamaki and Caitlin Dawson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

# Notes: 
* takes data downloaded from Gorilla **blinded, semicolon separated, csv format, short form, versions 22-25**
* cleans and processes data for the study 'Scientific thinking and decision-making in everyday life'

Version history: 
* version 22: Links fixed in information and consent
* version 23: HJ updated the experiment (source deleted from CI task--only 5 sources because of trouble getting a stable URL; Viiskunta source was taken down)
* version 24: HJ updated CI task to include all 6 sources again, one of them as image
* version 25: HJ. Word adult taken off from Study Information and Content

# Loading packages

```{r Loading packages, include = FALSE}

# library(car)
library(dplyr)
# library(ggplot2)
# library(GPArotation)
library(lavaan)
library(psych)
# library(psycho)
# library(tidyr)
# library(tidyverse)

```

# Load data 

This chunk loads the data and omits experiment-general columns from all files (except for participant private ID).

# Omit experiment-general columns from all files (except for participant ID)

```{r Loading data, include = FALSE}

# Versions 22-25
versions <- paste0("v", 22:25)
questionnaire_types <- c("2wlk", "79hv", "7qsg", "81k4", "c7cw", "cl1u", "eygv", "go4a", "mz16", "o43u", "otb8", "oyla", "w8n1")
task_types <- c("7mar", "8mu5", "9nll", "n8ns", "tg12", "zryk")
questionnaire_names <- c("epiQ", "heurQ", "openQ", "validQ", "demoQ", "sciattQ", "needcogQ", "scicurQ", "needcloQ", "infoQ", "rpQ", "inthumQ", "big5Q")
task_names <- c("uutT", "NavonT", "NeckerT", "nogoT", "matreasT", "citiT")
names_all <- c(questionnaire_names, task_names)

for (j in 1:length(versions)) {
  for (i in 1:length(questionnaire_types)) {
  assign(paste0("data_", questionnaire_names[i], "_", versions[j]),
         read.csv(paste0("data_exp_55551-", versions[j], "_questionnaire-", questionnaire_types[i], ".csv"), sep = ";")[, -c(1:12, 14:31)])
    }
}

for (j in 1:length(versions)) {
  for (i in 1:length(task_types)) {
    assign(paste0("data_", task_names[i], "_", versions[j]),
           read.csv(paste0("data_exp_55551-", versions[j], "_task-", task_types[i], ".csv"), sep = ";")[, -c(1:12, 14:31)])
  }
}

```

# Create questionnaire dataframe

This series of chunks computes the necessary data cleaning to merge the questionnaire dataframes and merges them.

## Merge the different versions of each task/questionnaire

This chunk combines the different versions of each task/questionnaire (leaving us with one df per task/questionnaire).

```{r Merge the versions, include = FALSE}

# Concatenate the versions of each task/questionnaire
data_big5Q <- rbind(data_big5Q_v22, data_big5Q_v23, data_big5Q_v24, data_big5Q_v25) 
data_citiT <- rbind(data_citiT_v22, data_citiT_v23, data_citiT_v24, data_citiT_v25) 
data_demoQ <- rbind(data_demoQ_v22, data_demoQ_v23, data_demoQ_v24, data_demoQ_v25)
data_epiQ <- rbind(data_epiQ_v22, data_epiQ_v23, data_epiQ_v24, data_epiQ_v25)
data_nogoT <- rbind(data_nogoT_v22, data_nogoT_v23, data_nogoT_v24, data_nogoT_v25)
data_heurQ <- rbind(data_heurQ_v22, data_heurQ_v23, data_heurQ_v24, data_heurQ_v25)
data_inthumQ <- rbind(data_inthumQ_v22, data_inthumQ_v23, data_inthumQ_v24, data_inthumQ_v25)
data_matreasT <- rbind(data_matreasT_v22, data_matreasT_v23, data_matreasT_v24, data_matreasT_v25)
data_NavonT <- rbind(data_NavonT_v22, data_NavonT_v23, data_NavonT_v24, data_NavonT_v25)
data_NeckerT <- rbind(data_NeckerT_v22, data_NeckerT_v23, data_NeckerT_v24, data_NeckerT_v25)
data_needcloQ <- rbind(data_needcloQ_v22, data_needcloQ_v23, data_needcloQ_v24, data_needcloQ_v25)
data_needcogQ <- rbind(data_needcogQ_v22, data_needcogQ_v23, data_needcogQ_v24, data_needcogQ_v25)
data_openQ <- rbind(data_openQ_v22, data_openQ_v23, data_openQ_v24, data_openQ_v25)
data_rpQ <- rbind(data_rpQ_v22, data_rpQ_v23, data_rpQ_v24, data_rpQ_v25)
data_sciattQ <- rbind(data_sciattQ_v22, data_sciattQ_v23, data_sciattQ_v24, data_sciattQ_v25)
data_scicurQ <- rbind(data_scicurQ_v22, data_scicurQ_v23, data_scicurQ_v24, data_scicurQ_v25)
data_infoQ <- rbind(data_infoQ_v22, data_infoQ_v23, data_infoQ_v24, data_infoQ_v25)
data_uutT <- rbind(data_uutT_v22, data_uutT_v23, data_uutT_v24, data_uutT_v25)
data_validQ <- rbind(data_validQ_v22, data_validQ_v23, data_validQ_v24, data_validQ_v25)

# Remove the empty last line of each file
for (i in 1:length(names_all)) {
  assign(paste0("data_", names_all[i]),
         get(paste0("data_", names_all[i]))[which(!is.na(get(paste0("data_", names_all[i]))[, 1])), ])
}

# Remove version files to clean up the environment
for (j in 1:length(versions)) {
  for (i in 1:length(names_all)) {
    rm(list = paste0("data_", names_all[i], "_", versions[j]))
  }
}

``` 


## Merge questionnaire dataframes

This chunk merges all questionnaire dataframes, leaving us with one dataframe.

```{r Merge questionnaire dataframes, include = FALSE}

# Rename two columns before combining all the questionnaires into one df (the column has the same name in each questionnaire file). END.QUESTIONNAIRE column gives you the response time for that questionnaire, and Randomise.questionnaire.elements. column gives you a logical value indicating whether the questionnaire items were randomised for that questionnaire.

# END.QUESTIONNAIRE
names(data_demoQ)[names(data_demoQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.DEMOGRAPHICS"
names(data_big5Q)[names(data_big5Q) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.BIG5"
names(data_epiQ)[names(data_epiQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.EPISTEMIC"
names(data_heurQ)[names(data_heurQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.HEURISTIC"
names(data_inthumQ)[names(data_inthumQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.INT.HUM"
names(data_needcloQ)[names(data_needcloQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.NEED.CLO"
names(data_needcogQ)[names(data_needcogQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.NEED.COG"
names(data_openQ)[names(data_openQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.OPEN.THINK"
names(data_rpQ)[names(data_rpQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.RANDOM.PROB"
names(data_sciattQ)[names(data_sciattQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.SCIENCE.ATT"
names(data_scicurQ)[names(data_scicurQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.SCIENCE.CUR"
names(data_infoQ)[names(data_infoQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.INFO"
names(data_validQ)[names(data_validQ) == "END.QUESTIONNAIRE"] <- "END.QUESTIONNAIRE.VALIDITY"

# Randomise.questionnaire.elements
names(data_demoQ)[names(data_demoQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..DEMOGRAPHICS"
names(data_big5Q)[names(data_big5Q) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..BIG5"
names(data_epiQ)[names(data_epiQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..EPISTEMIC"
names(data_heurQ)[names(data_heurQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..HEURISTIC"
names(data_inthumQ)[names(data_inthumQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..INT.HUM"
names(data_needcloQ)[names(data_needcloQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..NEED.CLO"
names(data_needcogQ)[names(data_needcogQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..NEED.COG"
names(data_openQ)[names(data_openQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..OPEN.THINK"
names(data_rpQ)[names(data_rpQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..RANDOM.PROB"
names(data_sciattQ)[names(data_sciattQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..SCIENCE.ATT"
names(data_scicurQ)[names(data_scicurQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..SCIENCE.CUR"
names(data_infoQ)[names(data_infoQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..INFO"
names(data_validQ)[names(data_validQ) == "Randomise.questionnaire.elements."] <- "Randomise.questionnaire.elements..VALIDITY"

# Merge by participant ID
# All rows for all dataframes are kept
data1 <- merge(data_demoQ, data_big5Q, 
               by = "Participant.Private.ID", 
               all = TRUE)
data2 <- merge(data_epiQ, data_heurQ, 
               by = "Participant.Private.ID", 
               all = TRUE)
data3 <- merge(data_inthumQ, data_needcloQ, 
               by = "Participant.Private.ID", 
               all = TRUE)
data4 <- merge(data_needcogQ, data_openQ, 
               by = "Participant.Private.ID", 
               all = TRUE)
data5 <- merge(data_rpQ, data_sciattQ, 
               by = "Participant.Private.ID", 
               all = TRUE)
data6 <- merge(data_scicurQ, data_infoQ, 
               by = "Participant.Private.ID", 
               all = TRUE)
data7 <- merge(data1, data2, 
               by = "Participant.Private.ID", 
               all = TRUE)
data8 <- merge(data3, data4, 
               by = "Participant.Private.ID", 
               all = TRUE)
data9 <- merge(data5, data6, 
               by = "Participant.Private.ID", 
               all = TRUE)
data10 <- merge(data7, data8, 
                by = "Participant.Private.ID", 
                all = TRUE)
data11 <- merge(data9, data_validQ, 
                by = "Participant.Private.ID", 
                all = TRUE)
data_Q_total <- merge(data10, data11, 
                      by = "Participant.Private.ID", 
                      all = TRUE)

# Clean the environment
rm(data1, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11)
rm(data_big5Q, data_epiQ, data_heurQ, data_infoQ, data_inthumQ, data_needcloQ, data_needcogQ, data_openQ, data_rpQ, data_sciattQ, data_scicurQ)

```

# Participant exclusions

This chunk removes nonvalid participants.

### Validity + Language

First, check comments for those who chose something other than "you can use my data" to see what else is chosen and why. Here, there were a few "other, what?" that can be kept, e.g. ppts worried that making mistakes in a few trials of Navon makes their data invalid.

Participants' data is omitted completely if they have stated that a) their responses are not valid, and/or b) their Finnish isn't Äidinkieli or Keskusteleva. Ppts who declined to consent were taken away from the study and no data was collected for them. 

```{r Clean questionnaire data, include = FALSE}
 
# Save data for nonvalid ppts ("älä huomioi aineistoani") in a separate file prior to removal
data_nonvalid <- data_Q_total %>%
  filter(Validity == "Ã„lÃ¤ huomioi aineistoani. Jokin muu syy esti minua osallistumasta kunnolla." | Validity == "Ã„lÃ¤ huomioi aineistoani. En suurimmaksi osaksi keskittynyt tai lukenut kysymyksiÃ¤ kunnolla.")

# Save data for participants with nonvalid language answers in a separate file. One participant who said "muu" but said they were fluent but not native level was included.
data_Q_lang_omit <- data_Q_total %>%
 filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

# Remove nonvalid participants
data_Q_total <- data_Q_total %>%
 filter(Validity %in% c("Aineistoani voi kÃ¤yttÃ¤Ã¤.", "Muu, mikÃ¤? ", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?"))

```

## Questionnaire processing (including exclusions)

The following chunks deal with TIPI, EC, IH, AOT, NFC, and NFcog. They remove bad quality data from each questionnaire, check the structure, and calculate sum or mean scores according to the questionnaire instructions. 

### Questionnaire response time + questionnaire answer distribution (latter for reverse-coded only)

The data from each questionnaire is checked as follows: if a participant was suspiciously quick at responding to the questionnaire (<1s/item), that participant's data for that questionnaire is replaced with NAs. Additionally, for scales that have reverse-coded items, if 95% of a participant's responses fall on the same response, their data for that scale are replaced with NAs (this indicates that they have not even read the questions properly). After this, the relevant items are reverse-coded, the structure is checked, and sum scores/mean scores are calculated for each questionnaire according to the scoring instructions.

## TIPI

Reliability are not calculated for TIPI, see Gosling's website for explanation. http://gosling.psy.utexas.edu/scales-weve-developed/ten-item-personality-measure-tipi/ 

```{r Scoring TIPI, include = FALSE}

# Big Five
b5 <- c("agreeablenessNormal", "emotionalStabilityNormal", "extroversionNormal", "conscientiousnessNormal", "opennessNormal", "agreeablenessReverse", "emotionalStabilityReverse", "extroversionReverse", "conscientiousnessReverse", "opennessReverse")
b5_rev <- c("agreeablenessReverse", "emotionalStabilityReverse", "extroversionReverse", "conscientiousnessReverse", "opennessReverse")

# Exclusion criteria
  # >= 90% of responses fall on the same response option
  # response time <= 10000ms

data_Q_total <- data_Q_total %>% 
  mutate(B5_max = max(table(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse)), na.rm = TRUE) /
           sum(table(c(agreeablenessNormal, agreeablenessReverse, conscientiousnessNormal, conscientiousnessReverse, extroversionNormal, extroversionReverse, emotionalStabilityNormal, emotionalStabilityReverse, opennessNormal, opennessReverse)), na.rm = TRUE))

data_Q_total <- data_Q_total %>% 
  mutate(B5_omit = case_when(B5_max >= .90 | END.QUESTIONNAIRE.BIG5 <= 1000*length(b5) ~ 1,
                             B5_max < .90 & END.QUESTIONNAIRE.BIG5 > 1000*length(b5) ~ 0))
 
# Omit B5 data based on the B5_omit column
data_Q_total[which(data_Q_total$B5_omit == 1), b5] <- NA

# Reverse-code
for (i in 1:length(b5_rev)) {
  data_Q_total[, b5_rev[i]] <- reverse.code(keys = c(-1), 
                                            items = data_Q_total[, b5_rev[i]],
                                            mini = c(1), 
                                            maxi = c(7)) 
}

# Describe: item-level
par(mfrow = c(2, 5))
for (i in 1:length(b5)) {
  hist(as.numeric(data_Q_total[, b5[i]]),
       main = colnames(data_Q_total[b5[i]]),
       col = sample(colors(), 1),
       breaks = seq(0, 7, 1),
       xlab = ""
       )
}
describe(data_Q_total[, b5])

# Calculate means
data_Q_total$AMean <- rowMeans(cbind(data_Q_total$agreeablenessNormal, 
                                     data_Q_total$agreeablenessReverse), 
                               na.rm = TRUE)
data_Q_total$CMean <- rowMeans(cbind(data_Q_total$conscientiousnessNormal,
                                     data_Q_total$conscientiousnessReverse),
                               na.rm = TRUE)
data_Q_total$EMean <- rowMeans(cbind(data_Q_total$extroversionNormal,
                                     data_Q_total$extroversionReverse), 
                               na.rm = TRUE)
data_Q_total$ESMean <- rowMeans(cbind(data_Q_total$emotionalStabilityNormal,
                                      data_Q_total$emostabilityReverse), 
                                na.rm = TRUE)
data_Q_total$OMean <- rowMeans(cbind(data_Q_total$opennessNormal,
                                     data_Q_total$opennessReverse), 
                               na.rm = TRUE)

# Describe: mean score level
b5_mean <- c("AMean", "OMean", "EMean", "CMean", "ESMean")
par(mfrow = c(2, 3))
for (i in 1:length(b5_mean)) {
  hist(data_Q_total[, b5_mean[i]],
       main = colnames(data_Q_total[b5_mean[i]]),
       col = sample(colors(), 1),
       breaks = seq(0, 7, 1),
       xlab = ""
       )
}
describe(data_Q_total[, b5_mean])

```

## Epistemic Curiosity

```{r Scoring Epistemic Curiosity, include = FALSE}

# Epistemic Curiosity
epicur <- c()
for (j in 1:2) {
  if (j == 1) {
    for (i in 1:5) {
      epicur <- c(epicur, which(colnames(data_Q_total) == paste0("Icuriosity", i)))
}
  } else if (j == 2) {
    for (i in 1:5) {
      epicur <- c(epicur, which(colnames(data_Q_total) == paste0("Dcuriosity", i)))
    }
  }
}

# Exclusion criteria
  # response time <= 10000ms
data_Q_total[which(data_Q_total$END.QUESTIONNAIRE.EPISTEMIC <= 1000*length(epicur)), epicur] <- NA

# Describe: item-level
par(mfrow = c(2, 5))
for (i in 1:length(epicur)) {
  hist(data_Q_total[, epicur[i]],
       main = colnames(data_Q_total[epicur[i]]),
       col = sample(colors(), 1),
       breaks = seq(0, 5, 1),
       xlab = ""
       )
}
describe(data_Q_total[, epicur])

# Cronbach's alphas
alpha(data_Q_total[, epicur[1:5]])
alpha(data_Q_total[, epicur[6:10]])

# Calculate sum scores
data_Q_total$ICuriositySum <- rowSums(cbind(data_Q_total$Icuriosity1, data_Q_total$Icuriosity2, data_Q_total$Icuriosity3, data_Q_total$Icuriosity4, data_Q_total$Icuriosity5), na.rm = TRUE)
data_Q_total$DCuriositySum <- rowSums(cbind(data_Q_total$Dcuriosity1, data_Q_total$Dcuriosity2, data_Q_total$Dcuriosity3, data_Q_total$Dcuriosity4, data_Q_total$Dcuriosity5), na.rm = TRUE)

# Describe: sum score level
epicur_sum <- c(which(colnames(data_Q_total) == "ICuriositySum"),
                 which(colnames(data_Q_total) == "DCuriositySum"))
par(mfrow = c(1, 2))
for (i in 1:length(epicur_sum)) {
  hist(data_Q_total[, epicur_sum[i]],
       main = colnames(data_Q_total[epicur_sum[i]]),
       col = sample(colors(), 1),
       xlab = ""
       )
}
describe(data_Q_total[, c(epicur_sum)])

```

## Intellectual Humility

```{r Scoring Intellectual Humility, include = FALSE}

# Intellectual Humility
IH <- c("IH1rev1", "IH2rev1","IH3rev1", "IH4rev1", "IH5rev1", "IH6norm2", "IH7norm2", "IH8norm2", "IH9norm2", "IH10norm2", "IH11norm3", "IH12norm3", "IH13norm3", "IH14norm3", "IH15norm3", "IH16norm3", "IH17rev4", "IH18rev4",  "IH19rev4", "IH20rev4", "IH21rev4", "IH22rev4")
IH_rev <- c( "IH1rev1", "IH2rev1", "IH3rev1", "IH4rev1", "IH5rev1", "IH17rev4", "IH18rev4", "IH19rev4", "IH20rev4", "IH21rev4", "IH22rev4")

# Exclusion criteria
  # >=90% of responses on the same option
  # response time <=22000ms
data_Q_total <- data_Q_total %>% 
  mutate(IH_max = max(table(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4)), na.rm = TRUE) /
           sum(table(c(IH1rev1, IH2rev1, IH3rev1, IH4rev1, IH5rev1, IH6norm2, IH7norm2, IH8norm2, IH9norm2, IH10norm2, IH11norm3, IH12norm3, IH13norm3, IH14norm3, IH15norm3, IH16norm3, IH17rev4, IH18rev4, IH19rev4, IH20rev4, IH21rev4, IH22rev4)), na.rm = TRUE))

data_Q_total <- data_Q_total %>% 
  mutate(IH_omit = case_when(IH_max >= .90 | END.QUESTIONNAIRE.INT.HUM <= 1000*length(IH) ~ 1,
                             IH_max < .90 & END.QUESTIONNAIRE.INT.HUM > 1000*length(IH) ~ 0))
 
# Omit IH data based on the IH_omit column
data_Q_total[which(data_Q_total$IH_omit == 1), IH] <- NA

# Reverse-coding
for (i in 1:length(IH_rev)) {
  data_Q_total[, IH_rev[i]] <- reverse.code(keys = c(-1), 
                                            items = data_Q_total[, IH_rev[i]],
                                            mini = c(1), 
                                            maxi = c(4))
}

# Describe: item-level
par(mfrow = c(4, 6))
for (i in 1:length(IH)) {
  hist(data_Q_total[, IH[i]],
       main = colnames(data_Q_total[IH[i]]),
       col = sample(colors(), 1),
       breaks = seq(0, 5, 1),
       xlab = ""
       )
}
describe(data_Q_total[, IH])

# Cronbach's alphas
alpha(data_Q_total[, IH[1:5]])
alpha(data_Q_total[, IH[6:10]])
alpha(data_Q_total[, IH[11:16]])
alpha(data_Q_total[, IH[17:22]])

# Intellectual Humility Scoring
# https://seaver.pepperdine.edu/social-science/content/comprehensive-intellectual-humility.pdf -> sum scores

# Calculate sum scores
data_Q_total$IH1Sum <- rowSums(cbind(data_Q_total$IH1rev1, data_Q_total$IH2rev1, data_Q_total$IH3rev1, data_Q_total$IH4rev1, data_Q_total$IH5rev1), na.rm = TRUE)
data_Q_total$IH2Sum <- rowSums(cbind(data_Q_total$IH6norm2, data_Q_total$IH7norm2, data_Q_total$IH8norm2, data_Q_total$IH9norm2, data_Q_total$IH10norm2), na.rm = TRUE)
data_Q_total$IH3Sum <- rowSums(cbind(data_Q_total$IH11norm3, data_Q_total$IH12norm3, data_Q_total$IH13norm3, data_Q_total$IH14norm3, data_Q_total$IH15norm3), na.rm = TRUE)
data_Q_total$IH4Sum <- rowSums(cbind(data_Q_total$IH17rev4, data_Q_total$IH18rev4, data_Q_total$IH19rev4, data_Q_total$IH20rev4, data_Q_total$IH21rev4), na.rm = TRUE)

# Describe: sum score level
IH_sum <- c(which(colnames(data_Q_total) == "IH1Sum"),
            which(colnames(data_Q_total) == "IH2Sum"),
            which(colnames(data_Q_total) == "IH3Sum"),
            which(colnames(data_Q_total) == "IH4Sum"))
par(mfrow = c(2, 2))
for (i in 1:length(IH_sum)) {
  hist(data_Q_total[, IH_sum[i]],
       main = colnames(data_Q_total[IH_sum[i]]),
       col = sample(colors(), 1),
       xlab = ""
       )
}
describe(data_Q_total[, IH_sum])

```

## Need for closure

```{r Scoring need for closure, include = FALSE}

# Need for Closure
need_clo <- c()
for (i in 1:15) {
  need_clo <- c(need_clo, which(colnames(data_Q_total) == paste0("closure", i)))
}

# Exclusion criteria
  # Response time (1s/item -> 15000ms total)
data_Q_total[which(data_Q_total$END.QUESTIONNAIRE.NEED.CLO <= 1000*length(need_clo)), need_clo] <- NA
# NOTE: case_when(Participant.Private.ID == "ppt ID that needs to be rejected for this task")

# Describe: item-level
par(mfrow = c(3, 5))
for (i in 1:length(need_clo)) {
  hist(data_Q_total[, need_clo[i]],
       main = colnames(data_Q_total[need_clo[i]]),
       breaks = seq(0, 6, 1),
       col = sample(colors(), 1),
       xlab = ""
       )
}
describe(data_Q_total[, need_clo])

# Cronbach's alphas
alpha(data_Q_total[, need_clo])

# Need for Closure Scoring
# https://www.midss.org/sites/default/files/need_for_closure_scale.pdf
# Not entirely sure if this is the correct file but it says to sum so I'll do that here

# Calculate Sum score
data_Q_total$CloSum <- rowSums(cbind(data_Q_total$closure1, data_Q_total$closure2, data_Q_total$closure3, data_Q_total$closure4, data_Q_total$closure5, data_Q_total$closure6, data_Q_total$closure7, data_Q_total$closure8, data_Q_total$closure9, data_Q_total$closure10, data_Q_total$closure11, data_Q_total$closure12, data_Q_total$closure13, data_Q_total$closure14, data_Q_total$closure15), na.rm = TRUE)

# Describe: sum score level
describe(data_Q_total$CloSum)
hist(data_Q_total$CloSum, 
     main = "Need for Closure", 
     col = rainbow(14), 
     ylim = c(0, 12), 
     breaks = seq(0, 80, 1), 
     xlab = "")

```

## Need for cognition

```{r Scoring need for cognition, include = FALSE}

# Need for Cognition
need_cog <- c("cognition1", "cognition2", "cognition3.rev", "cognition4.rev", "cognition5.rev", "cognition6", "cognition7.rev", "cognition8.rev", "cognition9.rev", "cognition10", "cognition11", "cognition12.rev", "cognition13", "cognition14", "cognition15", "cognition16.rev", "cognition17.rev","cognition18")
need_cog_rev <- c("cognition3.rev", "cognition4.rev", "cognition5.rev",  "cognition7.rev", "cognition8.rev", "cognition9.rev", "cognition12.rev", "cognition16.rev", "cognition17.rev")

# Exclusion criteria
  # >=90% of responses fall on the same response option
  # respone time <=18000ms
data_Q_total <- data_Q_total %>% 
  mutate(Cog_max = max(table(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18)), na.rm = TRUE) /
           sum(table(c(cognition1, cognition2, cognition3.rev, cognition4.rev, cognition5.rev, cognition6, cognition7.rev, cognition8.rev, cognition9.rev, cognition10, cognition11, cognition12.rev, cognition13, cognition14, cognition15, cognition16.rev, cognition17.rev, cognition18)), na.rm = TRUE))

data_Q_total <- data_Q_total %>% 
  mutate(Cog_omit = case_when(Cog_max >= .90 | END.QUESTIONNAIRE.NEED.COG <= 1000*length(need_cog) ~ 1,
                             Cog_max < .90 & END.QUESTIONNAIRE.NEED.COG > 1000*length(need_cog) ~ 0))
 
# Omit Cog data based on the Cog_omit column
data_Q_total[which(data_Q_total$Cog_omit == 1), need_cog] <- NA

# Reverse-coding
for (i in 1:length(need_cog_rev)) {
  data_Q_total[, need_cog_rev[i]] <- reverse.code(keys = c(-1),
                                                  items = data_Q_total[, need_cog_rev[i]],
                                                  mini = c(1),
                                                  maxi = c(6))
}

# Describe: item-level
par(mfrow = c(3, 6))
for (i in 1:length(need_cog)) {
  hist(data_Q_total[, need_cog[i]],
       main = colnames(data_Q_total[need_cog[i]]),
       breaks = seq(0, 6, 1),
       col = sample(colors(), 1),
       xlab = ""
       )
}
describe(data_Q_total[, need_cog])

# Cronbach's alphas
alpha(data_Q_total[, need_cog])

# Need for Cognition Scoring
# https://centerofinquiry.org/uncategorized/need-for-cognition-scale-wabash-national-study/
# According to this source you should calculate the sum score for this scale

# Calculate Sum score
data_Q_total$CogSum <- rowSums(cbind(data_Q_total$cognition1, data_Q_total$cognition2, data_Q_total$cognition3.rev, data_Q_total$cognition4.rev, data_Q_total$cognition5.rev, data_Q_total$cognition6, data_Q_total$cognition7.rev, data_Q_total$cognition8.rev, data_Q_total$cognition9.rev, data_Q_total$cognition10, data_Q_total$cognition11, data_Q_total$cognition12.rev, data_Q_total$cognition13, data_Q_total$cognition14, data_Q_total$cognition15, data_Q_total$cognition16.rev, data_Q_total$cognition17.rev, data_Q_total$cognition18), na.rm = TRUE)

# Describe: sum-score level
describe(data_Q_total$CogSum)
hist(data_Q_total$CogSum,
     main = "Need for Cognition", 
     col = rainbow(14), 
     xlab = "")

```

## Actively openminded thinking

```{r Scoring actively openminded thinking, include = FALSE}

# Actively Openminded Thinking
aot <- c("openReverse1", "openReverse2", "openReverse3", "openReverse4", "openNormal1", "openNormal2", "openNormal3")
aot_rev <- c("openReverse1", "openReverse2", "openReverse3", "openReverse4")

# Exclusion criteria
  # >=90% of responses on the same response option
  # <=7000ms response time
data_Q_total <- data_Q_total %>% 
  mutate(AOT_max = max(table(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3)), na.rm = TRUE) /
           sum(table(c(openReverse1, openReverse2, openReverse3, openReverse4, openNormal1, openNormal2, openNormal3)), na.rm = TRUE))

data_Q_total <- data_Q_total %>% 
  mutate(AOT_omit = case_when(AOT_max >= .90 | END.QUESTIONNAIRE.OPEN.THINK <= 1000*length(aot) ~ 1, 
                             AOT_max < .90 & END.QUESTIONNAIRE.OPEN.THINK > 1000*length(aot) ~ 0))
 
# Omit AOT data based on the AOT_omit column
data_Q_total[which(data_Q_total$AOT_omit == 1), aot] <- NA

# Reverse-code
for (i in 1:length(aot_rev)) {
  data_Q_total[, aot_rev[i]] <- reverse.code(keys = c(-1), 
                                             items = data_Q_total[, aot_rev[i]], 
                                             mini = c(1), 
                                             maxi = c(7))
}

# Describe: item-level
par(mfrow = c(2, 4))
for (i in 1:length(aot)) {
  hist(data_Q_total[, aot[i]], 
       main = colnames(data_Q_total[aot[i]]), 
       col = sample(colors(), 1), 
       breaks = seq(0, 7, 1), 
       xlab = "")
}
describe(data_Q_total[, aot])

# Cronbach's alpha
alpha(data_Q_total[, aot])

# Actively Openminded Thinking Scoring
# https://www.sciencedirect.com/science/article/pii/S1871187119303700
# Again, this article says to do a sum score

# Calculate Sum score
data_Q_total$AOTSum <- rowSums(cbind(data_Q_total$openNormal1, data_Q_total$openNormal2, data_Q_total$openNormal3, data_Q_total$openReverse1, data_Q_total$openReverse2, data_Q_total$openReverse3, data_Q_total$openReverse4), na.rm = TRUE)

# Describe: sum-score level
describe(data_Q_total$AOTSum)
hist(data_Q_total$AOTSum,
     main = "Actively Openminded Thinking", 
     col = rainbow(14), 
     xlab = "")

```


## Matrix Reasoning

This was coded as a Task in Gorilla but analyzed like a questionnaire.

```{r Scoring matrix reasoning, include = FALSE}

# Omit columns that are not relevant (experiment-general columns) + rows that are not relevant (e.g., practice trials)
data_matreasT <- data_matreasT %>%
  select(Participant.Private.ID, Spreadsheet:ANSWER) %>% 
  filter(display %in% c("TehtÃ¤vÃ¤_6", "TehtÃ¤vÃ¤_8"))

# Omit participants who commented that they had technical issues with this task or did not understand the task
data_matreasT <- data_matreasT %>%
 filter(Participant.Private.ID != "5555882" & Participant.Private.ID != "5608075" & Participant.Private.ID != "4887607")

# Exclusion Criteria
  # median reaction time <= 500ms
data_matreasT <- data_matreasT %>%
 group_by(Participant.Private.ID) %>%
 mutate(medianRT = median(Reaction.Time, na.rm = TRUE)) %>%
 mutate(Matrix_omit = case_when((medianRT > 500) ~ 0, 
                (medianRT <= 500) ~ 1))
# Create a separate df for subsetting
data_matrix_omit <- data_matreasT %>%
 group_by(Participant.Private.ID) %>%
 summarise(Matrix_omit = mean(Matrix_omit)) %>%
 select(Participant.Private.ID, Matrix_omit) 
# Extract the relevant information
data_matreasT <- data_matreasT %>%
 group_by(Participant.Private.ID) %>%
 summarise(MatrixCorrectCount = sum(Correct, na.rm = TRUE)) %>%
 select(Participant.Private.ID, MatrixCorrectCount)
# Omit data based on matrix_omit
data_matreasT_final <- merge(data_matreasT, data_matrix_omit, 
                             by = "Participant.Private.ID", 
                             all = TRUE)
data_matreasT_final[which(data_matreasT_final$Matrix_omit == 1), "MatrixCorrectCount"] <- NA
data_matreasT_final <- data_matreasT_final %>%
  select(Participant.Private.ID, MatrixCorrectCount)

# Exclude participants with invalid responses
data_ValidityFlag <- data_validQ %>%
  select(Participant.Private.ID, Validity.quantised)
data_Language <- data_demoQ %>%
  select(Participant.Private.ID, Language)
data_matrixValidity <- merge(data_Language, data_ValidityFlag, 
                             by = "Participant.Private.ID", 
                             all = TRUE)
data_matreasT_final <- merge(data_matreasT_final, data_matrixValidity, 
                             by = "Participant.Private.ID", 
                             all = TRUE)

# Create separate df for nonvalid ppts
data_nonvalid_matrix <- data_matreasT_final %>%
  filter(Validity.quantised %in% c(2, 3, 4))
data_Q_lang_omit_matrix <- data_matreasT_final %>%
  filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")
data_matreasT_final <- data_matreasT_final %>%
  filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?"))

# Delete the irrelevant columns
data_matreasT_final <- data_matreasT_final %>%
 select(Participant.Private.ID, MatrixCorrectCount)

# Describe
describe(data_matreasT_final$MatrixCorrectCount)
hist(data_matreasT_final$MatrixCorrectCount,
     main = "Matrix Score", 
     col = rainbow(14), 
     xlab = "")

```

## Science Attitudes Questionnaire

This section has 12 questions with Likert responses that represent a (possible) 3 factor model based on the sources of the questions, from an early version of the Science Capital Scale from the FINSCI population survey study. The first 8 questions originally come from Archer, 2015, and the last 4 are modified from the Trust in Science and Scientists Scale (Nadelson et al., 2014). 

There are 3 additional questions that can be analyzed separately or used in demographic info. We hadn't really decided what to do with those questions yet.

```{r Scoring science attitudes, include = FALSE}

# Science Attitudes
sci_att <- c("sa.1a", "sa.1b", "sa.1c", "sa.1d", "sa.1e", "sa.1f", "sa.1g", "sa.1h", "sa.2a", "sa.2b", "sa.2c", "sa.2d")
sci_att_rev <- c("sa.1b", "sa.1d", "sa.2a", "sa.2b", "sa.2d")

# Exclusion criteria
  # >=90% of responses fall on the same response option
  # <=15000ms response time
data_Q_total <- data_Q_total %>% 
  mutate(sciatt_max = max(table(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d)), na.rm = TRUE) /
           sum(table(c(sa.1a, sa.1b, sa.1c, sa.1d, sa.1e, sa.1f, sa.1g, sa.1h, sa.2a, sa.2b, sa.2c, sa.2d)), na.rm = TRUE))

data_Q_total <- data_Q_total %>% 
  mutate(sciatt_omit = case_when(sciatt_max >= .90 | END.QUESTIONNAIRE.SCIENCE.ATT <= 1000*length(sci_att) ~ 1, 
                             sciatt_max < .90 & END.QUESTIONNAIRE.SCIENCE.ATT> 1000*length(sci_att) ~ 0))
 
# Omit science attitude data based on sciatt_omit column
data_Q_total[which(data_Q_total$sciatt_omit == 1), sci_att] <- NA

# Reverse-code
for (i in 1:length(sci_att_rev)) {
  data_Q_total[, sci_att_rev[i]] <- reverse.code(keys = c(-1), 
                                             items = data_Q_total[, sci_att_rev[i]], 
                                             mini = c(1), 
                                             maxi = c(5))
}

# Describe: item-level
par(mfrow = c(3, 4))
for (i in 1:length(sci_att)) {
  hist(data_Q_total[, sci_att[i]], 
       main = colnames(data_Q_total[sci_att[i]]), 
       col = sample(colors(), 1), 
       breaks = seq(0, 7, 1), 
       xlab = "")
}
describe(data_Q_total[, sci_att])

# Cronbach's alphas
alpha(data_Q_total[, sci_att])

# Calculate sum score
data_Q_total$sci_id <- rowSums(cbind(data_Q_total$sa.1a, data_Q_total$sa.1b.rev, data_Q_total$sa.1d.rev, data_Q_total$sa.1g), na.rm = TRUE)
data_Q_total$sci_impo <- rowSums(cbind(data_Q_total$sa.1c, data_Q_total$sa.1e, data_Q_total$sa.1h, data_Q_total$sa.1f), na.rm = TRUE)
data_Q_total$sci_tru <- rowSums(cbind(data_Q_total$sa.2a.rev, data_Q_total$sa.2b.rev, data_Q_total$sa.2c, data_Q_total$sa.2d.rev), na.rm = TRUE)

# Replace total score zeroes with NA
data_Q_total$sci_id[which(data_Q_total$sci_id == 0)] <- NA
data_Q_total$sci_impo[which(data_Q_total$sci_impo == 0)] <- NA
data_Q_total$sci_tru[which(data_Q_total$sci_tru == 0)] <- NA

# Describe: sum-score level
sci_att_sum <- c("sci_id", "sci_impo", "sci_tru")
describe(data_Q_total[, sci_att_sum])
par(mfrow = c(3, 1))
for (i in 1:length(sci_att_sum)) {
  hist(data_Q_total[, sci_att_sum[i]], 
       main = colnames(data_Q_total[sci_att_sum[i]]), 
       col = sample(colors(), 1), 
       xlab = "")
}

```


## Science Curiosity

This is a 4-item scale, scored as a single sum score from the quantised responses. No reverse scoring. 
Modified from Landrum et al., 2016 and Motta et al., 2019

```{r Scoring science curiosity, include = FALSE}

## Science Curiosity (Range 1-5)

# How often, if at all, did you attend a science or technology-related public lecture or other presentation (e.g., a webinar) outside of study or work?
 # Not once
 # Once a year
 # Twice a year
 # 3-4 times a year
 # More than 5 times a year
# How many books on scientific research or scientific discoveries have you read in the last year?
 # Not at all
 # Equally
 # Two
 # Three or four
 # Five or more
# I am interested in scientific research and scientific discoveries.
# I follow the news about new technologies.
 # Completely disagree
 # Different opinion
 # Neither different nor agree
 # Agree
 # Completely agree

sci_cur <- c("sc.1.quantised", "sc.2.quantised","sc.3.quantised", "sc.3.quantised")

# Exclusion criteria
  # >=4000ms response time
data_Q_total <- data_Q_total %>%
 mutate(Sci.cur_omit = case_when(END.QUESTIONNAIRE.SCIENCE.CUR <= 4000 ~ 1, 
                 END.QUESTIONNAIRE.SCIENCE.CUR > 4000 ~ 0))

# Omit SC data based on the Sci.cur_omit column
data_Q_total[which(data_Q_total$Sci.cur_omit == 1), sci_cur] <- NA

# Describe: item-level
par(mfrow = c(2, 2))
for (i in 1:length(sci_cur)) {
  hist(data_Q_total[, sci_cur[i]], 
       main = colnames(data_Q_total[sci_cur[i]]), 
       col = sample(colors(), 1), 
       breaks = seq(0, 7, 1), 
       xlab = "")
}
describe(data_Q_total[, sci_cur])

# Cronbach's alpha
alpha(data_Q_total[, sci_cur])

# Calculate sum score
data_Q_total$sci_cur <- rowSums(cbind(data_Q_total$sc.1.quantised, data_Q_total$sc.2.quantised, data_Q_total$sc.3.quantised, data_Q_total$sc.4.quantised), na.rm = TRUE)

# Replace sum score 0s with NAs
data_Q_total$sci_cur[which(data_Q_total$sci_cur == 0)] <- NA

# Describe: sum-score level
describe(data_Q_total$sci_cur)
hist(data_Q_total$sci_cur, 
     col = sample(colors(), 1), 
     xlab = "")


```

## Heuristic Reasoning

***is this scoring method correct??***

6 items selected from Morsanyi et al., 2009. Each question has three possible answers: normative (correct), incorrect, and heuristic. The heuristic response options are either Representativeness Heuristic or Equiprobability Heuristic, depending on the question. The 3 final scores of interest (H-R, H-E, and N) are calculated as a percentage of total (6) responses. E.g. if a ppt gives N responses for questions 1, 2, 4, and 5, and heuristic responses for questions 3 and 6, their scores are: .17, .17, and .67. The heuristic responses can be calculated as either a percentage of each category (1/3) or of the total (1/6)--they will be proportional to each other, so it doesn't really matter.

For these purposes, incorrect answers will be excluded from analysis because they are not useful as most people don't give any wrong answers, and heuristic responses are binned together per participant. Participants each then have an HE score (0 or 1), and an HR score (0 or 1), each representing whether or not they made at least one heuristic mistake of that type (equiprobability or representativeness). 0 0 is a perfect normative tendency. 

```{r Scoring heuristic reasoning, include = FALSE}

# Exclusion criteria
  # <=6000ms response time
data_Q_total <- data_Q_total %>%
 mutate(HR_omit = case_when(END.QUESTIONNAIRE.HEURISTIC <= 6000 ~ 1, 
                            END.QUESTIONNAIRE.HEURISTIC > 6000 ~ 0))

# Q1
# Luonnollinen sukupuolijakauma syntyvien lasten osalta on arviolta yksi mies naista kohden. Tämä tarkoittaa sitä, että syntyvä lapsi on 50% todennäköisyydellä poika ja 50 % todennäköisyydellä tyttö. Kuvittele perhe, johon on syntynyt viisi lasta, kaikki heistä poikia. Mikä seuraavista on todennäköisin?
 # Kuudes lapsi on tyttö = H-R
 # Kuudes lapsi on poika = X
 # Kumpikin on yhtä todennäköistä = N

data_Q_total$hr.1 <- as.factor(data_Q_total$hr.1)
levels(data_Q_total$hr.1) <- list("N" = "Kumpikin on yhtÃ¤ todennÃ¤kÃ¶istÃ¤", "H-R" = "Kuudes lapsi on tyttÃ¶", "Neither" = "Kuudes lapsi on poika")

# Q2
# Kolikkoa heitetään kuusi kertaa. Kumpi seuraavista sarjoista on todennäköisempi kuuden kolikonheiton jälkeen? (H: Head = kruuna, T: Tails = klaava)
 # THHTHT
 # HTHTHT
 # Kummatkin sarjat ovat yhtä todennäköisiä
data_Q_total$hr.2 <- as.factor(data_Q_total$hr.2)
levels(data_Q_total$hr.2) <- list("N" = "Kummatkin sarjat ovat yhtÃ¤ todennÃ¤kÃ¶isiÃ¤", "H-R" = "THHTHT", "Neither" = "HTHTHT")

# Q3
# Terveystutkimus toteutettiin 100 aikuisen miehen otokselle, jossa kaikki ikäluokat ja ammattiryhmät olivat edustettuina. Herra F. valittiin osallistujien joukosta satunnaisesti. Herra F. on johtaja. Hän vietti pitkään todella kiireistä elämää. Hän osallistui useina iltoina yritysillallisiin ja hän oli harvoin lomalla. Hiljattain hänen piti lopettaa työskentely vähäksi aikaa. Hän on aloittanut työskentelyn uudelleen, mutta nykyisin hän ei ole yhtä kiireinen. Aiemmin hän hölkkäsi puistossa, mutta nyt hän menee mieluummin kävelylle. Raahaa seuraavat väittämät järjestykseen siten, että todennäköisin on ylimpänä ja epätodennäköisin alimpana.
# Todennäköisin

 # Herra F. on yli 55-vuotias ja on saanut sydänkohtauksen
 # Herra F. sai sydänkohtauksen
 # Herra F.:llä on suuri perhe

# Giving lower rating to response a.) than to response b.) is considered a heuristic response (H-R), and the opposite of this is considered a normative response (N).


# 3.1
data_Q_total$hr.3.1 <- as.factor(data_Q_total$hr.3.1)
levels(data_Q_total$hr.3.1) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")

# 3.2
data_Q_total$hr.3.2 <- as.factor(data_Q_total$hr.3.2)
levels(data_Q_total$hr.3.2) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")

# 3.3
data_Q_total$hr.3.3 <- as.factor(data_Q_total$hr.3.3)
levels(data_Q_total$hr.3.3) <- list("b" = "Herra F. sai sydÃ¤nkohtauksen", "a" = "Herra F. on yli 55-vuotias ja on saanut sydÃ¤nkohtauksen", "c" = "Herra F.:llÃ¤ on suuri perhe")

# Create the variables for the combinations of answers
# abc / acb / cab = N; bac / bca /cba = H-R
data_Q_total <- data_Q_total %>%
  mutate(hr.3.updated = case_when(
 ((hr.3.1 == "b" & (hr.3.2 == "a"|hr.3.3 == "a")) | hr.3.2 == "b" & hr.3.3 == "a") ~ "H-R", 
 ((hr.3.1 == "a" & (hr.3.2 == "b"|hr.3.3 == "b")) | (hr.3.2 == "a" & hr.3.3 == "b")) ~ "N"
 ))
data_Q_total$hr.3.updated <- factor(data_Q_total$hr.3.updated)


# Q4
# Kaksi eri tutkimusta selvittivät unettomuuden hoidossa kahden eri hoitomuodon vaikuttavuutta. Ensimmäisessä tutkimuksessa 400 lääkettä saaneesta henkilöstä 140 sai huomattavaa helpotusta. Toisessa tutkimuksessa 40 kognitiivis-behavioraalista terapiaa saaneesta potilaasta 16 kykeni nukkumaan paremmin kuin ennen hoitoa. Kumpaa hoitoa (jos kumpaakaan) suosittelisit unettomalle potilaalle?
 # Lääkehoitoa
 # Kognitiivis-behavioraalista terapiaa
 # Kumpikin on yhtä tehokas

data_Q_total$hr.4 <- as.factor(data_Q_total$hr.4)
levels(data_Q_total$hr.4) <- list("H-E" = "Kumpikin on yhtÃ¤ tehokas", "N" = "Kognitiivis-behavioraalista terapiaa", "Neither" = "LÃ¤Ã¤kehoitoa")
# Kognitiivis-behavioraalista terapiaa = N; Yhta tehokas = H-E

# Q5
# Mitä tarkoittaa, kun sääennusteessa kerrotaan sateen todennäköisyyden olevan huomenna 70%?
 # Huomenna luultavasti sataa
 # On mahdotonta sanoa sataako huomenna vai ei
 # Huomenna sataa

data_Q_total$hr.5 <- as.factor(data_Q_total$hr.5)
levels(data_Q_total$hr.5) <- list("N" = "Huomenna luultavasti sataa", "H-E" = "On mahdotonta sanoa sataako huomenna vai ei", "Neither" = "Huomenna sataa")
# Huomenna luultavasti sataa = N; On mahdotonta sanoa sataako huomenna vai ei = H-E

# Q6
# Luokassa on 13 poikaa ja 16 tyttöä. Opettaja suorittaa arvonnan. Jokaisen oppilaan nimi on kirjoitettuna paperilapulle. Kaikki laput laitetaan hattuun. Opettaja nostaa yhden lapun katsomatta hattuun. Kuka voittaa arvonnassa?
 # Poika
 # Tyttö
 # Kumpikin on yhtä todennäköistä
data_Q_total$hr.6 <- as.factor(data_Q_total$hr.6)
levels(data_Q_total$hr.6) <- list("N" = "TyttÃ¶", "H-E" = "Kumpikin on yhtÃ¤ todennÃ¤kÃ¶istÃ¤", "Neither" = "Poika")
# Tytto = N; Kumpikin on yht? todenn?k?ist? = H-E

# Calculate sums
data_Q_total <- data_Q_total %>%
 mutate(
  total_N = apply(., 1, function(x) length(which(x == "N"))), 
  total_HR = apply(., 1, function(x) length(which(x == "H-R"))), 
  total_HE = apply(., 1, function(x) length(which(x == "H-E"))), 
  total_Neither = apply(., 1, function(x) length(which(x == "Neither")))
 )

# Omit heuristic reasoning data based on the HR_omit column
heur <- c("total_N", "total_HR", "total_HE", "total_Neither")
data_Q_total[which(data_Q_total$HR_omit == 1), heur] <- NA

# this replaces the zeroes in these new columns with NA--only if there are zeroes in all 4 of these sum columns, because that indicates missing data (the participant didn't do the task), not true zeroes. The lines going down are different because after the first column's value gets replaced with NA, the logic of the whole set is changed, so there is now a combination of NAs and zeroes
data_Q_total[which(data_Q_total$total_N == 0 & data_Q_total$total_HR == 0 & data_Q_total$total_HE == 0 & data_Q_total$total_Neither == 0), heur] <- NA

# Describe
describe(data_Q_total[, heur])
par(mfrow = c(2, 2))
for (i in 1:length(heur)) {
  hist(data_Q_total[, heur[i]], 
       main = colnames(data_Q_total[heur[i]]), 
       col = sample(colors(), 1), 
       xlab = "")
}

# Create binary heuristic scores (0=0, 1=everything else)
data_Q_total <- data_Q_total %>% 
  mutate(HEscore = case_when(total_HE == 0 ~ 0,
                             total_HE != 0 ~ 1),
         HRscore = case_when(total_HR == 0 ~ 0,
                             total_HR != 0 ~ 1))

# Add a measure of total heuristic response, where 1 = at least one mistake in one heuristic category, 2 = at least 1 heuristic mistake in both heuristic categories, 0 = all normative responses
data_Q_total <- data_Q_total %>%
  group_by(Participant.Private.ID) %>% 
  mutate(HEHRscore = HEscore + HRscore)

```

# WHERE YOU LEFT OFF
# NOTE: all outlier stuff for single items is omitted

## Randomness and Probability

```{r Scoring randomness and probability, include = FALSE}

# Exclusion criteria
  #response time (1s/item -> 7000ms total)

## min response time
data_Q_total <- data_Q_total %>%
 mutate(RP_omit = case_when(END.QUESTIONNAIRE.RANDOM.PROB <= 4000 ~ 1, 
               END.QUESTIONNAIRE.RANDOM.PROB > 4000 ~ 0))

# Q1
# Sairaala B is the correct answer
class(data_Q_total$rp.1) 
data_Q_total$rp.1 <- as.factor(data_Q_total$rp.1) #transforming into a factor
levels(data_Q_total$rp.1)

# Creating a new column
data_Q_total <- data_Q_total %>%
 mutate(rp.1.int = case_when(rp.1 == "Sairaalassa B (jossa syntyy 10 lasta pÃ¤ivÃ¤ssÃ¤)." ~ 1, 
               rp.1 != "Sairaalassa B (jossa syntyy 10 lasta pÃ¤ivÃ¤ssÃ¤)." ~ 0)) # rows with correct answer take value 1 in the new column

# Q2
# Robottiteht?v?: Pyydys1 AND Pyydys 2. You only get a point if you have both of these and no other options.
class(data_Q_total$rp.2.1) 
data_Q_total$rp.2.1 <- as.factor(data_Q_total$rp.2.1)
levels(data_Q_total$rp.2.1)
data_Q_total$rp.2.2 <- as.factor(data_Q_total$rp.2.2)
data_Q_total$rp.2.3 <- as.factor(data_Q_total$rp.2.3)
data_Q_total$rp.2.4 <- as.factor(data_Q_total$rp.2.4)
data_Q_total$rp.2.5 <- as.factor(data_Q_total$rp.2.5)
data_Q_total$rp.2.6 <- as.factor(data_Q_total$rp.2.6)
data_Q_total$rp.2.7 <- as.factor(data_Q_total$rp.2.7)
data_Q_total$rp.2.8 <- as.factor(data_Q_total$rp.2.8)


# Creating a new column
# original code used isn.na(var) for the first chunk (assigning 1 point to correct answers) but the df cells are blank, not NA, so there were no correct answers. Can use the empty string "" for blank cells. This way assigns 1 to all cases that match the one correct answer combination and NA to anything else. This way avoids missing something if we were to try to list all the possible combinations.

data_Q_total <- data_Q_total %>%
 mutate(rp.2.int = case_when((rp.2.1 == "Pyydys 1" & rp.2.2 == "Pyydys 2" & rp.2.3 == "" & rp.2.4 == "" & rp.2.5 == "" & rp.2.6 == "" & rp.2.7 == "" & rp.2.8 == "") ~ 1))
 
# this keeps the 1s but replaces NAs with zeroes. In the last part of this chunk, we'll NA all ppts who didn't actually complete this task and get rid of any spurious zeroes
data_Q_total <- data_Q_total %>%
 mutate(rp.2.int = case_when(rp.2.int == "1" ~ 1, 
              (is.na(rp.2.int) ~ 0)))    

# Q3
# Kanava 1; 2 tai 3 is the correct answer
# It's easier to use rp.3.quantised to score this question than deal with the strings
# Kanava 1; 2 tai 3 = 4
# Kanava 2 tai 3 = 2
# Kanava 2 = 5
# Kanava 1 tai 3 = 3
# Kanava 1 tai 2 = 7
# Kanava 3 = 6

#class(data_Q_total$rp.3.quantised)

# Creating a new column
data_Q_total <- data_Q_total %>%
 mutate(rp.3.int = case_when(rp.3.quantised == "4" ~ 1, 
               rp.3.quantised != "4" ~ 0))

# Q4
# Ruudukot A; B ja C is the correct answer
# used rp.4.quantised for scoring this one too
### Ruudukot A; B ja C = 5
# Ruudukko B = 2
# Ruudukko A = 1
# Ruudukko C = 3
# Ruudukot A ja C = 4 

#class(data_Q_total$rp.4)

data_Q_total <- data_Q_total %>%
 mutate(rp.4.int = case_when(rp.4.quantised == "5" ~ 1, 
               rp.4.quantised != "5" ~ 0))

# Calculating the sum score for the randomness/probability questions
data_Q_total <- data_Q_total %>%
 mutate(RPSum = rp.1.int + rp.2.int + rp.3.int + rp.4.int)



# Omitting Randomness-Probability data based on the RP_omit column
data_Q_total$RPSum[which(data_Q_total$RP_omit == 1)] <- NA
data_Q_total$RPSum[which(is.na(data_Q_total$RP_omit))] <- NA 
# The way we've processed the questions resulted in some spurious zeroes, e.g. for ppts who didn't actually complete the task. If RP_omit = NA, then the ppt didn't do the task, and RPSum is replaced with NA based on this. 
# An alternative way to do it:
#data_Q_total$RPSum <- rowSums(cbind(data_Q_total$rp.1.int, data_Q_total$rp.2.int, data_Q_total$rp.3.int, data_Q_total$rp.4.int), na.rm = TRUE)

#hist(data_Q_total$RPSum, main = "Randomness/Probability Sum Score", col = rainbow(14), breaks = seq(0, 4, 1), xlab = "")

#RP_task <- (describe(data_Q_total$RPSum))
#row.names(RP_task) <- c("RPSum")
#View(RP_task)

```


# Merging Questionnaire variables

```{r Merging questionnaire variables, include = FALSE}

## Merging the important columns
data_Q_sub <- data_Q_total %>%
 select(Participant.Private.ID, gender, Age, Country, Language, Education, AMean, CMean, EMean, ESMean, OMean, ICuriositySum, DCuriositySum, IH1Sum, IH2Sum, IH3Sum, IH4Sum, CloSum, CogSum, AOTSum, HEscore, HRscore, RPSum, sci_cur, sci_tru, sci_impo, sci_id)

# for now leaving out this variable I created that isn't in the original variable list
#HEHRscore

# Adding matrix to the dataframe
# I think this syntax can be used to add all the other parts not included in data_Q_total, because they are within their own dfs but do not need to be added to data_Q_total first if they're able to be added separately here 
# double check that merge is keeping unique rows; if not, use cbind 
# this has to be added separately because it's a questionnaire coded as a task. Other task variables are put into their own dataframe separately which can be merged to create a total minimal variable set for EFA

data_Q_sub <- merge(data_Q_sub, data_matreasT_final, by = "Participant.Private.ID", all = TRUE)

# Make sure to include the argument all = TRUE! This includes rows that contain NA, which is necessary to include ppts with missing data. The default in merge() is to get rid of rows containing NA. 

# use this to get rid of NaNs or string NAs introduced by calculations
is.nan.data.frame <- function(x)
 do.call(cbind, lapply(x, is.nan))

data_Q_sub[is.nan(data_Q_sub)] <- NA

# probably need to coerce the numeric variables to numeric, don't do the whole data frame because then you lose the factors. Do it here so you don't have to do it later.
data_Q_sub$MatrixCorrectCount <- as.numeric(data_Q_sub$MatrixCorrectCount)
data_Q_sub$Age <- as.numeric(data_Q_sub$Age)


```

# Q missing data

Analyzing missing data in questionnaires. 

Better to do this for tasks and questionnaires separately, because they have different reasons for being missing and different implications. Do this before checking distributions because ppts with large amounts of missing data or suspicious patterns of missing data are removed here from the final dataset. 

Current N after this chunk N = 162 

```{r Analyzing Q missing data, include = FALSE}

# some cool missing data packages
library(ggplot2)
library(naniar)

# add a column for count of missing data per ppt, to sub df
data_Q_sub <- data_Q_sub %>%
 mutate(missingdata = rowSums(is.na(data_Q_sub)))

View(data_Q_sub)

# hard to ID a cutoff point because cutting at the elbow gets rid of too much data. 11 missing variables is ppts with at least 50% of usable data--about 5 ppts difference between cutoff of 30% or 50% (11 or 15 variables)
# we need to specify some cutoff point because 20 missing variables out of 22 is too many 
ggplot(data_Q_sub, aes(x = as.factor(Participant.Private.ID), y = missingdata)) + 
   geom_boxplot(fill = "slateblue", alpha = 0.2) + 
   xlab("Missing variables count")

# see if there's an elbow in the number of missing variables per ppt
MissingData<-sort(data_Q_sub$missingdata, decreasing = FALSE)
plot(MissingData)

gg_miss_fct(x = data_Q_sub, fct = Age)
cor.test(data_Q_sub$Age, data_Q_sub$missingdata, method = "spearman", exact = FALSE)

# visualizing missing data by demographics
gg_miss_fct(x = data_Q_sub, fct = Language)
gg_miss_fct(x = data_Q_sub, fct = Country)
gg_miss_fct(x = data_Q_sub, fct = gender)
gg_miss_fct(x = data_Q_sub, fct = Education)

# removing ppts with 16 or fewer variables missing out of total 22 (30%)
data_Q_sub <- data_Q_sub %>%
 group_by(Participant.Private.ID) %>%
 filter(missingdata < 16)

View(data_Q_sub)

```


# Q distributions and correlations

This chunk checks distributions of questionnaire variables and correlations between them. It's recommended that if two variables are highly correlated, to drop one of them. 

It also transforms variables that need to be transformed--no transformations applied yet.


```{r Checking the normality of the questionnaire variables, include = FALSE}

# Further subsetting the data as we probably won't need the demographic variables here (?)
#data_Q_sub2 <- data_Q_sub %>%
 #select(AMean:MatrixCorrectCount)

## Normality of variables: visualising with histograms
AMean <- ggplot(data_Q_sub, aes(x = AMean)) +
 geom_histogram(color = "black", fill = "lightblue")
AMean
CMean <- ggplot(data_Q_sub, aes(x = CMean)) +
 geom_histogram(color = "black", fill = "lightblue")
CMean
EMean <- ggplot(data_Q_sub, aes(x = EMean)) +
 geom_histogram(color = "black", fill = "lightblue")
EMean
OMean <- ggplot(data_Q_sub, aes(x = OMean)) +
 geom_histogram(color = "black", fill = "lightblue")
OMean
ESMean <- ggplot(data_Q_sub, aes(x = ESMean)) +
 geom_histogram(color = "black", fill = "lightblue")
ESMean
ICuriositySum <- ggplot(data_Q_sub, aes(x = ICuriositySum)) +
 geom_histogram(color = "black", fill = "lightblue")
ICuriositySum
DCuriositySum <- ggplot(data_Q_sub, aes(x = DCuriositySum)) +
 geom_histogram(color = "black", fill = "lightblue")
DCuriositySum
IH1Sum <- ggplot(data_Q_sub, aes(x = IH1Sum)) +
 geom_histogram(color = "black", fill = "lightblue")
IH1Sum
IH2Sum <- ggplot(data_Q_sub, aes(x = IH2Sum)) +
 geom_histogram(color = "black", fill = "lightblue")
IH2Sum
IH3Sum <- ggplot(data_Q_sub, aes(x = IH3Sum)) +
 geom_histogram(color = "black", fill = "lightblue")
IH3Sum
IH4Sum <- ggplot(data_Q_sub, aes(x = IH4Sum)) +
 geom_histogram(color = "black", fill = "lightblue")
IH4Sum
CloSum <- ggplot(data_Q_sub, aes(x = CloSum)) +
 geom_histogram(color = "black", fill = "lightblue")
CloSum
CogSum <- ggplot(data_Q_sub, aes(x = CogSum)) +
 geom_histogram(color = "black", fill = "lightblue")
CogSum
AOTSum <- ggplot(data_Q_sub, aes(x = AOTSum)) +
 geom_histogram(color = "black", fill = "lightblue")
AOTSum

RPSum <- ggplot(data_Q_sub, aes(x = RPSum)) +
 geom_histogram(color = "black", fill = "lightblue")
RPSum
MatrixCorrectCount <- ggplot(data_Q_sub, aes(x = MatrixCorrectCount)) +
 geom_histogram(color = "black", fill = "lightblue")
MatrixCorrectCount


# Transformations 

## Normality of variables: skewness
#which(abs(skew(data_Q_sub))>1) 
#almost all variables are skewed to some extent...

## Correlation matrix
#If two (or more) variables from the same questionnaire or task correlate so that r>.85, one of them should be omitted (from Eisenberg et al.)
#no omissions needed from questionnaires

# check the indexes, it changes if you've deleted the demographic columns
# no strong corelations in TIPI
# TRUE values: we should consider omitting one of the variables 
cor(data_Q_sub[, 2:6], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[, 2:6], method = "pearson", use = "pairwise.complete.obs")) > .85 

# correlation 0.558, but I think EC is supposed to correlate, and is still under .85
cor(data_Q_sub[, 7:8], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[, 7:8], method = "pearson", use = "pairwise.complete.obs")) > .85

# no strong correlations in intellectual humility either
cor(data_Q_sub[, 9:12], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[, 9:12], method = "pearson", use = "pairwise.complete.obs")) > .85

# no strong correlations in science attitudes either
cor(data_Q_sub[, 20:22], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_Q_sub[, 20:22], method = "pearson", use = "pairwise.complete.obs")) > .85

# subsetting now: this is the cleaned copy with only variables to be used in EFA
data_Q_sub <- data_Q_sub %>%
 select(AMean:MatrixCorrectCount)

``` 


# Tasks

It's useful to extract the information we want for each participant, and then merge that to the questionnaire data (for example); this way we can keep the data in short/wide format. The following chunks process each task and then a small chunk merges them to the main task dataframe, which can then be merged to the questionnaire df if necessary to combine tasks and questionnaires in the EFA. 

It should be noted that I only omitted participants who did not consent/stated their responses are not valid at the very end of each chunk, i.e. after cleaning the data and extracting the relevant info. This has to be done for each task chunk separately, whereas it was done at the beginning of the questionnaire chunks for all questionnaires. 

Tasks also include lines to exclude outlier *trials* based on reaction time, since individual trials with outlier RTs probably indicate 1) technical error, 2) ppts pressing buttons without trying, 3) long RTs caused by ppts taking unsanctioned breaks. 

Participants who stopped the study during a Task have all their data from that Task excluded, because that data is not Missing At Random and thus affects both total scores/calculations and the validity of the data. 

## Go No Go
N = 134 usable ppts (146??)


```{r Go No-Go, include = FALSE}

# potentially problematic ppts, check if data needs to be made NA 
# 0vnopw72	5845513 : was interrupted in the task 

# It's not really possible to exclude ppts who stopped in the middle of this task any other way. These ppts stopped the experiment during GNG.
# 7mik8ed5 4886650
# xt9lwzwk 5117494
# 73bdl37a 5282634
# tfn355ew 5500754
# 5aakmlti 5552405
# kqn3t62x 5635997


data_nogoT$Participant.Private.ID <- factor(data_nogoT$Participant.Private.ID)

## Omitting experiment-general columns & practice (etc.) rows
data_nogoT <- data_nogoT %>%
 select(Participant.Private.ID, Spreadsheet:Answer) %>%
 filter(display == "Trials")

# Outlier trial exclusions first
# interquartile range: 1.5*(Q3-Q1), subtract this value from Q1 and add to Q3 to get the outlier boundaries. Here it was 1072. At least everything above 4000 is clearly an outlier, according to boxplots there are 4 trials between 1072 and 3000 that are also outliers. Need to do this first because outlier trials mess up the ppt level calculations. 
# In GNG the screens advance automatically after 1000ms (250ms stimulus presentation and 750ms wait, so e.g. a no-go response should be recorded as 1000ms). According to Gorilla, there is also the 16.67ms refresh rate and about 8ms latency between a computer and mouse, which adds something. https://support.gorilla.sc/support/info/timing#onlinetimingaccuracy A glance says that most NG responses are only up to about 1004ms, but it could be that there are some up to 1050? 

# Min. 1st Qu.  Median   Mean 3rd Qu.   Max. 
# 0   342   416   1113   634 20694243

# trying to ID a median reaction time overall to reject ppts, but this doesn't work for Matrix because the RTs are so variable
#Q1 <- quantile(data_nogoT$Reaction.Time, 0.25)
#Q3 <- quantile(data_nogoT$Reaction.Time, 0.75)
#range <- (IQR(data_nogoT$Reaction.Time)*1.5)
#lowbound <- Q1 - range
#highbound <- Q3 + range
#summary(data_nogoT$Reaction.Time)
#lowbound
#highbound
#boxplot(data_nogoT$Reaction.Time)

# upper outliers need to be rejected in order to look at mean RT measures
# the upper bound is reasonable based on what looks like only a few outliers above it
# there are a lot of responses around 1000ms, these are "no go" responses which moved to the next trial automatically. We will only look at mean/SD RTs of HITS and FA (correct hits and commission errors)
data_nogoT$Reaction.Time[which(data_nogoT$Reaction.Time > 1072)] <- NA

# setting a lower bound based on Jaana's 2017 paper: brain needs this much time to react
data_nogoT$Reaction.Time[which(data_nogoT$Reaction.Time < 150)] <- NA

## Participant exclusion criteria
#median RT<200ms, accuracy <60%
#both of these conditions designed to catch ppl who are just pressing buttons too quickly

# Median RT + Accuracy, participant level rejections
# nobody rejected
data_nogoT <- data_nogoT %>%
 group_by(Participant.Private.ID) %>% 
 mutate(medianRT = median(Reaction.Time), Accuracy = sum(Correct)/(sum(Correct)+sum(Incorrect))) %>% # Creating a new column that gives the median response time for each participant
 mutate(go.nogo_omit = case_when((medianRT > 200 & Accuracy > .60) ~ 0, (medianRT <= 200 | Accuracy <= .60) ~ 1)) # assigning 1 to rows where median RT is <200ms
 
# Omitting rows based on exclusion criteria
data_nogoT$Response[which(data_nogoT$go.nogo_omit == 1)] <- NA


## Signal Detection Theory categories for each row
# can also use the Response and Answer columns but the logic is pretty much the same
data_nogoT <- data_nogoT %>%
 filter(display == "Trials") %>%
 mutate(SDT = case_when(((Array == "H.png" | Array == "T.png") & Response == "Go") ~ "Hit", 
             ((Array == "H.png" | Array == "T.png") & Response == "No Go") ~ "Miss", 
             (Array == "N.png" & Response == "Go") ~ "False Alarm", 
             (Array == "N.png" & Response == "No Go") ~ "Correct Rejection")) # This is in case we want to look at how these relate to reaction times or EEG data at some point?

# Hit = H.png or T.png and Go (Array and Response)
# Miss = H-png or T.png and No Go
# False alarm = N.png and Go
# Correct rejection = N.png and No Go

# D-Prime and Bias for each participant

# https://www.rdocumentation.org/packages/psycho/versions/0.6.1/topics/dprime
# http://wise.cgu.edu/wise-tutorials/tutorial-signal-detection-theory/signal-detection-d-defined-2/
 
library(psycho)

data_nogoT <- data_nogoT %>%
 mutate(Hit = case_when(SDT == "Hit" ~ 1, 
             SDT != "Hit" ~ 0), 
     Miss = case_when(SDT == "Miss" ~ 1, 
             SDT != "Miss" ~ 0), 
     FA = case_when(SDT == "False Alarm" ~ 1, 
            SDT != "False Alarm" ~ 0), 
     CR = case_when(SDT == "Correct Rejection" ~ 1, 
            SDT != "Correct Rejection" ~ 0))

# calculating the mean and sd of hits and FA
data_hit <- filter(data_nogoT , SDT == "Hit")
data_hit_RT <- data_hit %>%
 group_by(Participant.Private.ID) %>%
 summarise(meanHitRT = mean(Reaction.Time, na.rm = TRUE), sdHitRT = sd(Reaction.Time, na.rm = TRUE))

#Q1 <- quantile(data_hit_RT$sdHitRT, 0.25, na.rm = TRUE)
#Q3 <- quantile(data_hit_RT$sdHitRT, 0.75, na.rm = TRUE)
#range <- (IQR(data_hit_RT$sdHitRT, na.rm = TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_hit_RT$sdHitRT)
#lowbound
#highbound

# one high outlier identified and removed
data_hit_RT$meanHitRT[which(data_hit_RT$meanHitRT > 593)] <- NA
# about 6 high outliers removed. They aren't clearly outliers from plotting but are higher values. It helps the skewness only slightly. 
data_hit_RT$sdHitRT[which(data_hit_RT$sdHitRT > 165)] <- NA

# FAs
data_FA <- filter(data_nogoT , SDT == "False Alarm")
data_FA_RT <- data_FA %>%
 group_by(Participant.Private.ID) %>%
 summarise(meanFA_RT = mean(Reaction.Time, na.rm = TRUE), sdFA_RT = sd(Reaction.Time, na.rm = TRUE))

# e.g. remember to change the variables to calculate the quartiles 
#Q1 <- quantile(data_FA_RT$meanFA_RT, 0.25, na.rm = TRUE)
#Q3 <- quantile(data_FA_RT$meanFA_RT, 0.75, na.rm = TRUE)
#range <- (IQR(data_FA_RT$meanFA_RT, na.rm = TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_FA_RT$meanFA_RT)
#lowbound
#highbound

#data_FA_RT$meanFA_RT[which(data_FA_RT$meanFA_RT > ??)] <- NA
# no outliers in the mean 
data_FA_RT$sdFA_RT[which(data_FA_RT$sdFA_RT > 198)] <- NA


# Calculating d-prime + bias
data_dprime <- data_nogoT %>%
 group_by(Participant.Private.ID) %>%
 summarise(dp = dprime(n_hit = sum(Hit), n_fa = sum(FA), n_miss = sum(Miss), n_cr = sum(CR), n_targets = 300, n_distractors = 100))

# Adding a row to specify what the five different values given mean
names <- c("GNGdprime", "GNGbeta", "GNGaprime", "GNGbppd", "GNGc") # we are interested in dprime and beta which means bias
value <- rep_len(names, length.out = nrow(data_dprime))
data_dprime$value <- value

# Into wide format
data_dprime <- data_dprime %>%
 pivot_wider(names_from = value, values_from = dp)
data_GNGdprime <- as.data.frame(data_dprime)

# Creating a sum score of each response category for each participant
data_nogoT_final <- data_nogoT %>%
 select(Participant.Private.ID, Hit, Miss, FA, CR) %>%
 group_by(Participant.Private.ID) %>%
 summarise(GNGHitSum = sum(Hit, na.rm = TRUE), GNGMissSum = sum(Miss, na.rm = TRUE), GNGFASum = sum(FA, na.rm = TRUE), GNGCRSum = sum(CR, na.rm = TRUE))

# Combining the dataframes, keeping all rows
data_nogoT_final <- merge(data_nogoT_final, data_GNGdprime, by = "Participant.Private.ID", all = TRUE)
data_nogoT_final <- merge(data_nogoT_final, data_hit_RT, by = "Participant.Private.ID", all = TRUE)
data_nogoT_final <- merge(data_nogoT_final, data_FA_RT, by = "Participant.Private.ID", all = TRUE)


## Excluding participants with invalid responses
# this contains validity data for all tasks
data_ConsentValidity <- data_Q_total %>%
 select(Participant.Private.ID, Language, Validity.quantised)
 
data_nogoT_final <- merge(data_nogoT_final, data_ConsentValidity, by = "Participant.Private.ID")

####### creating new sets to double check that rejected ppts match the other df
# I think one ppt was already excluded because of validity etc. These are the ones that didn't complete the task
#data_nonvalid_gng <- data_nogoT_final %>%
 #filter(Participant.Private.ID %in% c("4886650", "5117494", "5282634", "5500754", "5552405", "5635997"))
 #filter(Validity.quantised %in% c("2", 3, 4))

#data_Q_lang_omit_gng <- data_nogoT_final %>%
 #filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

# final set. Somehow this ppt who didn't actually do the task (zeroes in sum scores) has squeaked through, so removing them now. 
data_nogoT_final <- data_nogoT_final %>%
 filter(Validity.quantised %in% c(1, NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?") & Participant.Private.ID != "5201242" & Participant.Private.ID != "4886650" & Participant.Private.ID != "5117494" & Participant.Private.ID != "5282634" & Participant.Private.ID != "5500754" & Participant.Private.ID != "5552405" & Participant.Private.ID != "5635997")
# there are some rows with NAs or other missing data still but I think those are gotten rid of during the merging or formatting task variables chunks

# omitting specific participants who commented that they were interrupted in the task
# first see if they were included in the first place based on quality
# it's mostly the hits and misses that are much lower/higher, but they are not the worst score. They are not an outlier. Keep them or no?

# 7mik8ed5 4886650
# xt9lwzwk 5117494
# 73bdl37a 5282634
# tfn355ew 5500754
# 5aakmlti 5552405
# kqn3t62x 5635997

# 5845513 the one who was interrupted during the task 

#######

# Subsetting by validity and consent info + omitting the irrelevant columns
# Technically we will likely only need d prime and bias but extra columns can easily be dropped later on
# has 148 ppts now but should eventually be 146
data_nogoT_final <- data_nogoT_final %>%
 select(Participant.Private.ID, GNGHitSum, GNGMissSum, GNGFASum, GNGCRSum, meanHitRT, sdHitRT, meanFA_RT, sdFA_RT, GNGdprime, GNGbeta, GNGaprime, GNGbppd, GNGc) 

# no outliers (dprime only??)
#par(mfrow = c(2, 3))
#hist(as.numeric(data_nogoT_final$GNGdprime), main = "dprime", ylim = c(0, 40), col = rainbow(14), xlab = "")
#hist(as.numeric(data_nogoT_final$GNGbeta), main = "beta", col = rainbow(14), xlab = "")
#hist(as.numeric(data_nogoT_final$GNGaprime), main = "aprime", col = rainbow(14), xlab = "")
#hist(as.numeric(data_nogoT_final$GNGbppd), main = "bppd", ylim = c(0, 100), col = rainbow(14), xlab = "")
#hist(as.numeric(data_nogoT_final$GNGc), main = "c", ylim = c(0, 40), col = rainbow(14), xlab = "")


#shapiro.test(as.numeric(data_nogoT_final$GNGdprime))

#GNG_task <- (describe(data_nogoT_final$dprime))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGbeta))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGaprime))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGbppd))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGc))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGHitSum))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGMissSum))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGFASum))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$GNGCRSum))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$meanHitRT))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$sdHitRT))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$meanFA_RT))
#GNG_task <- rbind(GNG_task, describe(data_nogoT_final$sdFA_RT))
#row.names(GNG_task) <- c("GNGdprime", "GNGbeta", "GNGaprime", "GNGbppd", "GNGc", "GNGHitSum", "GNGMissSum", "GNGFASum", "GNGCRSum", "meanHitRT", "sdHitRT", "meanFA_RT", "sdFA_RT")
#View(GNG_task)

```


## Navon

The two measures of interest are 1. the global-local precedence index, which quantifies the bias toward a global processing level. Responses are typically faster to a target stimulus that appears in the global condition versus the local; and 2. Global-to-local interference index, for which positive values indicate the extent to which the bias toward global stimuli interferes with processing local information. 

N = 135 usable ppts
started with 140 who finished 

***is using the interquartile method to delete trials based on reaction time OK for this task with this RT distribution??? ***

```{r Navon task, include = FALSE}

# potentially problematic ppts, replace data with NA if necessary
# qphf172f	5867681: thought their handedness would affect Navon (unlikely) 
# 7mr6hy7i	5446208: probably 25% of their responses are wrong--did not fully get the task/realized they were doing it wrong

# these ppts stopped the experiment during Navon, and thus don't have a full dataset for this task
# xb2ctdsi 4907987
# u7uqmiee 4960307
# qxvqj34s 5317567
# huo5rege 5372338
# uy3ewu4f 5526450
# 1jssdk6e 5578226
# ajrc2dxp 5626669
# l802ayaq 5808176

# Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only 

# Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only 

# Positive values indicate the extent to which global stimuli interfere with the local info 

# I calculated these manually. I first extracted the SDs for the reaction times for the two conditions in question (global consistent and local consistent for global precedence, local consistent and local inconsistent for global-to-local interference). I then calculated the pooled mean (https://www.statisticshowto.com/pooled-standard-deviation/). After that, I calculated the mean reaction time to the two trial types for each participant (e.g., global consistent and local consistent for global precedence). Finally, I compared the difference between these means for each participant to the pooled SD (https://www.statisticshowto.com/cohens-d/).

data_NavonT$Participant.Private.ID <- factor(data_NavonT$Participant.Private.ID)

## Omitting experiment-general columns & practice (etc.) rows
data_NavonT <- data_NavonT %>%
 select(Participant.Private.ID, Spreadsheet:Image) %>%
 filter(display %in% c("task1", "task2"))

## Only Including the relevant rows for us: this means rows where Screen.name = "Screen 3" 
data_NavonT <- data_NavonT %>%
 filter(Screen.Name == "Screen 3")

# Creating a column for consistency
data_NavonT <- data_NavonT %>%
 mutate(Consistency = case_when((Image == "bigHsmallH.png" | Image == "bigSsmallS.png") ~ "Consistent", 
                 (Image == "bigHsmallS.png" | Image == "bigSsmallH.png") ~ "Inconsistent"))
data_NavonT$Consistency <- factor(data_NavonT$Consistency)

data_NavonT$display <- factor(data_NavonT$display)
## Checking the accuracy per group (global/local + consistent/inconsistent)

# Accuracy is now its own df, summary(Accuracy_Navon) gives Accuracy_cond minimum 91.21%
Accuracy_Navon <- data_NavonT %>%
 group_by(Consistency, display) %>%
 summarise(Accuracy_cond = sum(Correct)/(sum(Correct)+sum(Incorrect)))

## Exclusion criteria

# for ppt level median RT<50ms (this is arbitrary, I've just chosen 50ms here (so that actually means 250+50 = 300 in this task), i.e. the previous screen is stimulus presentation and advances automatically after 250ms, while the response screen advances only on response, but we should probably look at the distribution of RTs later on), accuracy <60%, <95% RESPONSES fall on the same value
 
# Outlier trial exclusions first
# interquartile range: 1.5*(Q3-Q1), subtract this value from Q1 and add to Q3 to get the outlier boundaries. Here it was 671.8. Need to do this first because outlier trials mess up the ppt level calculations. There seem to be a lot of outliers on a gradient from around 5000ms up to 20000ms, different to GNG 

#Min. 1st Qu.  Median   Mean 3rd Qu.   Max. 
#0.6  211.0  307.1  389.2  441.4 183064.1 

#store_data_Navon <- data_NavonT
#data_NavonT <- store_data_Navon 

# getting rid of trials outside of range -- IQR method doesn't really work here because of an extreme skew
# instead, start with an arbitrary cutoff of 3000 (3s)
data_NavonT$Reaction.Time[which(data_NavonT$Reaction.Time > 3000)] <- NA

# this removes TRIALS that are outside 2.5 standard deviations of the mean PER PARTICIPANT
#########keep this or no?##############

data_NavonT <- data_NavonT %>%
 group_by(Participant.Private.ID) %>%
 filter(between(Reaction.Time, mean(Reaction.Time, na.rm = TRUE) - (2.5 * sd(Reaction.Time, na.rm = TRUE)), 
           mean(Reaction.Time, na.rm = TRUE) + (2.5 * sd(Reaction.Time, na.rm = TRUE))))

#Q1 <- quantile(data_NavonT$Reaction.Time, 0.25)
#Q3 <- quantile(data_NavonT$Reaction.Time, 0.75)
#range <- (IQR(data_NavonT$Reaction.Time)*1.5)
#lowbound <- Q1 - range
#highbound <- Q3 + range


# this rejects PARTICIPANTS based on their MEDIAN RT being too short or too long 
#1 ppt has a clearly too high median RT
#no ppt has a median RT of 50ms or less

# Median RT & Accuracy
data_NavonT <- data_NavonT %>%
 group_by(Participant.Private.ID) %>%
 mutate(MedianRT = median(Reaction.Time), Accuracy = sum(Correct)/(sum(Correct)+sum(Incorrect)), Ratio = max(table(Response))/length(Response)) %>%
 mutate(Navon_omit = case_when(MedianRT > 50 & MedianRT < 1000 & Accuracy > .60 & Ratio < .95 ~ 0, 
                MedianRT <= 50 | Accuracy <= .60 | Ratio >= .95 ~ 1))

# Omitting data based on Navon_omit
data_NavonT$Reaction.Time[which(data_NavonT$Navon_omit == 1)] <- NA

## Subsetting: only looking at the correct answers
data_NavonT <- data_NavonT %>%
 filter(Correct == "1")

## Calculating pooled SDs

data_NavonT <- ungroup(data_NavonT)

#Global SD 1 (consistent trials only)
#again need to include the argument na.rm = TRUE otherwise NA values will cause the sd calculation to return empty
sd_Global_con <- data_NavonT %>%
 filter((Consistency == "Consistent") & display == "task1") %>%
 summarise(sd(Reaction.Time, na.rm = TRUE))

# Local SD 1 (consistent trials only)
sd_Local_con <- data_NavonT %>%
 filter((Consistency == "Consistent") & display == "task2") %>%
 summarise(sd(Reaction.Time, na.rm = TRUE))

# Local SD 2 (inconsistent trials only)
sd_Local_incon <- data_NavonT %>%
 filter((Consistency == "Inconsistent") & display == "task2") %>%
 summarise(sd(Reaction.Time, na.rm = TRUE))
 
# Calculating pooled SD
# https://www.statisticshowto.com/pooled-standard-deviation/
# I used the simplest formula and calculated it manually but there might be a quicker way to do it
# The more complex formula on the website is to correct for small sample sizes but this shouldn't be a problem once we have our data, so I just used the simpler formula.

# Pooled SD consistent (local and global)
pooled_SD_con <- sqrt((sd_Global_con^2 + sd_Local_con^2)/2)
pooled_SD_con

# Pooled SD local (consistent and inconsistent)
pooled_SD_local <- sqrt((sd_Local_incon^2 + sd_Local_con^2)/2)
pooled_SD_local

#pooled_SD_con
 #sd(Reaction.Time, na.rm = TRUE)
#1             130.033

#pooled_SD_local
 #sd(Reaction.Time, na.rm = TRUE)
#1            137.5748

# Final form of the Navon data: selecting relevant columns and transforming the data so that the columns reflect mean reaction times in each of the four conditions (local/global x consistent/inconsistent)
data_NavonT_final <- data_NavonT %>% 
 select(Participant.Private.ID, Consistency, display, Reaction.Time) %>%
 group_by(Participant.Private.ID, Consistency, display) %>%
 summarise(NavonReactionTimeMean = mean(Reaction.Time, na.rm = TRUE), .groups = "keep") %>%
 pivot_wider(names_from = c(Consistency, display), values_from = NavonReactionTimeMean)



# Global-local precedence index: Standardized mean difference (cohen’s d) in RT between global and local judgments on consistent trials only 
data_NavonT_final <- data_NavonT_final %>%
 mutate(GlobalToLocalPrecedence = ((Consistent_task1 - Consistent_task2)/as.numeric(pooled_SD_con)))

## Global-to-local interference index: Standardized mean difference (cohen’s d) in RT between inconsistent and consistent trials in local condition only
data_NavonT_final <- data_NavonT_final %>%
 mutate(GlobalToLocalInterference = ((Inconsistent_task1 - Consistent_task2)/as.numeric(pooled_SD_local)))

## Excluding nonvalid participants
data_NavonT_final <- merge(data_NavonT_final, data_ConsentValidity, by = "Participant.Private.ID")

# xb2ctdsi 4907987
# u7uqmiee 4960307
# qxvqj34s 5317567
# huo5rege 5372338
# uy3ewu4f 5526450
# 1jssdk6e 5578226
# ajrc2dxp 5626669
# l802ayaq 5808176

#data_NavonT_final <- data_NavonT_final %>%
 #filter(ConsentFlag == 1 & Validity.quantised == 1 & Language == "Sujuva / Ã¤idinkieli") %>%
 #select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)

# getting rid of ppts who stopped halfway through, some have already been caught by quality control
data_NavonT_final <- data_NavonT_final %>%
 filter(Participant.Private.ID != "4907987" & Participant.Private.ID != "4960307" & Participant.Private.ID != "5317567" & Participant.Private.ID != "5372338" & Participant.Private.ID != "5526450" & Participant.Private.ID != "5578226" & Participant.Private.ID != "5626669" & Participant.Private.ID != "5808176")

# validity filter
data_NavonT_final <- data_NavonT_final %>%
 filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
 select(Participant.Private.ID, Consistent_task1, Consistent_task2, Inconsistent_task1, Inconsistent_task2, GlobalToLocalPrecedence, GlobalToLocalInterference)
# there are 3 rows of NAN 

# final score outlier exclusions
# not going to do this right now. The spread seems to include some upper and lower extremes, but the distribution shape is good 

#Q1 <- quantile(data_NavonT_final$GlobalToLocalInterference, 0.25, na.rm = TRUE)
#Q3 <- quantile(data_NavonT_final$GlobalToLocalInterference, 0.75, na.rm = TRUE)
#range <- (IQR(data_NavonT_final$GlobalToLocalInterference, na.rm = TRUE)*1.5)
#lowbound <- (Q1 - range)
#highbound <- (Q3 + range)
#summary(data_NavonT_final$GlobalToLocalInterference)
#lowbound
#highbound

#plot(data_NavonT_final$GlobalToLocalPrecedence)
#plot(data_NavonT_final$GlobalToLocalInterference)

#summary(data_NavonT_final$GlobalToLocalPrecedence)
#summary(data_NavonT_final$GlobalToLocalInterference)
#mean(data_NavonT_final$GlobalToLocalPrecedence, na.rm = TRUE) + (2.5 * sd(data_NavonT_final$GlobalToLocalPrecedence, na.rm = TRUE))
#mean(data_NavonT_final$GlobalToLocalPrecedence, na.rm = TRUE) - (2.5 * sd(data_NavonT_final$GlobalToLocalPrecedence, na.rm = TRUE))

#data_NavonT_final$GlobalToLocalPrecedence[which(data_NavonT_final$GlobalToLocalPrecedence < -1.29128)] <- NA
#data_NavonT_final$GlobalToLocalInterference[which(data_NavonT_final$GlobalToLocalInterference > 1.16392)] <- NA

#they're "almost normal"
#shapiro.test(data_NavonT_final$GlobalToLocalPrecedence)
#shapiro.test(data_NavonT_final$GlobalToLocalInterference)

#par(mfrow = c(1, 2))
#hist(data_NavonT_final$GlobalToLocalPrecedence, main = "GlobalToLocalPrecedence", ylim = c(0, 60), col = rainbow(14), breaks = seq(-2, 2, .5), xlab = "")
#hist(data_NavonT_final$GlobalToLocalInterference, main = "GlobalToLocalInterference", ylim = c(0, 60), col = rainbow(14), breaks = seq(-2, 2, .5), xlab = "")

#Navon_task <- (describe(data_NavonT_final$GlobalToLocalPrecedence))
#Navon_task <- rbind(Navon_task, describe(data_NavonT_final$GlobalToLocalInterference))
#row.names(Navon_task) <- c("GlobalToLocalPrecedence", "GlobalToLocalInterference")
#View(Navon_task)

```

## Necker

about 7 ppts didn't experience switching at all, which is a valid option
6 are outliers according to IQR
no exclusions made currently
N = 153

```{r Necker cube, include = FALSE}

# Necker: switches per second for each session

data_NeckerT$Participant.Private.ID <- factor(data_NeckerT$Participant.Private.ID)

# Omitting irrelevant columns
data_NeckerT <- data_NeckerT %>%
 select(Participant.Private.ID, Spreadsheet:Image)

# Omitting irrelevant rows (Instructions / empty rows)
data_NeckerT <- data_NeckerT %>%
 filter(display %in% c("Trial 1", "Trial 2"))

# Exclusion criteria: none for now, but consider high outliers and ppts who reported no switching--can check later if there is a difference there

# this ppt stopped during Necker
# t98f4qif 5385143

## Sum score for how many times space bar was hit in total
data_NeckerT_final <- data_NeckerT %>%
 select(Participant.Private.ID, Response) %>%
 group_by(Participant.Private.ID) %>%
 summarise(NeckerCountTotal = sum(Response == "space", na.rm = TRUE))

## Switches per second
data_NeckerT_final <- data_NeckerT_final %>%
 mutate(NeckerTotalRate = NeckerCountTotal/60)

# rate interquartile max 0.35832, 6 ppts NA'd here
#  Min. 1st Qu. Median  Mean 3rd Qu.  Max. 
#0.00000 0.06667 0.11667 0.13647 0.18333 0.48333 

#data_NeckerT_final$NeckerTotalRate[which(data_NeckerT_final$NeckerTotalRate > 0.35832)] <- NA
#data_NeckerT_final$NeckerCountTotal[which(data_NeckerT_final$NeckerTotalRate > 0.35832)] <- NA

data_NeckerT_final <- merge(data_NeckerT_final, data_ConsentValidity, by = "Participant.Private.ID")

# creating ppt omit sets
#data_nonvalid_Necker <- data_NeckerT_final %>%
# filter(Validity.quantised %in% c(2, 3, 4))

#data_Necker_lang_omit <- data_NeckerT_final %>%
# filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

# Subsetting by validity and consent info + omitting the irrelevant columns
data_NeckerT_final <- data_NeckerT_final %>%
 filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
 select(Participant.Private.ID, NeckerCountTotal, NeckerTotalRate)

# ppt 5385143 stopped during necker, exclude their data (already NA) Participant.Private.ID != "5385143" 

#boxplot(data_NeckerT_final$NeckerTotalRate)
#boxplot(data_NeckerT_final$NeckerCountTotal)
#hist(data_NeckerT_final$NeckerTotalRate, main = "Perceptual Switching Rate", col = "blue", breaks = seq(0, .35, .01), xlab = "")

```

## Unusual Uses Task

NB: FIRST conduct interrater reliability using UUT_Analysis.Rmd. Then create a file that contains at least columns for participant number, fluency and flexibility ratings for at least 2 raters. Rows are individual participant responses. Rows are individual participant responses.

Fluency is a measure of how many unique unusual uses a ppt can think of for each item. FluencySum is the count of all unique uses over all items for a ppt. Flexibility score refers to the uniquenes of the functional categories of items, i.e. a participant gets two point for using a shoe as a doorstop and a flowerpot but only one point for a houseplant pot and a bonsai tree pot (same functional use).FlexSum is the sum of flexibility points over all items for a participant. Refer to UUT scoring instructions for further detail.

N = 150

```{r Unusual Uses Task, include = FALSE}

data_UUT <- read.csv('UUT_scoring_COMBINED_REVISED_Rcsv.csv', sep = ";")
#View(data_UUT)

# potentially problematic ppts: 
# ghufyqzr	5691497 : wasn't sure if UUT answers were saved
# 6r93nkqg	5686104 : wasn't sure if UUT answers were saved 
# sssb0k4g	5507405 : wrote all UUT answers in same space
## these were checked by hand during rating and are all OK

########################################################################################################
## did they use these processing chunks in the reliability analysis?? maybe move them to there? 
#data_uutT$Participant.Private.ID <- factor(data_uutT$Participant.Private.ID)

# Omitting experiment-general columns and excluding practice trials
#data_uutT <- data_uutT %>%
# select(Participant.Private.ID, Spreadsheet:text) %>%
# filter(Screen.Name != "Screen 3")

# Omitting irrelevant rows (with empty cells)
#data_uutT$Response[which(data_uutT$Response == "")] <- NA

#data_uutT <- data_uutT %>%
# filter(!is.na(Response)) #only keeping rows with responses (not NAs)

# Splitting cells that have multiple responses (if participant forgot to press enter between answers)
#data_uutT <- separate_rows(data_uutT, Response, sep = ", ", convert = TRUE)

# Creating fake columns for flexibility and fluency to demonstrate how they would be calculated
#data_uutT$Fluency <- rbinom(n = nrow(data_uutT), 1, p = 0.90)
#data_uutT$Flexibility <- rbinom(n = nrow(data_uutT), 1, p = 0.70)

############################################################################################################

### can put a little section here looking at any differences in Fluency and Flexibility scores per ppt between the different items. probably we don't need to worry about this, but in case someone asks if there are some items that may seem invalid because of weird response patterns####

#######################################################################################

### Calculating the fluency and flexibility sum score for each participant per rater
data_UUT_scores <- data_UUT %>%
 select(Participant.Private.ID, S.Flex, S.Fluency, K.Flex, K.Fluency) %>%
 group_by(Participant.Private.ID) %>%
 summarise(SFlexibilitySum = sum(S.Flex), SFluencySum = sum(S.Fluency), KFlexibilitySum = sum(K.Flex), KFluencySum = sum(K.Fluency))
#View(data_UUT_scores)

# participant sum scores as a mean of rater scores
data_UUT_scores$FlexSum <- rowMeans(cbind(data_UUT_scores$SFlexibilitySum, data_UUT_scores$KFlexibilitySum), na.rm = TRUE)
data_UUT_scores$FluencySum <-rowMeans(cbind(data_UUT_scores$SFluencySum, data_UUT_scores$KFluencySum), na.rm = TRUE)

# checking distributions
#par(mfrow = c(2, 2))
#hist(data_UUT_scores$SFlexibilitySum)
#hist(data_UUT_scores$SFluencySum)
#hist(data_UUT_scores$KFlexibilitySum)
#hist(data_UUT_scores$KFluencySum)

# generally flexibility more normal than fluency
#(data_UUT_scores$SFlexibilitySum)
#shapiro.test(data_UUT_scores$SFluencySum)
#shapiro.test(data_UUT_scores$KFlexibilitySum)
#shapiro.test(data_UUT_scores$KFluencySum)

# total
#hist(data_UUT_scores$FlexSum)
#hist(data_UUT_scores$FluencySum)
#shapiro.test(data_UUT_scores$FlexSum)
#shapiro.test(data_UUT_scores$FluencySum)

# checking validity
data_UUT_scores <- merge(data_UUT_scores, data_ConsentValidity, by = "Participant.Private.ID")

#data_nonvalid_UUT <- data_UUT_scores %>%
 #filter(Validity.quantised %in% c(2, 3, 4))

#data_UUT_lang_omit <- data_UUT_scores %>%
 #filter(Language != "Sujuva / Ã¤idinkieli" & Language != "Keskitaso / keskusteleva" & Language != "Muu, mikÃ¤?")

# extracting the columns we want
data_UUT_scores <- data_UUT_scores %>%
 filter(Validity.quantised %in% c("1", NA, "") & Language %in% c("Sujuva / Ã¤idinkieli", "Keskitaso / keskusteleva", "Muu, mikÃ¤?")) %>%
 select(Participant.Private.ID, FlexSum, FluencySum)

```


# Merging task variables

Doesn't yet include the CI task! 

N = 155

```{r Combining the task dataframes, include = FALSE}

data_T_total1 <- merge(data_nogoT_final, data_NavonT_final, by = "Participant.Private.ID", all = TRUE)
data_T_total2 <- merge(data_UUT_scores, data_NeckerT_final, by = "Participant.Private.ID", all = TRUE)
#data_T_total <- merge(data_T_total, data_NeckerT_final, by = "Participant.Private.ID", all = TRUE)
data_T_total <- merge(data_T_total1, data_T_total2, by = "Participant.Private.ID", all = TRUE)
rm(data_T_total1, data_T_total2)


## Extracting the relevant columns

data_T_sub <- data_T_total %>%
 select(Participant.Private.ID, GNGdprime, GNGbeta, meanHitRT, sdHitRT, meanFA_RT, sdFA_RT, GlobalToLocalPrecedence, GlobalToLocalInterference, NeckerTotalRate, FlexSum, FluencySum)


# getting rid of values that should be NAs 
#is.nan.data.frame <- function(x)
# do.call(cbind, lapply(x, is.nan))
#data_T_sub[is.nan(data_T_sub)] <- NA

# need to coerce the numeric variables to numeric through unlist and get rid of the NULLs in the meantime
data_T_sub$GNGdprime[which(data_T_sub$GNGdprime == "NULL")] <- NA
data_T_sub$GNGbeta[which(data_T_sub$GNGbeta == "NULL")] <- NA
data_T_sub$GNGdprime <- as.numeric(unlist(data_T_sub$GNGdprime))
data_T_sub$GNGbeta <- as.numeric(unlist(data_T_sub$GNGbeta))

str(data_T_sub)


```


# T missing data

Better to do this for tasks and questionnaires separately, because they have different reasons for being missing and different implications. Do this before checking distributions because ppts with large amounts of missing data or suspicious patterns of missing data are removed here from the final dataset.

Final N after cleaning: N = 143 ppts with task data

```{r}

library(ggplot2)
library(naniar)

# add a column for count of missing data per ppt, to task sub df
data_T_sub1 <- data_T_sub %>%
 mutate(missingtasks = rowSums(is.na(data_T_sub)))

View(data_T_sub)

# there is a clear elbow at around 3 missing variables, the next step is 6 missing which adds 2 more ppts, and above that is 8 missing
# so for this I'll choose to cut off at below 4 missing
ggplot(data_T_sub, aes(x = as.factor(Participant.Private.ID), y = missingtasks)) +
   geom_boxplot(fill = "slateblue", alpha = 0.2) + 
   xlab("Missing variables count")

# try to see if there's an elbow in the number of missing variables per ppt 
MissingTasks<-sort(data_T_sub$missingtasks, decreasing = FALSE)
plot(MissingTasks)

# just temporarily getting the demographic info to the task df so I can investigate missingness
data_T_all <- data_Q_total %>%
 select(Participant.Private.ID, gender, Age, Country, Language, Education)

data_T_sub <- merge(data_T_all, data_T_sub, by = "Participant.Private.ID", all = TRUE)

# getting rid of some NaNs in the Navon variables
is.nan.data.frame <- function(x)
 do.call(cbind, lapply(x, is.nan))
data_T_sub[is.nan(data_T_sub)] <- NA

# there is a significant correlation between age and missing data in the tasks before ppt removal, probably because older ppts struggle more in the timed tasks
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age, data_T_sub$missing, method = "spearman", exact = FALSE)

#gg_miss_fct(x = data_T_sub, fct = Language)
#gg_miss_fct(x = data_T_sub, fct = Country)
#gg_miss_fct(x = data_T_sub, fct = gender)
#gg_miss_fct(x = data_T_sub, fct = Education)


# removing ppts with 5 or more task variables missing (total 9 variables, looks like most ppts have no more than 3 missing)
data_T_sub <- data_T_sub %>%
 group_by(Participant.Private.ID) %>%
 filter(missing < 4)

# checking whether there is still a correlation between age and missing data--it's better but still there
gg_miss_fct(x = data_T_sub, fct = Age)
cor.test(data_T_sub$Age, data_T_sub$missing, method = "spearman", exact = FALSE)

# removing the columns we don't need again
data_T_sub <- data_T_sub %>%
 select(GNGdprime:FluencySum)

View(data_T_sub)

```


# T distributions and correlations

Done according to our plan: 
Transform GNGbeta, meanHitRT and sdHitRT and sdFA_RT
Removing meanFA_RT and GlobalLocalInterference for having high correlations >.85 with other variables in the same measure

NB: not entirely sure about the processing here. 


```{r Checking the normality of the task variables, include = FALSE}

# each of the measures (mean, skew, kurtosis) should be inspected and transformations should be conducted accordingly

# this has already basically been checked in each processing section

## Normality of variables: visualising with histograms
#GNGdprime <- ggplot(data_T_sub, aes(x = GNGdprime)) +
# geom_histogram(color = "black", fill = "lightblue")
#GNGdprime
#GNGbeta <- ggplot(data_T_sub, aes(x = GNGbeta)) +
# geom_histogram(color = "black", fill = "lightblue")
#GNGbeta
#meanHitRT <- ggplot(data_T_sub, aes(x = meanHitRT)) +
# geom_histogram(color = "black", fill = "lightblue")
#meanHitRT
#meanFA_RT <- ggplot(data_T_sub, aes(x = meanFA_RT)) +
# geom_histogram(color = "black", fill = "lightblue")
#meanFA_RT
#sdHitRT <- ggplot(data_T_sub, aes(x = sdHitRT)) +
# geom_histogram(color = "black", fill = "lightblue")
#sdHitRT
#sdFA_RT <- ggplot(data_T_sub, aes(x = sdFA_RT)) +
# geom_histogram(color = "black", fill = "lightblue")
#sdFA_RT
#GlobalToLocalPrecendence <- ggplot(data_T_sub, aes(x = GlobalToLocalPrecendence)) +
# geom_histogram(color = "black", fill = "lightblue")
#GlobalToLocalPrecendence
#GlobalToLocalInterference <- ggplot(data_T_sub, aes(x = GlobalToLocalInterference)) +
# geom_histogram(color = "black", fill = "lightblue")
#GlobalToLocalInterference
#NeckerTotalRate <- ggplot(data_T_sub, aes(x = NeckerTotalRate)) +
# geom_histogram(color = "black", fill = "lightblue")
#NeckerTotalRate

# Transformations 

## Normality of variables: skewness
#which(abs(skew(data_T_sub))>1) #The variables that need to be transformed (no code for this yet)
#which(abs(skew(data_T_total))>1)

# I think the task variables need to be transformed

## Correlation matrix
#If two (or more) variables from the same questionnaire or task correlate so that r>.85, one of them should be omitted (from Eisenberg et al.)
#no omissions needed from questionnaires

# check the indexes, it changes if you've deleted the demographic columns
#GNG variables
#mean hit RT and mean FA RT are correlated 0.8775609 
cor(data_T_sub[, 2:7], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[, 2:7], method = "pearson", use = "pairwise.complete.obs")) > .85 #TRUE values: we should consider omitting one of the variables 

# Navon variables
#correlated with each other 0.8947398    
cor(data_T_sub[, 8:9], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[, 8:9], method = "pearson", use = "pairwise.complete.obs")) > .85

# UUT variables
# correlated with each other .984135
cor(data_T_sub[, 11:12], method = "pearson", use = "pairwise.complete.obs") 
abs(cor(data_T_sub[, 11:12], method = "pearson", use = "pairwise.complete.obs")) > .85


# GNGbeta has high positive skew; transforming it and replacing it in the df 

# the mean and sd hit and FA RTs are also skewed positively, so trying to transform them too just to see how it goes 


data_T_sub$GNGbetalog<-log10(data_T_sub$GNGbeta)
#GNGbetalog <- ggplot(data_T_sub, aes(x = GNGbetalog)) +
# geom_histogram(color = "black", fill = "lightblue")
#GNGbetalog
#qqnorm(data_T_sub$GNGbetalog)
#it's not as bad as it could be? keeping for now?? 

data_T_sub$meanHitRTlog<-log10(data_T_sub$meanHitRT)
#meanHitRTlog <- ggplot(data_T_sub, aes(x = meanHitRTlog)) +
# geom_histogram(color = "black", fill = "lightblue")
#meanHitRTlog
#good enough according to shapiro. The original wasn't that bad. 

data_T_sub$sdHitRTlog<-log10(data_T_sub$sdHitRT)
#sdHitRTlog <- ggplot(data_T_sub, aes(x = sdHitRTlog)) +
# geom_histogram(color = "black", fill = "lightblue")
#sdHitRTlog
#again wasn't that bad but helped

data_T_sub$sdFA_RTlog<-log10(data_T_sub$sdFA_RT)
#sdFA_RTlog <- ggplot(data_T_sub, aes(sdFA_RTlog)) +
# geom_histogram(color = "black", fill = "lightblue")
#sdFA_RTlog
# was a bit worse but helped, still not great

# selecting a final set of task variables including the transformed ones
#here abribtrarily remove variables that were highly correlated with others from the same task
data_T_sub <- data_T_sub %>%
 select(GNGdprime, GNGbetalog, meanHitRTlog, sdHitRTlog, sdFA_RTlog, GlobalToLocalPrecedence, NeckerTotalRate, FlexSum)

```


# Formatting T & Q dataframes 

there are now N = 163 in the full set (data_all_sub_cleaned) because there is one ppt who has NA for all Q data but has some T data. Q set N = 162, T set N = 143

These dfs have the final full set of variables and ppts, including transformed variables and cleaned data. 

```{r Combining task and questionnaire dataframes, include = FALSE}

data_all_sub_cleaned <- merge(data_Q_sub, data_T_sub, by = "Participant.Private.ID", all = TRUE)
View(data_all_sub_cleaned)

#ungroup(data_all_sub_cleaned)
#clustdata <- data_all_sub_cleaned %>%
 #select(Participant.Private.ID:AOTSum, RPSum:FluencySum)

# need to ungroup and select to get rid of ppt private id. This can also be done earlier. Ungrouping turns the df into a tibble, so have to coerce back to a df before selecting to remove ppt private id
ungroup(data_all_sub_cleaned)
data_all_sub_cleaned <- data_all_sub_cleaned %>%
 select(AMean:FluencySum)
View(data_all_sub_cleaned)

ungroup(data_Q_sub)
data_Q_sub<-data.frame(data_Q_sub)
data_Q_sub <- data_Q_sub %>%
 select(AMean:MatrixCorrectCount)

ungroup(data_T_sub)
data_T_sub<-data.frame(data_T_sub)
data_T_sub <- data_T_sub %>%
 select(GNGdprime:NeckerTotalRate)

# this set removes GNGbetalog and the other RT based GNG measures which are generally correlated and clustered with themselves and nothing else 
# trying this to see if it solves the ultra-Heywood case issue
data_all_without_GNG <- data_all_sub_cleaned %>%
 select(AMean:GNGdprime, GlobalToLocalPrecedence:FlexSum)

# without binary variables, use this for clustering raw (not correlation matrix)
data_all_without_binary <- data_all_sub_cleaned %>%
 select(AMean:AOTSum, RPSum:FlexSum)

# data without GNG or binary, use this for the cross validated ridge regression predictions of tasks by surveys etc. 
data_without_GNG_or_binary <- data_all_without_GNG %>%
 select(AMean:AOTSum, RPSum:FlexSum)

# data set based on predictions: surveys plus navon and necker
data_from_predictions <- data_all_sub_cleaned %>%
 select(AMean:MatrixCorrectCount, GlobalToLocalPrecedence:NeckerTotalRate)

#########################################################################
# First start from the beginning---sets for EFA process
# no need to worry about correlated variables, they were removed in the previous section
# whole set
all_new <- data_all_sub_cleaned %>%
 select(AMean:FlexSum)

# eventually leaving out HEscore, EMean, sci.tru.sum
Q_new <- data_all_sub_cleaned %>%
 select(AMean:MatrixCorrectCount)
#Q_new <- na.omit(Q_new) #dont use this, it gets rid of all rows with NAs
 #select(AMean:CMean, ESMean:AOTSum, HRscore:sci_cur, sci_impo:MatrixCorrectCount)

# Task set for EFA process
# UUT as a task
T_new <- data_T_sub %>%
 select(GNGdprime:FlexSum)
 
```

# Citizen's Initiative
Potentially problematic ppts for CI: 
ri0gfe1h	5767733	skipped reading at least one article
vu1mvwkd	5691188	didn't focus on the first CI text
8zz2teyh	5629594	is dyslexic
tjh0tjq3	4887029	CI task invalid


```{r}

# will add the code when it works on its own 


```




